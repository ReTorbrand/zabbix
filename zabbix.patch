diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/frontends/php/app/views/monitoring.widget.problems.view.php xe-rabbix/frontends/php/app/views/monitoring.widget.problems.view.php
--- zabbix-4.0.1/frontends/php/app/views/monitoring.widget.problems.view.php	2018-10-29 22:36:01.000000000 +0500
+++ xe-rabbix/frontends/php/app/views/monitoring.widget.problems.view.php	2018-11-13 11:11:53.000000000 +0500
@@ -50,7 +50,7 @@
 	->setHeader(array_merge($header, [
 		$show_recovery_data ? _('Recovery time') : null,
 		$show_recovery_data ? _('Status') : null,
-		_('Info'),
+//		_('Info'),
 		($data['sortfield'] === 'host') ? [_('Host'), $sort_div] : _('Host'),
 		[
 			($data['sortfield'] === 'name') ? [_('Problem'), $sort_div] : _('Problem'),
@@ -148,6 +148,18 @@
 		$info_icons[] = makeSuppressedProblemIcon($problem['suppression_data']);
 	}
 
+
+//	$description = (new CCol([$problem['name']
+//		
+//		(new CLinkAction($problem['name']))
+//			->setHint(
+//				make_popup_eventlist($trigger, $eventid, $backurl, $data['fullscreen'], $show_timeline, $sortorder),
+//				'',
+//				true
+//			)
+// 	]));
+
+
 	$description = (new CCol([
 		(new CLinkAction($problem['name']))
 			->setHint(
@@ -212,7 +224,7 @@
 	$table->addRow(array_merge($row, [
 		$show_recovery_data ? $cell_r_clock : null,
 		$show_recovery_data ? $cell_status : null,
-		makeInformationList($info_icons),
+//		makeInformationList($info_icons),
 		$triggers_hosts[$trigger['triggerid']],
 		$description,
 		(new CCol(zbx_date2age($problem['clock'], ($problem['r_eventid'] != 0) ? $problem['r_clock'] : 0)))
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/frontends/php/.htaccess xe-rabbix/frontends/php/.htaccess
--- zabbix-4.0.1/frontends/php/.htaccess	1970-01-01 05:00:00.000000000 +0500
+++ xe-rabbix/frontends/php/.htaccess	2018-08-15 16:23:16.000000000 +0500
@@ -0,0 +1,17 @@
+<FilesMatch "\.sql$">
+        Deny from all
+</FilesMatch>
+
+<FilesMatch "\.svn$">
+        Deny from all
+</FilesMatch>
+
+<FilesMatch "\.css$">
+        Allow from all
+</FilesMatch>
+
+AuthType Basic
+AuthName  "Zabbix Monitoring Tool (Graphs)"
+AuthBasicProvider pam
+AuthnPAMService httpd
+Require valid-user
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/frontends/php/include/classes/api/managers/CHistoryManager.php xe-rabbix/frontends/php/include/classes/api/managers/CHistoryManager.php
--- zabbix-4.0.1/frontends/php/include/classes/api/managers/CHistoryManager.php	2018-10-29 22:36:02.000000000 +0500
+++ xe-rabbix/frontends/php/include/classes/api/managers/CHistoryManager.php	2019-03-03 12:32:00.817412981 +0500
@@ -34,10 +34,15 @@
 	 * @return array    an array with items IDs as keys and arrays of history objects as values
 	 */
 	public function getLastValues(array $items, $limit = 1, $period = null) {
+
 		$results = [];
 		$grouped_items = self::getItemsGroupedByStorage($items);
 
-		if (array_key_exists(ZBX_HISTORY_SOURCE_ELASTIC, $grouped_items)) {
+		if (array_key_exists(ZBX_HISTORY_SOURCE_CLICKHOUSE, $grouped_items)) {
+			$results += $this->getLastValuesFromClickHouse($grouped_items[ZBX_HISTORY_SOURCE_CLICKHOUSE], $limit,
+					$period
+			);
+		} else if (array_key_exists(ZBX_HISTORY_SOURCE_ELASTIC, $grouped_items)) {
 			$results += $this->getLastValuesFromElasticsearch($grouped_items[ZBX_HISTORY_SOURCE_ELASTIC], $limit,
 					$period
 			);
@@ -55,6 +60,164 @@
 	 *
 	 * @see CHistoryManager::getLastValues
 	 */
+
+	/**
+	 * Clickhouse implementation of getLastValues.
+	 *
+	 */
+
+
+private function getLastValuesFromClickhouse($items, $limit, $period) {
+
+	global $HISTORY;
+	$results = [];
+	$itemslist='';
+
+	
+	foreach ($items as $item) {
+	    if (strlen($itemslist)>0) {
+	        $itemslist.=','.$item['itemid'];
+    	    } else {
+	        $itemslist.=$item['itemid'];
+		}
+	} 
+
+
+	$query_text='
+		SELECT 
+		    itemid, 
+		    max(toInt32(clock)) AS clk, 
+		    argMax(ns, toInt32(clock)) AS ns_, 
+		    argMax(value, toInt32(clock)) AS val, 
+		    argMax(value_dbl, toInt32(clock)) AS val_dbl, 
+		    argMax(value_str, toInt32(clock)) AS val_str' .
+	' FROM '.$HISTORY['tablename'].' h'.
+	' WHERE h.itemid in ( '.$itemslist.')'.
+	($period ? ' AND h.clock>'.(time() - $period) : '').
+	' GROUP BY itemid';
+
+        $values = CClickHouseHelper::query($query_text,1,array('itemid','clock','ns','value','value_dbl','value_str'));
+
+	foreach ($values as $res) 
+	{
+		$itemid=$res['itemid'];
+
+		//i know this is shit code, but it works much better then 
+		//checking for item type for some reason (see it celow)
+		$res['value']=floatval($res['value_dbl'])+intval($res['value']);		
+		if (strlen($res['value_str']>0)) $res['value']=$res['value_str'];
+
+		if (empty($results[$itemid])) 
+		    {
+			$results[$itemid]=[$res];
+		    }
+	}
+
+//	foreach ($items as $item) {
+//	    if ( !empty($results[$item['itemid']])) {
+//	    	if ($item['value_type'] ==  ITEM_VALUE_TYPE_FLOAT && !empty($results[$item['itemid']]['value_dbl'])) {
+//		    $results[$item['itemid']]['value']=$results[$item['itemid']]['value_dbl'];
+//	        }
+//		if ($item['value_type'] ==  ITEM_VALUE_TYPE_STR) {
+//		    $results[$item['itemid']]['value']=$results[$item['itemid']]['value_str'];
+//		}
+//	    }
+//	    
+//	}
+
+	return $results;
+
+//	foreach ($items as $item) {
+//	    if ($item['value_type'] ==  ITEM_VALUE_TYPE_FLOAT) {
+//    		if (strlen($float_itemslist)>0) {
+//		        $float_itemslist.=','.$item['itemid'];
+//    		} else {
+//		    $float_itemslist.=$item['itemid'];
+//		}
+//	    } else if ($item['value_type'] ==  ITEM_VALUE_TYPE_UINT64) {
+//		if (strlen($uint_itemslist)>0) {
+//		        $uint_itemslist.=','.$item['itemid'];
+//    		} else {
+//		    $uint_itemslist.=$item['itemid'];
+//		}
+//	    } else {
+//		if (strlen($str_itemslist)>0) {
+//		        $str_itemslist.=','.$item['itemid'];
+//    		} else {
+//		    $str_itemslist.=$item['itemid'];
+//		}
+//	    }
+//	}
+
+//	var_dump($itemslist);
+	
+//	$query_text='SELECT itemid, toInt32(clock) as clk,ns,value,value_dbl,value_str as value'.
+//	' FROM '.$HISTORY['tablename'].' h'.
+//	' WHERE h.itemid in ( '.$itemslist.')'.
+//	($period ? ' AND h.clock>'.(time() - $period) : '').
+//	' ORDER BY clk DESC';
+
+
+//	$query_text.=' UNION ALL SELECT itemid, toInt32(clock) as clk,ns,value as value'.
+//	' FROM '.$HISTORY['tablename'].' h'.
+//	' WHERE h.itemid in ( '.$uint_itemslist.')'.
+//	($period ? ' AND h.clock>'.(time() - $period) : '').
+//	' ORDER BY clk DESC';
+//
+//	$query_text.=' UNION ALL SELECT itemid, toInt32(clock) as clk,ns,value_str as value'.
+//	' FROM '.$HISTORY['tablename'].' h'.
+//	' WHERE h.itemid in ( '.$str_itemslist.')'.
+//	($period ? ' AND h.clock>'.(time() - $period) : '').
+//	' ORDER BY clk DESC';
+
+//	var_dump($query_text);
+    
+//        $values = CClickHouseHelper::query($query_text,1,array('itemid','clock','ns','value','value_dbl','value_str'));
+
+//var_dump($values);
+
+/*
+	foreach ($items as $item) {
+	    if ($item['value_type'] ==  ITEM_VALUE_TYPE_FLOAT) {
+		$query_text=	'SELECT itemid, toInt32(clock),ns,value_dbl'.
+		    ' FROM '.$HISTORY['tablename'].' h'.
+		    ' WHERE h.itemid= '.$item['itemid'].
+		    ($period ? ' AND h.clock>'.(time() - $period) : '').
+		    ' ORDER BY h.clock DESC';
+	    }
+
+	    if ($item['value_type'] ==  ITEM_VALUE_TYPE_UINT64) {
+		$query_text=	'SELECT itemid, toInt32(clock) as clock,ns,value'.
+		    ' FROM '.$HISTORY['tablename'].' h'.
+		    ' WHERE h.itemid= '.$item['itemid']. 
+		    ($period ? ' AND h.clock>'.(time() - $period) : '').
+		    ' ORDER BY h.clock DESC';
+	    }
+
+	    if ($item['value_type'] ==  ITEM_VALUE_TYPE_STR || $item['value_type'] ==  ITEM_VALUE_TYPE_TEXT ) {
+		$query_text=	'SELECT itemid, toInt32(clock) as clock,ns,value_str'.
+		    ' FROM '.$HISTORY['tablename'].' h'.
+		    ' WHERE h.itemid= '.$item['itemid']. 
+		    ($period ? ' AND h.clock>'.(time() - $period) : '').
+		    ' ORDER BY h.clock DESC';
+	    }
+
+	    if ($limit > 0) $query_text.=" LIMIT $limit";
+	    
+	    $values = CClickHouseHelper::query($query_text,1,array('itemid','clock','ns','value'));
+
+//	    var_dump($values);
+	    if ($values) {
+		$results[$item['itemid']] = $values;
+	    } else {
+//			    error("Got empty array, ommiting the result");
+	    }
+	}
+
+	return $results;
+*/
+    }
+
 	private function getLastValuesFromElasticsearch($items, $limit, $period) {
 		$terms = [];
 		$results = [];
@@ -137,6 +300,7 @@
 	 *
 	 * @see CHistoryManager::getLastValues
 	 */
+
 	private function getLastValuesFromSql($items, $limit, $period) {
 		$results = [];
 
@@ -171,6 +335,7 @@
 	 * @return array    history value aggregation for graphs
 	 */
 	public function getGraphAggregation(array $items, $time_from, $time_to, $width = null) {
+//		error("Hello wold");
 		if ($width !== null) {
 			$size = $time_to - $time_from;
 			$delta = $size - $time_from % $size;
@@ -183,7 +348,13 @@
 		$grouped_items = self::getItemsGroupedByStorage($items);
 
 		$results = [];
-		if (array_key_exists(ZBX_HISTORY_SOURCE_ELASTIC, $grouped_items)) {
+
+
+		if (array_key_exists(ZBX_HISTORY_SOURCE_CLICKHOUSE, $grouped_items)) {
+			$results += $this->getGraphAggregationFromClickhouse($grouped_items[ZBX_HISTORY_SOURCE_CLICKHOUSE],
+					$time_from, $time_to, $width, $size, $delta
+			);
+		} else if (array_key_exists(ZBX_HISTORY_SOURCE_ELASTIC, $grouped_items)) {
 			$results += $this->getGraphAggregationFromElasticsearch($grouped_items[ZBX_HISTORY_SOURCE_ELASTIC],
 					$time_from, $time_to, $width, $size, $delta
 			);
@@ -203,6 +374,62 @@
 	 *
 	 * @see CHistoryManager::getGraphAggregation
 	 */
+	private function getGraphAggregationFromClickhouse(array $items, $time_from, $time_to, $width, $size, $delta) {
+
+		global $HISTORY;
+		$group_by = 'itemid';
+		$sql_select_extra = '';
+
+		if ($width !== null && $size !== null && $delta !== null) {
+			// Required for 'group by' support of Oracle.
+			$calc_field = 'round('.$width.'*'.'modulo(toUInt32(clock)'.'+'.$delta.",$size)".'/('.$size.'),0)';
+
+			$sql_select_extra = ','.$calc_field.' AS i';
+			$group_by .= ','.$calc_field;
+		}
+
+		$results = [];
+
+		foreach ($items as $item) {
+			if ($item['value_type'] == ITEM_VALUE_TYPE_UINT64) {
+				$sql_select = 'COUNT(*) AS count,AVG(value) AS avg,MIN(value) AS min,MAX(value) AS max';
+			} else
+			{
+				$sql_select = 'COUNT(*) AS count,AVG(value_dbl) AS avg,MIN(value_dbl) AS min,MAX(value_dbl) AS max';
+			}
+			$daystart=date('Y-m-d',$time_from);
+			$dayend=date('Y-m-d',$time_to);
+			
+			$query_text = 
+				'SELECT itemid,'.$sql_select.$sql_select_extra.',MAX(toUInt32(clock)) AS clock1'.
+				' FROM '. $HISTORY['tablename'] .
+				' WHERE itemid='.$item['itemid'].
+					' AND day >= \''.$daystart. '\''.
+					' AND day <= \''. $dayend. '\''.	 
+					' AND toUInt32(clock)>='.$time_from.
+					' AND toUInt32(clock)<='.$time_to.
+				' GROUP BY '.$group_by ;
+
+//			file_put_contents('/var/log/nginx/chartlog.log', "Will do query '$new_query_text' \n",FILE_APPEND);
+
+
+			$values = CClickHouseHelper::query($query_text,1,array('itemid','count','avg','min','max','i','clock'));
+
+			$results[$item['itemid']]['source'] = 'history';
+			$results[$item['itemid']]['data'] = $values;
+		}
+
+//	    ob_start();
+//	    var_dump($results);
+//	    $dresult = ob_get_clean();
+//	    error("Dump of the result is '$dresult'");
+
+//	    file_put_contents('/var/log/nginx/chartlog.log', "Clickhouse Results structure is $dresult' \n",FILE_APPEND);
+
+		return $results;
+
+	}
+
 	private function getGraphAggregationFromElasticsearch(array $items, $time_from, $time_to, $width, $size, $delta) {
 		$terms = [];
 
@@ -423,6 +650,8 @@
 	 */
 	public function getAggregatedValue(array $item, $aggregation, $time_from) {
 		switch (self::getDataSourceType($item['value_type'])) {
+			case ZBX_HISTORY_SOURCE_CLICKHOUSE:
+				return $this->getAggregatedValueFromClickhouse($item, $aggregation, $time_from);
 			case ZBX_HISTORY_SOURCE_ELASTIC:
 				return $this->getAggregatedValueFromElasticsearch($item, $aggregation, $time_from);
 
@@ -431,6 +660,24 @@
 		}
 	}
 
+	private function getAggregatedValueFromClickhouse(array $item, $aggregation, $time_from) {
+
+		global $HISTORY;
+		$query_text =
+			'SELECT '.$aggregation.'(value) AS value'.
+			' FROM '. $HISTORY['tablename'].
+			' WHERE clock>toDateTime('.$time_from.')'.
+			' AND itemid='.$item['itemid'].
+			' HAVING COUNT(*)>0';
+		
+
+		$value = CClickHouseHelper::query($query_text,0,array());
+
+		return $value;
+
+	}
+
+
 	/**
 	 * Elasticsearch specific implementation of getAggregatedValue.
 	 *
@@ -623,8 +870,12 @@
 			global $HISTORY;
 
 			if (is_array($HISTORY) && array_key_exists('types', $HISTORY) && is_array($HISTORY['types'])) {
-				$cache[$value_type] = in_array(self::getTypeNameByTypeId($value_type), $HISTORY['types'])
-						? ZBX_HISTORY_SOURCE_ELASTIC : ZBX_HISTORY_SOURCE_SQL;
+					if ($HISTORY['storagetype']=='clickhouse') 
+							$cache[$value_type] = in_array(self::getTypeNameByTypeId($value_type), $HISTORY['types'])
+								? ZBX_HISTORY_SOURCE_CLICKHOUSE : ZBX_HISTORY_SOURCE_SQL;
+					else 
+							$cache[$value_type] = in_array(self::getTypeNameByTypeId($value_type), $HISTORY['types'])
+								? ZBX_HISTORY_SOURCE_ELASTIC : ZBX_HISTORY_SOURCE_SQL;
 			}
 			else {
 				// SQL is a fallback data source.
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/frontends/php/include/classes/api/services/CHistory.php xe-rabbix/frontends/php/include/classes/api/services/CHistory.php
--- zabbix-4.0.1/frontends/php/include/classes/api/services/CHistory.php	2018-10-29 22:36:02.000000000 +0500
+++ xe-rabbix/frontends/php/include/classes/api/services/CHistory.php	2018-12-14 11:20:58.418477596 +0500
@@ -112,7 +112,10 @@
 		switch (CHistoryManager::getDataSourceType($options['history'])) {
 			case ZBX_HISTORY_SOURCE_ELASTIC:
 				return $this->getFromElasticsearch($options);
-
+				break;
+			case ZBX_HISTORY_SOURCE_CLICKHOUSE:
+				return $this->getFromClickHouse($options);
+				break;
 			default:
 				return $this->getFromSql($options);
 		}
@@ -239,6 +242,129 @@
 	}
 
 	/**
+	 * Clickhouse specific implementation of get.
+	 *
+	 * @see CHistory::get
+	 */
+	private function getFromClickHouse($options) {
+		global $HISTORY;
+		$result = [];
+		$sql_parts = [
+			'select'	=> ['history' => 'h.itemid'],
+			'from'		=> [],
+			'where'		=> [],
+			'group'		=> [],
+			'order'		=> [],
+			'limit'		=> null
+		];
+
+
+		$value_col='value';
+
+		if ($options['history']==ITEM_VALUE_TYPE_FLOAT) {
+		    $value_col='value_dbl';
+		}
+
+		if ($options['history']==ITEM_VALUE_TYPE_STR) {
+		    $value_col='value_str';
+		}
+
+
+		$table_name = $HISTORY['tablename'];
+
+		$sql_parts['from']['history'] = $table_name.' h';
+
+		// itemids
+		if ($options['itemids'] !== null) {
+			$sql_parts['where']['itemid'] = "h.itemid =". $options['itemids'][0];
+		}
+
+		// time_from
+		if ($options['time_from'] !== null) {
+			$sql_parts['where']['clock_from'] = 'h.clock>='.zbx_dbstr($options['time_from']);
+		}
+
+		// time_till
+		if ($options['time_till'] !== null) {
+			$sql_parts['where']['clock_till'] = 'h.clock<='.zbx_dbstr($options['time_till']);
+		}
+
+		// filter
+		if (is_array($options['filter'])) {
+			$this->dbFilter($sql_parts['from']['history'], $options, $sql_parts);
+		}
+
+		// search
+		if (is_array($options['search'])) {
+			zbx_db_search($sql_parts['from']['history'], $options, $sql_parts);
+		}
+
+		// output
+		if ($options['output'] == API_OUTPUT_EXTEND) {
+			unset($sql_parts['select']['clock']);
+			$sql_parts['select']['history'] = 'h.*';
+		}
+
+		// countOutput
+		if ($options['countOutput']) {
+			$options['sortfield'] = '';
+			$sql_parts['select'] = ['count(DISTINCT h.hostid) as rowscount'];
+
+			// groupCount
+			if ($options['groupCount']) {
+				foreach ($sql_parts['group'] as $key => $fields) {
+					$sql_parts['select'][$key] = $fields;
+				}
+			}
+		}
+
+		// sorting
+		$sql_parts = $this->applyQuerySortOptions($table_name, $this->tableAlias(), $options, $sql_parts);
+
+		// limit
+		if (zbx_ctype_digit($options['limit']) && $options['limit']) {
+			$sql_parts['limit'] = $options['limit'];
+		}
+
+		$sql_parts['select'] = array_unique($sql_parts['select']);
+		$sql_parts['from'] = array_unique($sql_parts['from']);
+		$sql_parts['where'] = array_unique($sql_parts['where']);
+		$sql_parts['order'] = array_unique($sql_parts['order']);
+
+		$sql_select = '';
+		$sql_from = '';
+		$sql_order = '';
+
+		if ($sql_parts['select']) {
+			$sql_select .= implode(',', $sql_parts['select']);
+		}
+
+		if ($sql_parts['from']) {
+			$sql_from .= implode(',', $sql_parts['from']);
+		}
+
+		$sql_where = $sql_parts['where'] ? ' WHERE '.implode(' AND ', $sql_parts['where']) : '';
+
+		if ($sql_parts['order']) {
+			$sql_order .= ' ORDER BY '.implode(',', $sql_parts['order']);
+		}
+
+		$sql_limit = $sql_parts['limit'];
+		$sql = "SELECT itemid, toInt32(clock), ns, $value_col".
+				' FROM '.$sql_from.
+				$sql_where.
+				$sql_order;
+
+		var_dump($sql);
+		$values = CClickHouseHelper::query($sql,1,array('itemid','clock','ns', 'value'));
+
+
+//		error("Will exec sql $sql");
+
+		return $values;
+	}
+
+	/**
 	 * Elasticsearch specific implementation of get.
 	 *
 	 * @see CHistory::get
@@ -315,4 +441,5 @@
 
 		return null;
 	}
+
 }
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/frontends/php/include/classes/helpers/CClickHouseHelper.php xe-rabbix/frontends/php/include/classes/helpers/CClickHouseHelper.php
--- zabbix-4.0.1/frontends/php/include/classes/helpers/CClickHouseHelper.php	1970-01-01 05:00:00.000000000 +0500
+++ xe-rabbix/frontends/php/include/classes/helpers/CClickHouseHelper.php	2018-12-14 11:20:58.418477596 +0500
@@ -0,0 +1,99 @@
+<?php
+
+/*
+ * A helper class for working with ClickHouse database
+ */
+class CClickHouseHelper {
+
+	/**
+	 * Perform request(s) to Elasticsearch and parse the results.
+	 *
+	 * @param string $method      HTTP method to be used to perform request
+	 * @param string $endpoint    requested url
+	 * @param mixed  $request     data to be sent
+	 *
+	 * @return array    parsed result
+	 */
+	public static function query($request,$is_table_result,$columns) {
+		
+		global $HISTORY;
+//		error("CClikHouseHelper.query($request) ");
+		$ch = curl_init();
+
+		curl_setopt($ch, CURLOPT_URL,$HISTORY['url']['uint']);
+		curl_setopt($ch, CURLOPT_POST, 1);
+		curl_setopt($ch, CURLOPT_POSTFIELDS,$request);
+
+		// receive server response ...
+		curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
+
+		$server_output = curl_exec ($ch);
+		curl_close ($ch);
+
+//		error("Clickhouse returned '$server_output'");
+
+//		ob_start();
+//    		var_dump($request);
+//    		var_dump($server_output);
+
+//		$dresult = ob_get_clean();
+//	    error("Dump of the result is '$dresult'");
+
+//		file_put_contents('/var/log/nginx/clickhouse.log', "Clickhouse Results structure is $dresult' \n",FILE_APPEND);
+
+
+
+		return self::parseResult($server_output,$is_table_result,$columns);
+		
+	}
+
+	/**
+	 * Parse result and return two dimentional array of the result
+	 *
+	 * @param string $data        result as a string
+	 *
+	 * @return array    parsed result  two dimentional array of the result
+	 */
+	private static function parseResult($data,$is_table_result,$columns) {
+
+	    //to make processing simpler, lets distinguish results of two types - table (two dimensional array as result
+	    //returned or SINGLE, when one value (a number, probably) 
+	    if ($is_table_result) 
+	    {
+		$result=[];
+
+		$lines = explode("\n", $data);
+		$curline=0;
+
+		foreach ($lines as $line) {
+		    if (strlen(str_replace("\n",'',$line) ) > 0) 
+		    { 
+//			error("Processing line '$line'");
+//			error("Columns count is ".count($columns)." field count is ".count(explode("\t",$line)));
+			$result[$curline]=array_combine($columns,explode("\t",$line));
+			$curline++;
+
+		    } else {
+//			error("Got empty line, skipping");
+		    }
+		}
+
+	    } else
+	    {
+		//single result is here, stripping tabs,spaces and newlines
+		$result=str_replace(array("\r", "\n","\t"), '', $data);
+	    }
+
+/*	    ob_start();
+	    var_dump($result);
+	    $dresult = ob_get_clean();
+	    error("Dump of the result is '$dresult'");
+*/
+	    return $result;
+	}
+
+
+}
+
+
+
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/frontends/php/include/classes/macros/CMacrosResolverGeneral.php xe-rabbix/frontends/php/include/classes/macros/CMacrosResolverGeneral.php
--- zabbix-4.0.1/frontends/php/include/classes/macros/CMacrosResolverGeneral.php	2018-10-29 22:36:02.000000000 +0500
+++ xe-rabbix/frontends/php/include/classes/macros/CMacrosResolverGeneral.php	2018-11-13 11:11:53.000000000 +0500
@@ -772,7 +772,7 @@
 		}
 
 		$result = DBselect(
-			'SELECT f.triggerid,f.functionid,h.hostid,h.host,h.name'.
+			'SELECT f.triggerid,f.functionid,h.hostid,h.host,h.name,h.description'.
 			' FROM functions f'.
 				' JOIN items i ON f.itemid=i.itemid'.
 				' JOIN hosts h ON i.hostid=h.hostid'.
@@ -781,6 +781,7 @@
 
 		while ($row = DBfetch($result)) {
 			foreach ($macros[$row['functionid']] as $macro => $tokens) {
+				//var_dump($row);
 				switch ($macro) {
 					case 'HOST.ID':
 						$value = $row['hostid'];
@@ -794,6 +795,10 @@
 					case 'HOST.NAME':
 						$value = $row['name'];
 						break;
+					case 'HOST.DESCRIPTION1':
+						$value = $row['description'];
+						break;
+
 				}
 
 				foreach ($tokens as $token) {
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/frontends/php/include/classes/macros/CMacrosResolver.php xe-rabbix/frontends/php/include/classes/macros/CMacrosResolver.php
--- zabbix-4.0.1/frontends/php/include/classes/macros/CMacrosResolver.php	2018-10-29 22:36:02.000000000 +0500
+++ xe-rabbix/frontends/php/include/classes/macros/CMacrosResolver.php	2018-11-13 11:11:53.000000000 +0500
@@ -331,7 +331,7 @@
 
 		$types = [
 			'macros_n' => [
-				'host' => ['{HOSTNAME}', '{HOST.HOST}', '{HOST.NAME}'],
+				'host' => ['{HOSTNAME}', '{HOST.HOST}', '{HOST.NAME}', '{HOST.DESCRIPTION1}'],
 				'interface' => ['{IPADDRESS}', '{HOST.IP}', '{HOST.DNS}', '{HOST.CONN}', '{HOST.PORT}'],
 				'item' => ['{ITEM.LASTVALUE}', '{ITEM.VALUE}']
 			],
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/frontends/php/include/defines.inc.php xe-rabbix/frontends/php/include/defines.inc.php
--- zabbix-4.0.1/frontends/php/include/defines.inc.php	2018-10-29 22:36:02.000000000 +0500
+++ xe-rabbix/frontends/php/include/defines.inc.php	2018-11-13 11:11:53.000000000 +0500
@@ -50,8 +50,10 @@
 
 // the maximum period to display history data for the latest data and item overview pages in seconds
 // by default set to 86400 seconds (24 hours)
-define('ZBX_HISTORY_PERIOD', 86400);
+define('ZBX_HISTORY_PERIOD', 7200);
 
+
+define('ZBX_HISTORY_SOURCE_CLICKHOUSE',	'clickhouse');
 define('ZBX_HISTORY_SOURCE_ELASTIC',	'elastic');
 define('ZBX_HISTORY_SOURCE_SQL',		'sql');
 
@@ -59,7 +61,7 @@
 define('ELASTICSEARCH_RESPONSE_AGGREGATION',	1);
 define('ELASTICSEARCH_RESPONSE_DOCUMENTS',		2);
 
-define('ZBX_WIDGET_ROWS', 20);
+define('ZBX_WIDGET_ROWS', 2000);
 
 define('ZBX_FONTPATH',				realpath('fonts')); // where to search for font (GD > 2.0.18)
 define('ZBX_GRAPH_FONT_NAME',		'DejaVuSans'); // font file name
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/frontends/php/include/hosts.inc.php xe-rabbix/frontends/php/include/hosts.inc.php
--- zabbix-4.0.1/frontends/php/include/hosts.inc.php	2018-10-29 22:36:02.000000000 +0500
+++ xe-rabbix/frontends/php/include/hosts.inc.php	2019-01-10 09:50:00.000000000 +0500
@@ -538,7 +538,6 @@
 
 	$hostIds = [];
 	$oldStatus = ($status == HOST_STATUS_MONITORED ? HOST_STATUS_NOT_MONITORED : HOST_STATUS_MONITORED);
-
 	$db_hosts = DBselect(
 		'SELECT h.hostid,h.host,h.status'.
 		' FROM hosts h'.
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/include/common.h xe-rabbix/include/common.h
--- zabbix-4.0.1/include/common.h	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/include/common.h	2018-12-14 11:20:58.418477596 +0500
@@ -87,6 +87,7 @@
 #define	AGENT_ERROR	-5
 #define	GATEWAY_ERROR	-6
 #define	CONFIG_ERROR	-7
+#define	NOT_PROCESSED	-8
 
 #define SUCCEED_OR_FAIL(result) (FAIL != (result) ? SUCCEED : FAIL)
 const char	*zbx_sysinfo_ret_string(int ret);
@@ -538,7 +539,9 @@
 #define ZBX_PROCESS_TYPE_ALERTMANAGER	25
 #define ZBX_PROCESS_TYPE_PREPROCMAN	26
 #define ZBX_PROCESS_TYPE_PREPROCESSOR	27
-#define ZBX_PROCESS_TYPE_COUNT		28	/* number of process types */
+#define ZBX_PROCESS_TYPE_ASYNC_SNMP	28
+#define ZBX_PROCESS_TYPE_ASYNC_AGENT	29
+#define ZBX_PROCESS_TYPE_COUNT		30	/* number of process types */
 #define ZBX_PROCESS_TYPE_UNKNOWN	255
 const char	*get_process_type_string(unsigned char process_type);
 int		get_process_type_by_name(const char *proc_type_str);
@@ -1524,5 +1527,8 @@
 #define ZBX_PROBLEM_SUPPRESSED_FALSE	0
 #define ZBX_PROBLEM_SUPPRESSED_TRUE	1
 
+#define ZBX_MIN_OPEN_FILES	16384
+#define ZBX_DESIRED_OPEN_FILES 65536
+
 #endif
 
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/include/dbcache.h xe-rabbix/include/dbcache.h
--- zabbix-4.0.1/include/dbcache.h	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/include/dbcache.h	2018-12-16 15:14:17.063936852 +0500
@@ -34,12 +34,17 @@
 #define	ZBX_POLLER_TYPE_IPMI		2
 #define	ZBX_POLLER_TYPE_PINGER		3
 #define	ZBX_POLLER_TYPE_JAVA		4
-#define	ZBX_POLLER_TYPE_COUNT		5	/* number of poller types */
+#define	ZBX_POLLER_TYPE_ASYNC_SNMP		5
+#define	ZBX_POLLER_TYPE_ASYNC_AGENT		6
+#define	ZBX_POLLER_TYPE_COUNT		7	/* number of poller types */
 
 #define MAX_JAVA_ITEMS		32
 #define MAX_SNMP_ITEMS		128
 #define MAX_POLLER_ITEMS	128	/* MAX(MAX_JAVA_ITEMS, MAX_SNMP_ITEMS) */
-#define MAX_PINGER_ITEMS	128
+#define MAX_PINGER_ITEMS	4096
+#define MAX_UNREACH_ITEMS		64 //we don't want this to be too big, but it's better for efficiency if thats more then one item 
+#define MAX_ASYNC_SNMP_ITEMS		512
+#define MAX_ASYNC_AGENT_ITEMS		4096
 
 #define ZBX_TRIGGER_DEPENDENCY_LEVELS_MAX	32
 
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/include/zbxjson.h xe-rabbix/include/zbxjson.h
--- zabbix-4.0.1/include/zbxjson.h	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/include/zbxjson.h	2018-12-14 11:20:58.418477596 +0500
@@ -117,6 +117,7 @@
 #define ZBX_PROTO_VALUE_JAVA_GATEWAY_JMX	"java gateway jmx"
 #define ZBX_PROTO_VALUE_GET_QUEUE		"queue.get"
 #define ZBX_PROTO_VALUE_GET_STATUS		"status.get"
+#define ZBX_PROTO_VALUE_GET_PROBLEMS	"problems.get"
 #define ZBX_PROTO_VALUE_PROXY_DATA		"proxy data"
 #define ZBX_PROTO_VALUE_PROXY_TASKS		"proxy tasks"
 
@@ -146,6 +147,7 @@
 zbx_json_status_t;
 
 #define ZBX_JSON_STAT_BUF_LEN 4096
+#define ZBX_JSON_PROBLEMS_BUF_LEN 51200000
 
 struct zbx_json
 {
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/libs/zbxcommon/str.c xe-rabbix/src/libs/zbxcommon/str.c
--- zabbix-4.0.1/src/libs/zbxcommon/str.c	2018-10-29 22:36:01.000000000 +0500
+++ xe-rabbix/src/libs/zbxcommon/str.c	2018-12-14 11:20:58.418477596 +0500
@@ -1159,6 +1159,10 @@
 	{
 		case ZBX_PROCESS_TYPE_POLLER:
 			return "poller";
+		case ZBX_PROCESS_TYPE_ASYNC_SNMP:
+			return "async snmp poller";
+		case ZBX_PROCESS_TYPE_ASYNC_AGENT:
+			return "async agent poller";
 		case ZBX_PROCESS_TYPE_UNREACHABLE:
 			return "unreachable poller";
 		case ZBX_PROCESS_TYPE_IPMIPOLLER:
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/libs/zbxdbcache/dbconfig.c xe-rabbix/src/libs/zbxdbcache/dbconfig.c
--- zabbix-4.0.1/src/libs/zbxdbcache/dbconfig.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/libs/zbxdbcache/dbconfig.c	2018-12-14 11:20:58.418477596 +0500
@@ -90,6 +90,8 @@
 
 extern unsigned char	program_type;
 extern int		CONFIG_TIMER_FORKS;
+extern int CONFIG_ASYNC_AGENT_POLLER_FORKS;
+extern int CONFIG_ASYNC_SNMP_POLLER_FORKS;
 
 ZBX_MEM_FUNC_IMPL(__config, config_mem)
 
@@ -187,7 +189,7 @@
 	return ret;
 }
 
-static unsigned char	poller_by_item(unsigned char type, const char *key)
+static unsigned char	poller_by_item(unsigned char type, const char *key, zbx_uint64_t itemid)
 {
 	switch (type)
 	{
@@ -202,10 +204,7 @@
 				return ZBX_POLLER_TYPE_PINGER;
 			}
 			/* break; is not missing here */
-		case ITEM_TYPE_ZABBIX:
-		case ITEM_TYPE_SNMPv1:
-		case ITEM_TYPE_SNMPv2c:
-		case ITEM_TYPE_SNMPv3:
+
 		case ITEM_TYPE_INTERNAL:
 		case ITEM_TYPE_AGGREGATE:
 		case ITEM_TYPE_EXTERNAL:
@@ -218,6 +217,44 @@
 				break;
 
 			return ZBX_POLLER_TYPE_NORMAL;
+		
+		case ITEM_TYPE_ZABBIX:
+			if (0 == CONFIG_ASYNC_AGENT_POLLER_FORKS ){
+				if (0 == CONFIG_POLLER_FORKS)
+					break;
+
+				return ZBX_POLLER_TYPE_NORMAL;
+			}
+			return ZBX_POLLER_TYPE_ASYNC_AGENT;
+
+		case ITEM_TYPE_SNMPv1:
+		case ITEM_TYPE_SNMPv2c:
+		case ITEM_TYPE_SNMPv3:
+			if (0 == CONFIG_ASYNC_SNMP_POLLER_FORKS ){
+				if (0 == CONFIG_POLLER_FORKS)
+					break;
+
+				return ZBX_POLLER_TYPE_NORMAL;
+			} else {
+				ZBX_DC_SNMPITEM *snmpitem;
+
+				//need to see if this statical oid snmp item or a dynamic one
+				snmpitem = (ZBX_DC_SNMPITEM *)zbx_hashset_search(&config->snmpitems, &itemid);
+				if (NULL == snmpitem ) 
+						return ZBX_POLLER_TYPE_NORMAL;
+
+				
+
+				if ( 0 == strncmp(snmpitem->snmp_oid, "discovery[", 10) || 
+						NULL != strchr(snmpitem->snmp_oid, '[') )
+				{
+					zabbix_log(LOG_LEVEL_DEBUG,"Selecting normal poller for dynamic item snmp  %s",snmpitem->snmp_oid);
+					return ZBX_POLLER_TYPE_NORMAL;
+				} else {
+					return ZBX_POLLER_TYPE_ASYNC_SNMP;
+				}
+			}
+
 		case ITEM_TYPE_IPMI:
 			if (0 == CONFIG_IPMIPOLLER_FORKS)
 				break;
@@ -400,7 +437,7 @@
 		return;
 	}
 
-	poller_type = poller_by_item(dc_item->type, dc_item->key);
+	poller_type = poller_by_item(dc_item->type, dc_item->key, dc_item->itemid);
 
 	if (0 != (flags & ZBX_HOST_UNREACHABLE))
 	{
@@ -5651,6 +5688,8 @@
 	CREATE_HASHSET(config->corr_conditions, 0);
 	CREATE_HASHSET(config->corr_operations, 0);
 	CREATE_HASHSET(config->hostgroups, 0);
+	CREATE_HASHSET(config->problems, 0);
+
 	zbx_vector_ptr_create_ext(&config->hostgroups_name, __config_mem_malloc_func, __config_mem_realloc_func,
 			__config_mem_free_func);
 
@@ -7602,6 +7641,18 @@
 		case ZBX_POLLER_TYPE_PINGER:
 			max_items = MAX_PINGER_ITEMS;
 			break;
+		case ZBX_POLLER_TYPE_NORMAL:
+			max_items = 1;
+			break;
+		case ZBX_POLLER_TYPE_ASYNC_SNMP:
+			max_items = MAX_ASYNC_SNMP_ITEMS;
+			break;
+		case ZBX_POLLER_TYPE_UNREACHABLE:
+			max_items = MAX_UNREACH_ITEMS;
+			break;
+		case ZBX_POLLER_TYPE_ASYNC_AGENT:
+			max_items = MAX_ASYNC_AGENT_ITEMS;
+			break;
 		default:
 			max_items = 1;
 	}
@@ -7619,22 +7670,18 @@
 		min = zbx_binary_heap_find_min(queue);
 		dc_item = (ZBX_DC_ITEM *)min->data;
 
+
 		if (dc_item->nextcheck > now)
 			break;
-
-		if (0 != num)
-		{
-			if (SUCCEED == is_snmp_type(dc_item_prev->type))
-			{
-				if (0 != __config_snmp_item_compare(dc_item_prev, dc_item))
-					break;
-			}
-			else if (ITEM_TYPE_JMX == dc_item_prev->type)
-			{
-				if (0 != __config_java_item_compare(dc_item_prev, dc_item))
-					break;
-			}
-		}
+		
+		if ( (0 != num) && 	( ZBX_POLLER_TYPE_NORMAL == poller_type ) && (SUCCEED == is_snmp_type(dc_item_prev->type))
+					 && (0 != __config_snmp_item_compare(dc_item_prev, dc_item)) )
+			break;
+		
+		
+		if ( (0 != num) && 	( ZBX_POLLER_TYPE_JAVA == poller_type )	&& (ITEM_TYPE_JMX == dc_item_prev->type) && 
+				(0 != __config_java_item_compare(dc_item_prev, dc_item)) )
+			break;
 
 		zbx_binary_heap_remove_min(queue);
 		dc_item->location = ZBX_LOC_NOWHERE;
@@ -7652,34 +7699,41 @@
 		}
 
 		/* don't apply unreachable item/host throttling for prioritized items */
-		if (ZBX_QUEUE_PRIORITY_HIGH != dc_item->queue_priority)
-		{
-			if (0 == (disable_until = DCget_disable_until(dc_item, dc_host)))
-			{
-				/* move reachable items on reachable hosts to normal pollers */
-				if (ZBX_POLLER_TYPE_UNREACHABLE == poller_type &&
-						ZBX_QUEUE_PRIORITY_LOW != dc_item->queue_priority)
-				{
-					dc_requeue_item(dc_item, dc_host, dc_item->state, ZBX_ITEM_COLLECTED, now);
-					continue;
-				}
-			}
-			else
-			{
-				/* move items on unreachable hosts to unreachable pollers or    */
-				/* postpone checks on hosts that have been checked recently and */
-				/* are still unreachable                                        */
-				if (ZBX_POLLER_TYPE_NORMAL == poller_type || ZBX_POLLER_TYPE_JAVA == poller_type ||
-						disable_until > now)
-				{
-					dc_requeue_item(dc_item, dc_host, dc_item->state,
-							ZBX_ITEM_COLLECTED | ZBX_HOST_UNREACHABLE, now);
-					continue;
-				}
-
-				DCincrease_disable_until(dc_item, dc_host, now);
-			}
-		}
+		/* and for async and unreachable pollers */
+		
+		//in async polling model there is NO problems with checking whatever we want
+		//whenever we want, so no prioritization required at all
+		//in fact, there is even no reason to pause quering such an items
+		
+//		if (ZBX_QUEUE_PRIORITY_HIGH != dc_item->queue_priority && ZBX_POLLER_TYPE_ASYNC != poller_type 
+//										&& ZBX_POLLER_TYPE_UNREACHABLE != poller_type)
+//		{
+//			if (0 == (disable_until = DCget_disable_until(dc_item, dc_host)))
+//			{
+//				/* move reachable items on reachable hosts to normal pollers */
+//				if (ZBX_POLLER_TYPE_UNREACHABLE == poller_type &&
+//						ZBX_QUEUE_PRIORITY_LOW != dc_item->queue_priority)
+//				{
+//					dc_requeue_item(dc_item, dc_host, dc_item->state, ZBX_ITEM_COLLECTED, now);
+//					continue;
+//				}
+//			}
+//			else
+//			{
+//				/* move items on unreachable hosts to unreachable pollers or    */
+//				/* postpone checks on hosts that have been checked recently and */
+//				/* are still unreachable                                        */
+//				if (ZBX_POLLER_TYPE_NORMAL == poller_type || ZBX_POLLER_TYPE_JAVA == poller_type ||
+//						disable_until > now)
+//				{
+//					dc_requeue_item(dc_item, dc_host, dc_item->state,
+//							ZBX_ITEM_COLLECTED | ZBX_HOST_UNREACHABLE, now);
+//					continue;
+//				}
+//
+//				DCincrease_disable_until(dc_item, dc_host, now);
+//			}
+//		}
 
 		dc_item_prev = dc_item;
 		dc_item->location = ZBX_LOC_POLLER;
@@ -7687,21 +7741,22 @@
 		DCget_item(&items[num], dc_item);
 		num++;
 
-		if (1 == num && ZBX_POLLER_TYPE_NORMAL == poller_type && SUCCEED == is_snmp_type(dc_item->type) &&
-				0 == (ZBX_FLAG_DISCOVERY_RULE & dc_item->flags))
-		{
-			ZBX_DC_SNMPITEM	*snmpitem;
+		//the following code never works anyway as MAX_SNMP_ITEMS is one for regular pollers
 
-			snmpitem = (ZBX_DC_SNMPITEM *)zbx_hashset_search(&config->snmpitems, &dc_item->itemid);
-
-			if (ZBX_SNMP_OID_TYPE_NORMAL == snmpitem->snmp_oid_type ||
-					ZBX_SNMP_OID_TYPE_DYNAMIC == snmpitem->snmp_oid_type)
-			{
-				max_items = DCconfig_get_suggested_snmp_vars_nolock(dc_item->interfaceid, NULL);
-			}
-		}
+//		if (1 == num && ZBX_POLLER_TYPE_NORMAL == poller_type && SUCCEED == is_snmp_type(dc_item->type) &&
+//				0 == (ZBX_FLAG_DISCOVERY_RULE & dc_item->flags))
+//		{
+//			ZBX_DC_SNMPITEM	*snmpitem;
+//
+//			snmpitem = (ZBX_DC_SNMPITEM *)zbx_hashset_search(&config->snmpitems, &dc_item->itemid);
+//
+//			if (ZBX_SNMP_OID_TYPE_NORMAL == snmpitem->snmp_oid_type ||
+//					ZBX_SNMP_OID_TYPE_DYNAMIC == snmpitem->snmp_oid_type)
+//			{
+//				max_items = DCconfig_get_suggested_snmp_vars_nolock(dc_item->interfaceid, NULL);
+//			}
+//		}
 	}
-
 	UNLOCK_CACHE;
 
 	zabbix_log(LOG_LEVEL_DEBUG, "End of %s():%d", __function_name, num);
@@ -7954,6 +8009,7 @@
 				dc_requeue_item(dc_item, dc_host, states[i], ZBX_ITEM_COLLECTED, lastclocks[i]);
 				break;
 			case NETWORK_ERROR:
+			case NOT_PROCESSED:
 			case GATEWAY_ERROR:
 			case TIMEOUT_ERROR:
 				dc_item->queue_priority = ZBX_QUEUE_PRIORITY_LOW;
@@ -7961,11 +8017,48 @@
 						time(NULL));
 				break;
 			default:
+				zabbix_log(LOG_LEVEL_INFORMATION,"Unknown errcode: %d", errcodes[i]);
 				THIS_SHOULD_NEVER_HAPPEN;
 		}
 	}
 }
 
+static void	dc_requeue_async_items(const zbx_uint64_t *itemids, const unsigned char *states, const int *lastclocks,
+		const int *errcodes, size_t num)
+{
+	size_t		i;
+	ZBX_DC_ITEM	*dc_item;
+	ZBX_DC_HOST	*dc_host;
+
+	for (i = 0; i < num; i++)
+	{
+		if (FAIL == errcodes[i])
+			continue;
+
+		if (NULL == (dc_item = (ZBX_DC_ITEM *)zbx_hashset_search(&config->items, &itemids[i])))
+			continue;
+
+		if (ZBX_LOC_POLLER == dc_item->location)
+			dc_item->location = ZBX_LOC_NOWHERE;
+
+		if (ITEM_STATUS_ACTIVE != dc_item->status)
+			continue;
+
+		if (NULL == (dc_host = (ZBX_DC_HOST *)zbx_hashset_search(&config->hosts, &dc_item->hostid)))
+			continue;
+
+		if (HOST_STATUS_MONITORED != dc_host->status)
+			continue;
+
+		if (SUCCEED != is_counted_in_item_queue(dc_item->type, dc_item->key))
+			continue;
+
+		//whatever the other return codes, we want the item to be polled again
+		dc_requeue_item(dc_item, dc_host, states[i], ZBX_ITEM_COLLECTED, lastclocks[i]);
+	}
+}
+
+
 void	DCrequeue_items(const zbx_uint64_t *itemids, const unsigned char *states, const int *lastclocks,
 		const int *errcodes, size_t num)
 {
@@ -7980,13 +8073,17 @@
 		const int *errcodes, size_t num, unsigned char poller_type, int *nextcheck)
 {
 	WRLOCK_CACHE;
-
-	dc_requeue_items(itemids, states, lastclocks, errcodes, num);
+	if (ZBX_POLLER_TYPE_ASYNC_AGENT == poller_type || ZBX_POLLER_TYPE_ASYNC_SNMP == poller_type) {
+		dc_requeue_async_items(itemids, states, lastclocks, errcodes, num);	
+	} else {
+		dc_requeue_items(itemids, states, lastclocks, errcodes, num);
+	}
 	*nextcheck = dc_config_get_queue_nextcheck(&config->queues[poller_type]);
 
 	UNLOCK_CACHE;
 }
 
+
 /******************************************************************************
  *                                                                            *
  * Function: zbx_dc_requeue_unreachable_items                                 *
@@ -11774,3 +11871,112 @@
 
 	UNLOCK_CACHE;
 }
+
+/******************************************************************************
+ *                                                                            *
+ * Function: zbx_XXXXX_problems			                                      *
+ *                                                                            *
+ * Purpose: keep in the hashset existing (active) problems                    *
+ *                                                                            *
+ ******************************************************************************/
+void zbx_clean_problems()
+{
+	static int lastclean=0;
+	ZBX_DC_PROBLEM *problem=NULL;
+	unsigned int timenow, count=0;
+	zbx_hashset_iter_t problems_iter;
+
+	
+	if ((time(NULL)-lastclean)>ZBX_PROBLEM_CLEAN_RUN) {
+		zabbix_log(LOG_LEVEL_DEBUG,"Doing problems cleanout");
+		timenow=time(NULL);
+
+		zbx_hashset_iter_reset(&config->problems,&problems_iter);
+
+		while (NULL!=(problem=zbx_hashset_iter_next(&problems_iter))){
+
+			if  ( (ZBX_PROBLEM_CLOSED == problem->state && ( timenow - problem->lastupdate > ZBX_PROBLEM_CLOSED_TIMEOUT )) ||
+				 (timenow - problem->lastupdate > ZBX_PROBLEM_OPEN_TIMEOUT))
+				{
+					//problem is aged, removing
+					zabbix_log(LOG_LEVEL_DEBUG,"Cleaning problem %u",problem->eventid);
+					zbx_hashset_remove_direct(&config->problems,problem);
+
+					//zbx_free(problem);
+					count++;
+			} 
+			
+		}
+		lastclean=time(NULL);
+		zabbix_log(LOG_LEVEL_DEBUG,"Problems cleanup: cleaned %u problems, left %u",count,config->problems.num_data);
+	}
+}
+	
+
+void zbx_register_problem(zbx_uint64_t id, char *problem_text) 
+{
+	ZBX_DC_PROBLEM problem,*tmpproblem;
+
+	WRLOCK_CACHE;
+
+	if ( NULL == (tmpproblem = zbx_hashset_search(&config->problems,&id)))
+	{
+		zabbix_log(LOG_LEVEL_DEBUG,"Adding event %d",id);
+		problem.eventid=id;
+		zbx_strlcpy(problem.description,problem_text,511);
+		problem.lastupdate=time(NULL);
+		problem.state=ZBX_PROBLEM_OPEN;
+		zbx_hashset_insert(&config->problems,(const void*)&problem,sizeof(ZBX_DC_PROBLEM));
+
+	} else {
+		zabbix_log(LOG_LEVEL_DEBUG,"Updating event %d",id);
+		zbx_strlcpy(problem.description,problem_text,511);
+		problem.lastupdate=time(NULL);
+	}
+	//zabbix_log(LOG_LEVEL_INFORMATION,"problem registered");
+	zbx_clean_problems();
+	UNLOCK_CACHE;
+}
+
+void zbx_register_problem_recovery(zbx_uint64_t  id)  {
+	zabbix_log(LOG_LEVEL_DEBUG,"Problem %u recovery call",id);
+
+	ZBX_DC_PROBLEM *problem=NULL;
+	WRLOCK_CACHE;
+
+	problem=zbx_hashset_search(&config->problems,&id);
+
+	if (NULL != problem) {
+		zabbix_log(LOG_LEVEL_DEBUG,"Closing problem %u",id);
+		problem->state=ZBX_PROBLEM_CLOSED;
+		problem->lastupdate=time(NULL);
+	} else {
+		zabbix_log(LOG_LEVEL_DEBUG,"Problem %u not found",id);
+	}
+	//zabbix_log(LOG_LEVEL_INFORMATION,"problem recovery registered");
+	zbx_clean_problems();
+	UNLOCK_CACHE;
+}
+
+void zbx_dump_problems_to_json(struct zbx_json *json) {
+	
+	zbx_hashset_iter_t problems_iter;
+	ZBX_DC_PROBLEM *problem;
+
+	WRLOCK_CACHE;
+	zbx_json_addarray(json, "problems");	
+
+	zbx_hashset_iter_reset(&config->problems,&problems_iter);
+
+	while (NULL!=(problem=(ZBX_DC_PROBLEM*)zbx_hashset_iter_next(&problems_iter))){
+		if (ZBX_PROBLEM_CLOSED != problem->state) {
+			zbx_json_addobject(json, NULL);	
+			zbx_json_adduint64(json, "eventid", problem->eventid);
+			zbx_json_addraw(json, "eventdata", problem->description);
+			zbx_json_close(json);	
+		}
+	}
+
+	zbx_json_close(json);	
+	UNLOCK_CACHE;
+}
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/libs/zbxdbcache/dbconfig.h xe-rabbix/src/libs/zbxdbcache/dbconfig.h
--- zabbix-4.0.1/src/libs/zbxdbcache/dbconfig.h	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/libs/zbxdbcache/dbconfig.h	2018-12-14 11:20:58.418477596 +0500
@@ -760,9 +760,33 @@
 	ZBX_DC_CONFIG_TABLE	*config;
 	ZBX_DC_STATUS		*status;
 	zbx_hashset_t		strpool;
+	zbx_hashset_t		problems;
 }
 ZBX_DC_CONFIG;
 
+typedef struct
+{
+	zbx_uint64_t 	eventid;
+	char 			description[512];
+	unsigned int 	lastupdate;
+	unsigned int 	state;
+}
+ZBX_DC_PROBLEM;
+
+/* problem in memory cache-related defines */
+
+/* how often to run in memory problems cleanup */
+#define ZBX_PROBLEM_CLEAN_RUN 120 
+
+#define ZBX_PROBLEM_CLOSED	0
+#define ZBX_PROBLEM_OPEN	1
+
+/* delete problems from memory that's been there for more then 1 month */
+#define ZBX_PROBLEM_OPEN_TIMEOUT	30*86400
+/* and keep closed problems only for 1 hour */
+#define ZBX_PROBLEM_CLOSED_TIMEOUT	30
+
+
 extern int	sync_in_progress;
 extern ZBX_DC_CONFIG	*config;
 extern zbx_rwlock_t	config_lock;
@@ -818,11 +842,15 @@
 void	DCsync_maintenance_groups(zbx_dbsync_t *sync);
 void	DCsync_maintenance_hosts(zbx_dbsync_t *sync);
 
+/* trapper problems reporting */
+void zbx_dump_problems_to_json(struct zbx_json *json);
+void zbx_register_problem(zbx_uint64_t id, char *problem_text);
+void zbx_register_problem_recovery(zbx_uint64_t id);
+
 /* maintenance support */
 
 /* number of slots to store maintenance update flags */
 #define ZBX_MAINTENANCE_UPDATE_FLAGS_NUM()	\
 		((CONFIG_TIMER_FORKS + sizeof(uint64_t) * 8 - 1) / (sizeof(uint64_t) * 8))
 
-
 #endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/libs/zbxhistory/history.c xe-rabbix/src/libs/zbxhistory/history.c
--- zabbix-4.0.1/src/libs/zbxhistory/history.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/libs/zbxhistory/history.c	2018-12-14 11:20:58.418477596 +0500
@@ -25,10 +25,11 @@
 
 #include "../zbxalgo/vectorimpl.h"
 
-ZBX_VECTOR_IMPL(history_record, zbx_history_record_t)
+ZBX_VECTOR_IMPL(history_record, zbx_history_record_t);
 
 extern char	*CONFIG_HISTORY_STORAGE_URL;
 extern char	*CONFIG_HISTORY_STORAGE_OPTS;
+extern char	*CONFIG_HISTORY_STORAGE_TYPE;
 
 zbx_history_iface_t	history_ifaces[ITEM_VALUE_TYPE_MAX];
 
@@ -53,10 +54,21 @@
 
 	for (i = 0; i < ITEM_VALUE_TYPE_MAX; i++)
 	{
-		if (NULL == CONFIG_HISTORY_STORAGE_URL || NULL == strstr(CONFIG_HISTORY_STORAGE_OPTS, opts[i]))
+		if (NULL == CONFIG_HISTORY_STORAGE_URL || NULL == strstr(CONFIG_HISTORY_STORAGE_OPTS, opts[i])) 
+		{
+			zabbix_log(LOG_LEVEL_INFORMATION, "Init SQL storage engine as history storage for type %s", opts[i]);
 			ret = zbx_history_sql_init(&history_ifaces[i], i, error);
-		else
+		}
+		else if ( NULL != strstr(CONFIG_HISTORY_STORAGE_TYPE,"clickhouse")) 
+		{
+			ret = zbx_history_clickhouse_init(&history_ifaces[i], i, error);
+			zabbix_log(LOG_LEVEL_INFORMATION, "Init Clickhouse storage engine as history storage for type %s", opts[i]);
+		}
+		else 
+		{
 			ret = zbx_history_elastic_init(&history_ifaces[i], i, error);
+			zabbix_log(LOG_LEVEL_INFORMATION, "Init ElasticsSearch storage engine as history storage for type %s", opts[i]);
+		}
 
 		if (FAIL == ret)
 			return FAIL;
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/libs/zbxhistory/history_clickhouse.c xe-rabbix/src/libs/zbxhistory/history_clickhouse.c
--- zabbix-4.0.1/src/libs/zbxhistory/history_clickhouse.c	1970-01-01 05:00:00.000000000 +0500
+++ xe-rabbix/src/libs/zbxhistory/history_clickhouse.c	2018-12-25 16:00:17.405770730 +0500
@@ -0,0 +1,914 @@
+/*
+** Zabbix
+** Copyright (C) 2001-2018 Zabbix SIA
+**
+** This program is free software; you can redistribute it and/or modify
+** it under the terms of the GNU General Public License as published by
+** the Free Software Foundation; either version 2 of the License, or
+** (at your option) any later version.
+**
+** This program is distributed in the hope that it will be useful,
+** but WITHOUT ANY WARRANTY; without even the implied warranty of
+** MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+** GNU General Public License for more details.
+**
+** You should have received a copy of the GNU General Public License
+** along with this program; if not, write to the Free Software
+** Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+**/
+
+#include "common.h"
+#include "log.h"
+#include "zbxjson.h"
+#include "zbxalgo.h"
+#include "dbcache.h"
+#include "zbxhistory.h"
+#include "zbxself.h"
+#include "history.h"
+
+/* curl_multi_wait() is supported starting with version 7.28.0 (0x071c00) */
+#if defined(HAVE_LIBCURL) && LIBCURL_VERSION_NUM >= 0x071c00
+
+#define		ZBX_HISTORY_STORAGE_DOWN	10000 /* Timeout in milliseconds */
+
+//#define		ZBX_IDX_JSON_ALLOCATE		256
+//#define		ZBX_JSON_ALLOCATE		2048
+#define     ZBX_VALUECACHE_FILL_TIME 300
+//#define     ZBX_HISTORY_AGE_TIME    15*60-1 //we don't request 15-minutes old data from history it's better to
+                                            //wait till value cache fills
+#define		MAX_HISTORY_CLICKHOUSE_FIELDS	5 /* How many fields to parse from clickhouse output */
+
+//const char	*value_type_str[] = {"dbl", "str", "log", "uint", "text"};
+
+extern char	*CONFIG_HISTORY_STORAGE_URL;
+extern int	CONFIG_HISTORY_STORAGE_PIPELINES;
+extern char *CONFIG_HISTORY_STORAGE_TABLE_NAME;
+
+typedef struct
+{
+	char	*base_url;
+	char	*post_url;
+	char	*buf;
+	CURL	*handle;
+}
+zbx_clickhouse_data_t;
+
+typedef struct
+{
+	unsigned char		initialized;
+	zbx_vector_ptr_t	ifaces;
+
+	CURLM			*handle;
+}
+zbx_clickhouse_writer_t;
+
+static zbx_clickhouse_writer_t	writer;
+
+typedef struct
+{
+	char	*data;
+	size_t	alloc;
+	size_t	offset;
+}
+zbx_httppage_t;
+
+
+
+typedef struct
+{
+	zbx_httppage_t	page;
+	char		errbuf[CURL_ERROR_SIZE];
+}
+zbx_curlpage_t;
+
+static zbx_curlpage_t	page_w[ITEM_VALUE_TYPE_MAX];
+
+static size_t	curl_write_cb(void *ptr, size_t size, size_t nmemb, void *userdata)
+{
+	size_t	r_size = size * nmemb;
+
+	zbx_httppage_t	*page = (zbx_httppage_t	*)userdata;
+    zabbix_log(LOG_LEVEL_INFORMATION, "Callback: before strncpy");
+	zbx_strncpy_alloc(&page->data, &page->alloc, &page->offset, ptr, r_size);
+    zabbix_log(LOG_LEVEL_INFORMATION, "Callback: after strncpy");
+
+	return r_size;
+}
+
+static history_value_t	history_str2value(char *str, unsigned char value_type)
+{
+	history_value_t	value;
+
+	switch (value_type)
+	{
+		case ITEM_VALUE_TYPE_LOG:
+			value.log = (zbx_log_value_t *)zbx_malloc(NULL, sizeof(zbx_log_value_t));
+			memset(value.log, 0, sizeof(zbx_log_value_t));
+			value.log->value = zbx_strdup(NULL, str);
+			break;
+		case ITEM_VALUE_TYPE_STR:
+		case ITEM_VALUE_TYPE_TEXT:
+			value.str = zbx_strdup(NULL, str);
+			break;
+		case ITEM_VALUE_TYPE_FLOAT:
+			value.dbl = atof(str);
+			break;
+		case ITEM_VALUE_TYPE_UINT64:
+			ZBX_STR2UINT64(value.ui64, str);
+			break;
+	}
+
+	return value;
+}
+
+static const char	*history_value2str(const ZBX_DC_HISTORY *h)
+{
+	static char	buffer[MAX_ID_LEN + 1];
+
+	switch (h->value_type)
+	{
+		case ITEM_VALUE_TYPE_STR:
+		case ITEM_VALUE_TYPE_TEXT:
+			return h->value.str;
+		case ITEM_VALUE_TYPE_LOG:
+			return h->value.log->value;
+		case ITEM_VALUE_TYPE_FLOAT:
+			zbx_snprintf(buffer, sizeof(buffer), ZBX_FS_DBL, h->value.dbl);
+			break;
+		case ITEM_VALUE_TYPE_UINT64:
+			zbx_snprintf(buffer, sizeof(buffer), ZBX_FS_UI64, h->value.ui64);
+			break;
+	}
+
+	return buffer;
+}
+
+static int	history_parse_value(struct zbx_json_parse *jp, unsigned char value_type, zbx_history_record_t *hr)
+{
+	char	*value = NULL;
+	size_t	value_alloc = 0;
+	int	ret = FAIL;
+
+	if (SUCCEED != zbx_json_value_by_name_dyn(jp, "clock", &value, &value_alloc))
+		goto out;
+
+	hr->timestamp.sec = atoi(value);
+
+	if (SUCCEED != zbx_json_value_by_name_dyn(jp, "ns", &value, &value_alloc))
+		goto out;
+
+	hr->timestamp.ns = atoi(value);
+
+	if (SUCCEED != zbx_json_value_by_name_dyn(jp, "value", &value, &value_alloc))
+		goto out;
+
+	hr->value = history_str2value(value, value_type);
+
+	if (ITEM_VALUE_TYPE_LOG == value_type)
+	{
+
+		if (SUCCEED != zbx_json_value_by_name_dyn(jp, "timestamp", &value, &value_alloc))
+			goto out;
+
+		hr->value.log->timestamp = atoi(value);
+
+		if (SUCCEED != zbx_json_value_by_name_dyn(jp, "logeventid", &value, &value_alloc))
+			goto out;
+
+		hr->value.log->logeventid = atoi(value);
+
+		if (SUCCEED != zbx_json_value_by_name_dyn(jp, "severity", &value, &value_alloc))
+			goto out;
+
+		hr->value.log->severity = atoi(value);
+
+		if (SUCCEED != zbx_json_value_by_name_dyn(jp, "source", &value, &value_alloc))
+			goto out;
+
+		hr->value.log->source = zbx_strdup(NULL, value);
+	}
+
+	ret = SUCCEED;
+
+out:
+	zbx_free(value);
+
+	return ret;
+}
+
+static void	clickhouse_log_error(CURL *handle, CURLcode error, const char *errbuf,zbx_httppage_t *page_r)
+{
+	long	http_code;
+
+	if (CURLE_HTTP_RETURNED_ERROR == error)
+	{
+		curl_easy_getinfo(handle, CURLINFO_RESPONSE_CODE, &http_code);
+
+		if (0 != page_r->offset)
+		{
+			zabbix_log(LOG_LEVEL_ERR, "cannot get values from clickhouse, HTTP error: %ld, message: %s",
+					http_code, page_r->data);
+		}
+		else
+			zabbix_log(LOG_LEVEL_ERR, "cannot get values from clickhousesearch, HTTP error: %ld", http_code);
+	}
+	else
+	{
+		zabbix_log(LOG_LEVEL_ERR, "cannot get values from clickhousesearch: %s",
+				'\0' != *errbuf ? errbuf : curl_easy_strerror(error));
+	}
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_close                                                          *
+ *                                                                                  *
+ * Purpose: closes connection and releases allocated resources                      *
+ *                                                                                  *
+ * Parameters:  hist - [IN] the history storage interface                           *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_close(zbx_history_iface_t *hist)
+{
+	zbx_clickhouse_data_t	*data = (zbx_clickhouse_data_t *)hist->data;
+
+	zbx_free(data->buf);
+	zbx_free(data->post_url);
+
+	if (NULL != data->handle)
+	{
+		if (NULL != writer.handle)
+			curl_multi_remove_handle(writer.handle, data->handle);
+
+		curl_easy_cleanup(data->handle);
+		data->handle = NULL;
+	}
+}
+
+
+/******************************************************************************************************************
+ *                                                                                                                *
+ * common sql service support                                                                                     *
+ *                                                                                                                *
+ ******************************************************************************************************************/
+
+
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_init                                                    *
+ *                                                                                  *
+ * Purpose: initializes clickhouse writer for a new batch of history values            *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_writer_init(void)
+{
+	if (0 != writer.initialized)
+		return;
+
+	zbx_vector_ptr_create(&writer.ifaces);
+
+	if (NULL == (writer.handle = curl_multi_init()))
+	{
+		zbx_error("Cannot initialize cURL multi session");
+		exit(EXIT_FAILURE);
+	}
+
+	writer.initialized = 1;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_release                                                 *
+ *                                                                                  *
+ * Purpose: releases initialized clickhouse writer by freeing allocated resources and  *
+ *          setting its state to uninitialized.                                     *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_writer_release(void)
+{
+	int	i;
+
+	for (i = 0; i < writer.ifaces.values_num; i++)
+		clickhouse_close((zbx_history_iface_t *)writer.ifaces.values[i]);
+
+	curl_multi_cleanup(writer.handle);
+	writer.handle = NULL;
+
+	zbx_vector_ptr_destroy(&writer.ifaces);
+
+	writer.initialized = 0;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_add_iface                                               *
+ *                                                                                  *
+ * Purpose: adds history storage interface to be flushed later                      *
+ *                                                                                  *
+ * Parameters: db_insert - [IN] bulk insert data                                    *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_writer_add_iface(zbx_history_iface_t *hist)
+{
+	zbx_clickhouse_data_t	*data = (zbx_clickhouse_data_t *)hist->data;
+    zabbix_log(LOG_LEVEL_INFORMATION, "Will flush data to clickhouse");
+
+	clickhouse_writer_init();
+
+	if (NULL == (data->handle = curl_easy_init()))
+	{
+		zabbix_log(LOG_LEVEL_ERR, "cannot initialize cURL session");
+		return;
+	}
+
+	curl_easy_setopt(data->handle, CURLOPT_URL, data->base_url);
+	curl_easy_setopt(data->handle, CURLOPT_POST, 1L);
+	curl_easy_setopt(data->handle, CURLOPT_POSTFIELDS, data->buf);
+	curl_easy_setopt(data->handle, CURLOPT_WRITEFUNCTION, curl_write_cb);
+
+	curl_easy_setopt(data->handle, CURLOPT_WRITEDATA, &page_w[hist->value_type].page);
+	curl_easy_setopt(data->handle, CURLOPT_FAILONERROR, 1L);
+	curl_easy_setopt(data->handle, CURLOPT_ERRORBUFFER, page_w[hist->value_type].errbuf);
+	*page_w[hist->value_type].errbuf = '\0';
+	curl_easy_setopt(data->handle, CURLOPT_PRIVATE, &page_w[hist->value_type]);
+	page_w[hist->value_type].page.offset = 0;
+	if (0 < page_w[hist->value_type].page.alloc)
+		*page_w[hist->value_type].page.data = '\0';
+
+	curl_multi_add_handle(writer.handle, data->handle);
+
+	zbx_vector_ptr_append(&writer.ifaces, hist);
+    zabbix_log(LOG_LEVEL_INFORMATION, "Flushed data to clickhouse");
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_flush                                                   *
+ *                                                                                  *
+ * Purpose: posts historical data to clickhouse storage                                *
+ *                                                                                  *
+ ************************************************************************************/
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_flush                                                   *
+ *                                                                                  *
+ * Purpose: posts historical data to clickhouse storage                                *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_writer_flush(void)
+{
+	const char		*__function_name = "clickhouse_writer_flush";
+
+	struct curl_slist	*curl_headers = NULL;
+	int			i, running, previous, msgnum;
+	CURLMsg			*msg;
+	zbx_vector_ptr_t	retries;
+
+	zabbix_log(LOG_LEVEL_INFORMATION, "In %s()", __function_name);
+
+	/* The writer might be uninitialized only if the history */
+	/* was already flushed. In that case, return SUCCEED */
+	if (0 == writer.initialized)
+		return SUCCEED;
+
+	zbx_vector_ptr_create(&retries);
+
+	curl_headers = curl_slist_append(curl_headers, "Content-Type: application/x-ndjson");
+
+	for (i = 0; i < writer.ifaces.values_num; i++)
+	{
+		zbx_history_iface_t	*hist = (zbx_history_iface_t *)writer.ifaces.values[i];
+		zbx_clickhouse_data_t	*data = (zbx_clickhouse_data_t *)hist->data;
+
+		(void)curl_easy_setopt(data->handle, CURLOPT_HTTPHEADER, curl_headers);
+
+		zabbix_log(LOG_LEVEL_INFORMATION, "Will send to clickhouse %s", data->buf);
+	}
+
+try_again:
+	previous = 0;
+
+	do
+	{
+		int		fds;
+		CURLMcode	code;
+		char 		*error;
+		zbx_curlpage_t	*curl_page;
+
+		if (CURLM_OK != (code = curl_multi_perform(writer.handle, &running)))
+		{
+			zabbix_log(LOG_LEVEL_ERR, "cannot perform on curl multi handle: %s", curl_multi_strerror(code));
+			break;
+		}
+
+		if (CURLM_OK != (code = curl_multi_wait(writer.handle, NULL, 0, ZBX_HISTORY_STORAGE_DOWN, &fds)))
+		{
+			zabbix_log(LOG_LEVEL_ERR, "cannot wait on curl multi handle: %s", curl_multi_strerror(code));
+			break;
+		}
+
+		if (previous == running)
+			continue;
+
+		while (NULL != (msg = curl_multi_info_read(writer.handle, &msgnum)))
+		{
+			/* If the error is due to malformed data, there is no sense on re-trying to send. */
+			/* That's why we actually check for transport and curl errors separately */
+			if (CURLE_HTTP_RETURNED_ERROR == msg->data.result)
+			{
+				if (CURLE_OK == curl_easy_getinfo(msg->easy_handle, CURLINFO_PRIVATE,
+						(char **)&curl_page) && '\0' != *curl_page->errbuf)
+				{
+					zabbix_log(LOG_LEVEL_ERR, "cannot send data to clickhousesearch, HTTP error"
+							" message: %s", curl_page->errbuf);
+				}
+				else
+				{
+					long int	err;
+
+					curl_easy_getinfo(msg->easy_handle, CURLINFO_RESPONSE_CODE, &err);
+					zabbix_log(LOG_LEVEL_ERR, "cannot send data to clickhouse, HTTP error code:"
+							" %ld", err);
+				}
+			}
+			else if (CURLE_OK != msg->data.result)
+			{
+				if (CURLE_OK == curl_easy_getinfo(msg->easy_handle, CURLINFO_PRIVATE,
+						(char **)&curl_page) && '\0' != *curl_page->errbuf)
+				{
+					zabbix_log(LOG_LEVEL_WARNING, "cannot send data to clickhouse: %s",
+							curl_page->errbuf);
+				}
+				else
+				{
+					zabbix_log(LOG_LEVEL_WARNING, "cannot send data to clickhouse: %s",
+							curl_easy_strerror(msg->data.result));
+				}
+
+				/* If the error is due to curl internal problems or unrelated */
+				/* problems with HTTP, we put the handle in a retry list and */
+				/* remove it from the current execution loop */
+				zbx_vector_ptr_append(&retries, msg->easy_handle);
+				curl_multi_remove_handle(writer.handle, msg->easy_handle);
+			}
+//			else if (CURLE_OK == curl_easy_getinfo(msg->easy_handle, CURLINFO_PRIVATE, (char **)&curl_page)
+//					&& SUCCEED == clickhouse_is_error_present(&curl_page->page, &error))
+//			{
+//				zabbix_log(LOG_LEVEL_WARNING, "%s() cannot send data to clickhousesearch: %s",
+//						__function_name, error);
+//				zbx_free(error);
+
+				/* If the error is due to clickhouse internal problems (for example an index */
+				/* became read-only), we put the handle in a retry list and */
+//				/* remove it from the current execution loop */
+//				zbx_vector_ptr_append(&retries, msg->easy_handle);
+//				curl_multi_remove_handle(writer.handle, msg->easy_handle);
+//			}
+		}
+
+		previous = running;
+	}
+	while (running);
+
+	/* We check if we have handles to retry. If yes, we put them back in the multi */
+	/* handle and go to the beginning of the do while() for try sending the data again */
+	/* after sleeping for ZBX_HISTORY_STORAGE_DOWN / 1000 (seconds) */
+	if (0 < retries.values_num)
+	{
+		for (i = 0; i < retries.values_num; i++)
+			curl_multi_add_handle(writer.handle, retries.values[i]);
+
+		zbx_vector_ptr_clear(&retries);
+
+		sleep(ZBX_HISTORY_STORAGE_DOWN / 1000);
+		goto try_again;
+	}
+
+	curl_slist_free_all(curl_headers);
+
+	zbx_vector_ptr_destroy(&retries);
+
+	clickhouse_writer_release();
+
+	zabbix_log(LOG_LEVEL_INFORMATION, "End of %s()", __function_name);
+
+	return SUCCEED;
+}
+
+
+/******************************************************************************************************************
+ *                                                                                                                *
+ * history interface support                                                                                      *
+ *                                                                                                                *
+ ******************************************************************************************************************/
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_destroy                                                        *
+ *                                                                                  *
+ * Purpose: destroys history storage interface                                      *
+ *                                                                                  *
+ * Parameters:  hist - [IN] the history storage interface                           *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_destroy(zbx_history_iface_t *hist)
+{
+	zbx_clickhouse_data_t	*data = (zbx_clickhouse_data_t *)hist->data;
+
+	clickhouse_close(hist);
+
+	zbx_free(data->base_url);
+	zbx_free(data);
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_get_values                                                     *
+ *                                                                                  *
+ * Purpose: gets item history data from history storage                             *
+ *                                                                                  *
+ * Parameters:  hist    - [IN] the history storage interface                        *
+ *              itemid  - [IN] the itemid                                           *
+ *              start   - [IN] the period start timestamp                           *
+ *              count   - [IN] the number of values to read                         *
+ *              end     - [IN] the period end timestamp                             *
+ *              values  - [OUT] the item history data values                        *
+ *                                                                                  *
+ * Return value: SUCCEED - the history data were read successfully                  *
+ *               FAIL - otherwise                                                   *
+ *                                                                                  *
+ * Comments: This function reads <count> values from ]<start>,<end>] interval or    *
+ *           all values from the specified interval if count is zero.               *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_get_values(zbx_history_iface_t *hist, zbx_uint64_t itemid, int start, int count, int end,
+		zbx_vector_history_record_t *values)
+{
+	const char		*__function_name = "clickhouse_get_values";
+
+	zbx_clickhouse_data_t	*data = (zbx_clickhouse_data_t *)hist->data;
+	size_t			url_alloc = 0, url_offset = 0, id_alloc = 0;
+    // scroll_alloc = 0, scroll_offset = 0;
+	int			total, empty, ret;
+	CURLcode		err;
+	//struct zbx_json		query;
+	struct curl_slist	*curl_headers = NULL;
+	//char			*scroll_id = NULL, *scroll_query = NULL,
+    char  errbuf[CURL_ERROR_SIZE];
+    char	*sql_buffer=NULL;
+    size_t			buf_alloc = 0, buf_offset = 0;
+    static int first_run=0;
+    int i;
+    zbx_history_record_t	hr;
+    zbx_httppage_t	*page_r;
+
+	zabbix_log(LOG_LEVEL_INFORMATION, "In %s()", __function_name);
+
+    if ( NULL == (page_r=zbx_malloc(NULL,sizeof(zbx_httppage_t)))) {
+        zabbix_log(LOG_LEVEL_ERR,"Couldn't alocate pager_r");
+        return (FAIL);    
+    } else 
+        bzero(page_r,sizeof(zbx_httppage_t));
+
+    if (0 == first_run) 
+		first_run = time(NULL);
+
+    //for checks with small intervalls it's better to wait item
+    //collection then to request SLOOW history cache, so 
+    if (time(NULL)- ZBX_VALUECACHE_FILL_TIME < first_run) {
+			zabbix_log(LOG_LEVEL_INFORMATION, "waiting for cache load, exiting");
+            ret = SUCCEED;
+            goto out;
+
+	}
+
+	ret=SUCCEED;
+	goto out;
+
+	ret = FAIL;
+
+	if (NULL == (data->handle = curl_easy_init()))
+	{
+		zabbix_log(LOG_LEVEL_ERR, "cannot initialize cURL session");
+
+		return FAIL;
+	} 
+	
+    zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, 
+		"SELECT  toUInt32(clock),ns,value,value_dbl,value_str FROM %s WHERE itemid=%ld ",
+		CONFIG_HISTORY_STORAGE_TABLE_NAME,itemid);
+
+	if (1 == end-start) {
+		zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "AND clock = %d ", end);
+
+	} else {
+		if (0 < start) {
+			zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "AND clock > %d ", start);
+		}
+		if (0 < end ) {
+			zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "AND clock <= %d ", end);
+		}
+         
+	}
+
+	zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "ORDER BY clock DESC ");
+
+	if (0 < count) 
+	{
+	    zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "LIMIT %d", count);
+	}
+
+	zabbix_log(LOG_LEVEL_INFORMATION, "sending query to clickhouse: %s", sql_buffer);
+
+
+    
+      
+//    zbx_snprintf_alloc(&data->post_url, &url_alloc, &url_offset, "%s/%s*/values/_search?scroll=10s", data->base_url,
+//			value_type_str[hist->value_type]);
+
+	
+	//curl_headers = curl_slist_append(curl_headers, "Content-Type: application/json");
+
+	curl_easy_setopt(data->handle, CURLOPT_URL, data->base_url);
+	curl_easy_setopt(data->handle, CURLOPT_POSTFIELDS, sql_buffer);
+	curl_easy_setopt(data->handle, CURLOPT_WRITEFUNCTION, curl_write_cb);
+	curl_easy_setopt(data->handle, CURLOPT_WRITEDATA, page_r);
+	curl_easy_setopt(data->handle, CURLOPT_HTTPHEADER, curl_headers);
+	curl_easy_setopt(data->handle, CURLOPT_FAILONERROR, 1L);
+	curl_easy_setopt(data->handle, CURLOPT_ERRORBUFFER, errbuf);
+
+	zabbix_log(LOG_LEVEL_INFORMATION, "sending query to %s; post data: %s", data->base_url, sql_buffer);
+
+	page_r->offset = 0;
+	*errbuf = '\0';
+
+	if (CURLE_OK != (err = curl_easy_perform(data->handle)))
+	{
+		clickhouse_log_error(data->handle, err, errbuf,page_r);
+        zabbix_log(LOG_LEVEL_INFORMATION, "Failed query");
+		goto out;
+	}
+
+    zabbix_log(LOG_LEVEL_INFORMATION, "recieved from clickhouse: %s", page_r->data);
+		
+	
+	char *end_str;
+	if (NULL !=page_r->data && page_r->data[0]!=0) {
+
+	    zabbix_log(LOG_LEVEL_DEBUG, "Parsing line by line");
+	    int line_count=0, field_count=0;
+
+
+	    char *line_ptr = strtok_r(page_r->data, "\n", &end_str);
+
+	    while (line_ptr != NULL)
+	    {
+			char *end_field;
+			char *field_ptr = strtok_r(line_ptr, "\t", &end_field);
+			char *fields[MAX_HISTORY_CLICKHOUSE_FIELDS];
+
+			zabbix_log(LOG_LEVEL_DEBUG, "Parsing line '%s'", line_ptr);
+
+			for (i=0; i++; i<field_count)  fields[i]=NULL; 
+
+			while (field_ptr != NULL && MAX_HISTORY_CLICKHOUSE_FIELDS>field_count) 
+			{	
+				fields[field_count++]=field_ptr;
+				field_ptr = strtok_r(NULL, "\t", &end_field);
+			}
+			
+			//the fields order  must be in sync with SQL query above
+			//OR TODO: make it via some proper interface, perhaps JSON or whatever clickhouse supports to 
+			//be able to distingiosh wich value is from what field name, not depending on the order in SQL request
+
+
+			zabbix_log(LOG_LEVEL_INFORMATION, "Parsed line %d clock:'%s', ns:'%s', value:'%s', value_dbl:'%s' '",line_count, fields[0],fields[1],fields[2],fields[3]);
+
+			if (NULL != fields[4]) 
+			{
+				//we've got at least three fields
+				hr.timestamp.sec = atoi(fields[0]);
+				hr.timestamp.ns = atoi(fields[1]);
+				switch (hist->value_type)
+				{
+					case ITEM_VALUE_TYPE_UINT64:
+						zabbix_log(LOG_LEVEL_DEBUG, "Parsed  as UINT64 %s",fields[2]);
+			    		hr.value = history_str2value(fields[2], hist->value_type);
+						break;
+
+					case ITEM_VALUE_TYPE_FLOAT: 
+						zabbix_log(LOG_LEVEL_DEBUG, "Parsed  as DBL field %s",fields[3]);
+			    		hr.value = history_str2value(fields[3], hist->value_type);
+                        zbx_vector_history_record_append_ptr(values, &hr);
+						break;
+					case ITEM_VALUE_TYPE_STR:
+					case ITEM_VALUE_TYPE_TEXT:
+						//!!!! for some reason there are major memory leak when reading 
+						//string values from history.
+						//remove the following goto statement if you really need it
+						//break;
+
+						zabbix_log(LOG_LEVEL_DEBUG, "Parsed  as STR/TEXT type %s",fields[4]);
+						hr.value = history_str2value(fields[4], hist->value_type);
+                        zbx_vector_history_record_append_ptr(values, &hr);
+                        break;
+
+					case ITEM_VALUE_TYPE_LOG:
+						//todo: if i ever need this, but for now there is no log write to clickhouse
+						//goto out;
+                        break;
+				}				
+				//adding to zabbix vector
+				//zbx_vector_history_record_append_ptr(values, &hr);
+
+				ret=SUCCEED;
+				line_count++;
+			} else {
+				zabbix_log(LOG_LEVEL_DEBUG, "Skipping the result, not enough fields");
+			}
+			
+			line_ptr = strtok_r(NULL, "\n", &end_str);
+	    }
+	    page_r->data[0]=0;	
+	} else 
+	{
+	    zabbix_log(LOG_LEVEL_DEBUG, "No data from clickhouse");
+	    ret = SUCCEED;
+	}
+
+
+
+out:
+	clickhouse_close(hist);
+	curl_slist_free_all(curl_headers);
+    zbx_free(sql_buffer);
+    zbx_free(page_r->data);
+    zbx_free(page_r);
+
+
+	zbx_vector_history_record_sort(values, (zbx_compare_func_t)zbx_history_record_compare_desc_func);
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
+
+	return ret;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_add_values                                                     *
+ *                                                                                  *
+ * Purpose: sends history data to the storage                                       *
+ *                                                                                  *
+ * Parameters:  hist    - [IN] the history storage interface                        *
+ *              history - [IN] the history data vector (may have mixed value types) *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_add_values(zbx_history_iface_t *hist, const zbx_vector_ptr_t *history)
+{
+	const char	*__function_name = "clickhouse_add_values";
+
+	zbx_clickhouse_data_t	*data = (zbx_clickhouse_data_t *)hist->data;
+	int			i,j, num = 0;
+	ZBX_DC_HISTORY		*h;
+	struct zbx_json		json_idx, json;
+	size_t			buf_alloc = 0, buf_offset = 0;
+	
+    char *tmp_buffer=NULL;	
+	size_t tmp_alloc=0, tmp_offset=0;
+
+
+	zabbix_log(LOG_LEVEL_INFORMATION, "In %s()", __function_name);
+
+    
+	zbx_snprintf_alloc(&tmp_buffer,&tmp_alloc,&tmp_offset,"INSERT INTO %s VALUES ", CONFIG_HISTORY_STORAGE_TABLE_NAME );
+    
+	for (i = 0; i < history->values_num; i++)
+	{
+		h = (ZBX_DC_HISTORY *)history->values[i];
+
+		if (hist->value_type != h->value_type)
+			continue;
+
+		
+		if (ITEM_VALUE_TYPE_UINT64 == h->value_type) {
+	           zbx_snprintf_alloc(&tmp_buffer,&tmp_alloc,&tmp_offset,"(CAST(%d as date) ,%ld,%d,%d,%ld,0,''),",
+				h->ts.sec,h->itemid,h->ts.sec,h->ts.ns,h->value.ui64);
+    	}
+
+		if (ITEM_VALUE_TYPE_FLOAT == h->value_type) {
+           zbx_snprintf_alloc(&tmp_buffer,&tmp_alloc,&tmp_offset,"(CAST(%d as date) ,%ld,%d,%d,0,%f,''),",
+					h->ts.sec,h->itemid,h->ts.sec,h->ts.ns,h->value.dbl);
+        }
+
+		if (ITEM_VALUE_TYPE_STR == h->value_type || 
+		 	        ITEM_VALUE_TYPE_TEXT == h->value_type ) {
+		    zabbix_log(LOG_LEVEL_DEBUG, "Parsing value as string or text type");
+			
+                //todo: make more sensible string quotation
+            for (j = 0; j < strlen(h->value.str); j++) {
+		        if ('\'' == h->value.str[j]) { 
+				    h->value.str[j]=' ';
+			    }
+			}
+
+		    zbx_snprintf_alloc(&tmp_buffer,&tmp_alloc,&tmp_offset,"(CAST(%d as date) ,%ld,%d,%d,0,0,'%s'),",
+					h->ts.sec,h->itemid,h->ts.sec,h->ts.ns,h->value.str);
+		}
+
+		if (ITEM_VALUE_TYPE_LOG == h->value_type)
+		{
+		//    const zbx_log_value_t	*log;
+		//    log = h->value.log;
+		}
+
+		num++;
+	}
+
+	if (num > 0)
+	{ 
+        zbx_snprintf_alloc(&data->buf, &buf_alloc, &buf_offset, "%s\n", tmp_buffer);
+        zabbix_log(LOG_LEVEL_INFORMATION, "will insert to clickhouse: %s",data->buf);
+
+		clickhouse_writer_add_iface(hist);
+	}
+
+	zbx_free(tmp_buffer);
+	zabbix_log(LOG_LEVEL_INFORMATION, "End of %s()", __function_name);
+
+	return num;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_flush                                                          *
+ *                                                                                  *
+ * Purpose: flushes the history data to storage                                     *
+ *                                                                                  *
+ * Parameters:  hist    - [IN] the history storage interface                        *
+ *                                                                                  *
+ * Comments: This function will try to flush the data until it succeeds or          *
+ *           unrecoverable error occurs                                             *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_flush(zbx_history_iface_t *hist)
+{
+	ZBX_UNUSED(hist);
+
+	return clickhouse_writer_flush();
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: zbx_history_clickhouse_init                                               *
+ *                                                                                  *
+ * Purpose: initializes history storage interface                                   *
+ *                                                                                  *
+ * Parameters:  hist       - [IN] the history storage interface                     *
+ *              value_type - [IN] the target value type                             *
+ *              error      - [OUT] the error message                                *
+ *                                                                                  *
+ * Return value: SUCCEED - the history storage interface was initialized            *
+ *               FAIL    - otherwise                                                *
+ *                                                                                  *
+ ************************************************************************************/
+int	zbx_history_clickhouse_init(zbx_history_iface_t *hist, unsigned char value_type, char **error)
+{
+	zbx_clickhouse_data_t	*data;
+
+	if (0 != curl_global_init(CURL_GLOBAL_ALL))
+	{
+		*error = zbx_strdup(*error, "Cannot initialize cURL library");
+		return FAIL;
+	}
+
+	data = (zbx_clickhouse_data_t *)zbx_malloc(NULL, sizeof(zbx_clickhouse_data_t));
+	memset(data, 0, sizeof(zbx_clickhouse_data_t));
+	data->base_url = zbx_strdup(NULL, CONFIG_HISTORY_STORAGE_URL);
+	zbx_rtrim(data->base_url, "/");
+	data->buf = NULL;
+	data->post_url = NULL;
+	data->handle = NULL;
+
+	hist->value_type = value_type;
+	hist->data = data;
+	hist->destroy = clickhouse_destroy;
+	hist->add_values = clickhouse_add_values;
+	hist->flush = clickhouse_flush;
+	hist->get_values = clickhouse_get_values;
+	hist->requires_trends = 0;
+
+	return SUCCEED;
+}
+
+#else
+
+int	zbx_history_clickhouse_init(zbx_history_iface_t *hist, unsigned char value_type, char **error)
+{
+	ZBX_UNUSED(hist);
+	ZBX_UNUSED(value_type);
+
+	*error = zbx_strdup(*error, "cURL library support >= 7.28.0 is required for clickhousesearch history backend");
+	return FAIL;
+}
+
+#endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/libs/zbxhistory/history_clickhouse.c.OLD xe-rabbix/src/libs/zbxhistory/history_clickhouse.c.OLD
--- zabbix-4.0.1/src/libs/zbxhistory/history_clickhouse.c.OLD	1970-01-01 05:00:00.000000000 +0500
+++ xe-rabbix/src/libs/zbxhistory/history_clickhouse.c.OLD	2018-12-24 19:22:50.653099133 +0500
@@ -0,0 +1,802 @@
+/*
+** Zabbix
+** Copyright (C) 2001-2018 Zabbix SIA
+**
+** This program is free software; you can redistribute it and/or modify
+** it under the terms of the GNU General Public License as published by
+** the Free Software Foundation; either version 2 of the License, or
+** (at your option) any later version.
+**
+** This program is distributed in the hope that it will be useful,
+** but WITHOUT ANY WARRANTY; without even the implied warranty of
+** MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+** GNU General Public License for more details.
+**
+** You should have received a copy of the GNU General Public License
+** along with this program; if not, write to the Free Software
+** Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+**/
+
+
+
+#include "common.h"
+#include "log.h"
+#include "zbxjson.h"
+#include "zbxalgo.h"
+#include "dbcache.h"
+#include "zbxhistory.h"
+#include "zbxself.h"
+#include "history.h"
+#include <stdio.h>
+#include <string.h>
+
+/* curl_multi_wait() is supported starting with version 7.28.0 (0x071c00) */
+#if defined(HAVE_LIBCURL) && LIBCURL_VERSION_NUM >= 0x071c00
+
+#define		ZBX_HISTORY_STORAGE_DOWN	10000 /* Timeout in milliseconds */
+#define		MAX_HISTORY_CLICKHOUSE_FIELDS	5 /* How many fields to parse from clickhouse output */
+#define 	ZBX_VALUECACHE_FILL_TIME	300
+
+//const char	*value_type_str[] = {"dbl", "str", "log", "uint", "text"};
+
+extern char	*CONFIG_HISTORY_STORAGE_URL;
+extern char *CONFIG_HISTORY_STORAGE_TABLE_NAME;
+
+typedef struct
+{
+	char	*base_url;
+
+//post_url  here from elastics where it was used for scrolling of data search results, 
+//post_url might be used to use some clickhouse options, so i've decided to leave it
+	//char	*post_url;
+	char	*buf;
+	CURL	*handle;
+}
+zbx_clickhouse_data_t;
+
+typedef struct
+{
+	unsigned char		initialized;
+	zbx_vector_ptr_t	ifaces;
+
+	CURLM			*handle;
+}
+zbx_clickhouse_writer_t;
+
+static zbx_clickhouse_writer_t	writer;
+
+typedef struct
+{
+	char	*data;
+	size_t	alloc;
+	size_t	offset;
+}
+zbx_httppage_t;
+
+static zbx_httppage_t	page;
+
+static size_t	curl_write_cb(void *ptr, size_t size, size_t nmemb, void *userdata)
+{
+	size_t	r_size = size * nmemb;
+
+	ZBX_UNUSED(userdata);
+
+	zbx_strncpy_alloc(&page.data, &page.alloc, &page.offset, ptr, r_size);
+
+	return r_size;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Comments: stub function for avoiding LibCURL to print on the standard output.    *
+ *           In case of success, elasticsearch return a JSON, but the HTTP error    *
+ *           code is enough                                                         *
+ *                                                                                  *
+ ************************************************************************************/
+static size_t	curl_write_send_cb(void *ptr, size_t size, size_t nmemb, void *userdata)
+{
+	ZBX_UNUSED(ptr);
+	ZBX_UNUSED(userdata);
+	return size * nmemb;
+}
+
+static history_value_t	history_str2value(char *str, unsigned char value_type)
+{
+	history_value_t	value;
+
+	switch (value_type)
+	{
+		case ITEM_VALUE_TYPE_LOG:
+			value.log = zbx_malloc(NULL, sizeof(zbx_log_value_t));
+			memset(value.log, 0, sizeof(zbx_log_value_t));
+			value.log->value = zbx_strdup(NULL, str);
+			break;
+		case ITEM_VALUE_TYPE_STR:
+		case ITEM_VALUE_TYPE_TEXT:
+			value.str = zbx_strdup(NULL, str);
+			break;
+		case ITEM_VALUE_TYPE_FLOAT:
+			value.dbl = atof(str);
+			break;
+		case ITEM_VALUE_TYPE_UINT64:
+			ZBX_STR2UINT64(value.ui64, str);
+			break;
+	}
+
+	return value;
+}
+
+static const char	*history_value2str(const ZBX_DC_HISTORY *h)
+{
+	static char	buffer[MAX_ID_LEN + 1];
+
+	switch (h->value_type)
+	{
+		case ITEM_VALUE_TYPE_STR:
+		case ITEM_VALUE_TYPE_TEXT:
+			return h->value.str;
+		case ITEM_VALUE_TYPE_LOG:
+			return h->value.log->value;
+		case ITEM_VALUE_TYPE_FLOAT:
+			zbx_snprintf(buffer, sizeof(buffer), ZBX_FS_DBL, h->value.dbl);
+			break;
+		case ITEM_VALUE_TYPE_UINT64:
+			zbx_snprintf(buffer, sizeof(buffer), ZBX_FS_UI64, h->value.ui64);
+			break;
+	}
+
+	return buffer;
+}
+
+static void	clickhouse_log_error(CURL *handle, CURLcode error)
+{
+	long	http_code;
+
+	if (CURLE_HTTP_RETURNED_ERROR == error)
+	{
+		curl_easy_getinfo(handle, CURLINFO_RESPONSE_CODE, &http_code);
+
+		if (0 != page.offset)
+		{
+			zabbix_log(LOG_LEVEL_ERR, "cannot get values from clickhouse, HTTP error: %ld,", http_code);
+		}
+		else
+			zabbix_log(LOG_LEVEL_ERR, "cannot get values from clickhouse, HTTP error: %ld", http_code);
+	}
+	else
+	{
+		zabbix_log(LOG_LEVEL_ERR, "cannot get values from clickhouse: %s", curl_easy_strerror(error));
+	}
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_close                                                          *
+ *                                                                                  *
+ * Purpose: closes connection and releases allocated resources                      *
+ *                                                                                  *
+ * Parameters:  hist - [IN] the history storage interface                           *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_close(zbx_history_iface_t *hist)
+{
+	zbx_clickhouse_data_t	*data = hist->data;
+
+	zbx_free(data->buf);
+	//zbx_free(data->post_url);
+
+	if (NULL != data->handle)
+	{
+		if (NULL != writer.handle)
+			curl_multi_remove_handle(writer.handle, data->handle);
+
+		curl_easy_cleanup(data->handle);
+		data->handle = NULL;
+	}
+}
+
+/******************************************************************************************************************
+ *                                                                                                                *
+ * common sql service support                                                                                     *
+ *                                                                                                                *
+ ******************************************************************************************************************/
+
+
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_init                                                    *
+ *                                                                                  *
+ * Purpose: initializes clickhouse writer for a new batch of history values            *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_writer_init()
+{
+	if (0 != writer.initialized)
+		return;
+
+	zbx_vector_ptr_create(&writer.ifaces);
+
+	if (NULL == (writer.handle = curl_multi_init()))
+	{
+		zbx_error("Cannot initialize cURL multi session");
+		exit(EXIT_FAILURE);
+	}
+
+	writer.initialized = 1;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_release                                                 *
+ *                                                                                  *
+ * Purpose: releases initialized clickhouse writer by freeing allocated resources and  *
+ *          setting its state to uninitialized.                                     *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_writer_release()
+{
+	int	i;
+
+	for (i = 0; i < writer.ifaces.values_num; i++)
+		clickhouse_close(writer.ifaces.values[i]);
+
+	curl_multi_cleanup(writer.handle);
+	writer.handle = NULL;
+
+	zbx_vector_ptr_destroy(&writer.ifaces);
+
+	writer.initialized = 0;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_add_iface                                               *
+ *                                                                                  *
+ * Purpose: adds history storage interface to be flushed later                      *
+ *                                                                                  *
+ * Parameters: db_insert - [IN] bulk insert data                                    *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_writer_add_iface(zbx_history_iface_t *hist)
+{
+	zbx_clickhouse_data_t	*data = hist->data;
+
+	clickhouse_writer_init();
+
+	if (NULL == (data->handle = curl_easy_init()))
+	{
+		zabbix_log(LOG_LEVEL_ERR, "cannot initialize cURL session");
+		return;
+	}
+
+	//curl_easy_setopt(data->handle, CURLOPT_URL, data->post_url);
+	curl_easy_setopt(data->handle, CURLOPT_URL, data->base_url);
+	curl_easy_setopt(data->handle, CURLOPT_POST, 1);
+	curl_easy_setopt(data->handle, CURLOPT_POSTFIELDS, data->buf);
+	curl_easy_setopt(data->handle, CURLOPT_WRITEFUNCTION, curl_write_send_cb);
+	curl_easy_setopt(data->handle, CURLOPT_FAILONERROR, 1L);
+
+	curl_multi_add_handle(writer.handle, data->handle);
+
+	zbx_vector_ptr_append(&writer.ifaces, hist);
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_flush                                                   *
+ *                                                                                  *
+ * Purpose: posts historical data to clickhouse storage                                *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_writer_flush()
+{
+	const char		*__function_name = "clickhouse_writer_flush";
+
+	struct curl_slist	*curl_headers = NULL;
+	int			i, running, previous, msgnum;
+	CURLMsg			*msg;
+	zbx_vector_ptr_t	retries;
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s()", __function_name);
+
+	if (0 == writer.initialized)
+		return SUCCEED;
+
+	zbx_vector_ptr_create(&retries);
+
+	curl_headers = curl_slist_append(curl_headers, "Content-Type: application/x-ndjson");
+
+	for (i = 0; i < writer.ifaces.values_num; i++)
+	{
+		zbx_history_iface_t	*hist = (zbx_history_iface_t *)writer.ifaces.values[i];
+		zbx_clickhouse_data_t	*data = hist->data;
+
+		curl_easy_setopt(data->handle, CURLOPT_HTTPHEADER, curl_headers);
+
+		zabbix_log(LOG_LEVEL_DEBUG, "sending %s", data->buf);
+	}
+
+try_again:
+	previous = 0;
+
+	do
+	{
+		int		fds;
+		CURLMcode	code;
+
+		if (CURLM_OK != (code = curl_multi_perform(writer.handle, &running)))
+		{
+			zabbix_log(LOG_LEVEL_ERR, "cannot perform on curl multi handle: %s", curl_multi_strerror(code));
+			break;
+		}
+
+		if (CURLM_OK != (code = curl_multi_wait(writer.handle, NULL, 0, ZBX_HISTORY_STORAGE_DOWN, &fds)))
+		{
+			zabbix_log(LOG_LEVEL_ERR, "cannot wait on curl multi handle: %s", curl_multi_strerror(code));
+			break;
+		}
+
+		if (previous == running)
+			continue;
+
+		while (NULL != (msg = curl_multi_info_read(writer.handle, &msgnum)))
+		{
+			/* If the error is due to malformed data, there is no sense on re-trying to send. */
+			/* That's why we actually check for transport and curl errors separately */
+			if (CURLE_HTTP_RETURNED_ERROR == msg->data.result)
+			{
+				long int	err;
+
+				curl_easy_getinfo(msg->easy_handle, CURLINFO_RESPONSE_CODE, &err);
+
+				zabbix_log(LOG_LEVEL_ERR, "cannot send data to clickhouse, HTTP error %ld",  err);
+			}
+			else if (CURLE_OK != msg->data.result)
+			{
+				zabbix_log(LOG_LEVEL_WARNING, "%s: %s", "cannot send to clickhouse",
+						curl_easy_strerror(msg->data.result));
+
+				/* If the error is due to curl internal problems or unrelated */
+				/* problems with HTTP, we put the handle in a retry list and */
+				/* remove it from the current execution loop */
+				zbx_vector_ptr_append(&retries, msg->easy_handle);
+				curl_multi_remove_handle(writer.handle, msg->easy_handle);
+			}
+		}
+
+		previous = running;
+	}
+	while (running);
+
+	/* We check if we have handles to retry. If yes, we put them back in the multi */
+	/* handle and go to the beginning of the do while() for try sending the data again */
+	/* after sleeping for ZBX_HISTORY_STORAGE_DOWN / 1000 (seconds) */
+	if (0 < retries.values_num)
+	{
+		for (i = 0; i < retries.values_num; i++)
+			curl_multi_add_handle(writer.handle, retries.values[i]);
+
+		zbx_vector_ptr_clear(&retries);
+
+		sleep(ZBX_HISTORY_STORAGE_DOWN / 1000);
+		goto try_again;
+	}
+
+	curl_slist_free_all(curl_headers);
+
+	zbx_vector_ptr_destroy(&retries);
+
+	clickhouse_writer_release();
+
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
+	return SUCCEED;
+}
+
+/******************************************************************************************************************
+ *                                                                                                                *
+ * history interface support                                                                                      *
+ *                                                                                                                *
+ ******************************************************************************************************************/
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_destroy                                                        *
+ *                                                                                  *
+ * Purpose: destroys history storage interface                                      *
+ *                                                                                  *
+ * Parameters:  hist - [IN] the history storage interface                           *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_destroy(zbx_history_iface_t *hist)
+{
+	zbx_clickhouse_data_t	*data = hist->data;
+
+	clickhouse_close(hist);
+
+	zbx_free(data->base_url);
+	zbx_free(data);
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_get_values                                                     *
+ *                                                                                  *
+ * Purpose: gets item history data from history storage                             *
+ *                                                                                  *
+ * Parameters:  hist    - [IN] the history storage interface                        *
+ *              itemid  - [IN] the itemid                                           *
+ *              start   - [IN] the period start timestamp                           *
+ *              count   - [IN] the number of values to read                         *
+ *              end     - [IN] the period end timestamp                             *
+ *              values  - [OUT] the item history data values                        *
+ *                                                                                  *
+ * Return value: SUCCEED - the history data were read successfully                  *
+ *               FAIL - otherwise                                                   *
+ *                                                                                  *
+ * Comments: This function reads <count> values from ]<start>,<end>] interval or    *
+ *           all values from the specified interval if count is zero.               *
+ *                                                                                  *
+ ************************************************************************************/
+
+static int	clickhouse_get_values(zbx_history_iface_t *hist, zbx_uint64_t itemid, int start, int count, int end,
+		zbx_vector_history_record_t *values)
+{
+	const char		*__function_name = "clickhouse_get_values";
+	static int first_run=0;
+	
+
+	zbx_clickhouse_data_t	*data = hist->data;
+
+	int			ret=SUCCEED;
+	int			i;
+
+	CURLcode		err;
+	struct curl_slist	*curl_headers = NULL;
+
+	char	*sql_buffer=NULL;
+	size_t			buf_alloc = 0, buf_offset = 0;
+
+	zbx_history_record_t	hr;
+
+
+	if (0 == first_run) 
+		first_run = time(NULL);
+	
+	//just for testing to avoid history thread startup hummering
+	//return ret;
+	
+	//fix to prevent ValueCache filling on zabbix server startup
+	//in case when there are lots of items it's usually faster to 
+	//fill them via polling and not to kill the database with millions 
+	//of requests
+	
+	if (time(NULL)-first_run < ZBX_VALUECACHE_FILL_TIME) return (ret);
+	
+
+	//remove this after fixing segv on zabbix 4+
+	//but in reality, the server DOES NOT HAVE TO GO TO SLOW DB to get last year's average
+	//it better to plan your checks right or increase ValueCache mem size
+	//return (ret);
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s() Data request: we are asked for item%ld starting:%d ending:%d, count:%d", __function_name,itemid,start,end,count);
+
+
+	//HACK FIX TODO make it proper
+	//i see no reason to hold data in the value cache older then 1 day long 
+	//sure there must NOT be triggers with such a demand
+	//this is dirty workaround, has to fix like in ZABBIX history sql module
+	//trying to select data for several periods starting from day and extending 
+	//to month, but i am sure for triggering and alerting data from more then one 
+	//day long isn't really important
+	//
+	//to make things proper remove next condition, i put it here to resolver
+	//clickhouse overload problem but it was something else, amyway i've decided to leave it here
+
+	//if (end - start > 86400) {
+	  //  start=end-7*86400;
+	//} 
+
+
+	if (NULL == (data->handle = curl_easy_init()))
+	{
+		zabbix_log(LOG_LEVEL_ERR, "cannot initialize cURL session");
+		return FAIL;
+	}
+
+	zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, 
+		"SELECT  toUInt32(clock),ns,value,value_dbl,value_str FROM %s WHERE itemid=%ld ",
+		CONFIG_HISTORY_STORAGE_TABLE_NAME,itemid);
+
+
+	if (1 == end-start) {
+
+		zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "AND clock = %d ", end);
+
+	} else {
+		if (0 < start) {
+			zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "AND clock > %d ", start);
+		}
+		if (0 < end ) {
+			zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "AND clock <= %d ", end);
+		}
+	}
+
+	zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "ORDER BY clock DESC ");
+
+	if (0<count) 
+	{
+	    zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "LIMIT %d", count);
+	}
+
+	zabbix_log(LOG_LEVEL_DEBUG, "sending query to clickhouse: %s", sql_buffer);
+
+
+	curl_easy_setopt(data->handle, CURLOPT_URL, data->base_url);
+	curl_easy_setopt(data->handle, CURLOPT_POSTFIELDS, sql_buffer);
+	curl_easy_setopt(data->handle, CURLOPT_WRITEFUNCTION, curl_write_cb);
+	curl_easy_setopt(data->handle, CURLOPT_HTTPHEADER, curl_headers);
+	curl_easy_setopt(data->handle, CURLOPT_FAILONERROR, 1L);
+
+
+	page.offset = 0;
+
+	if (CURLE_OK != (err = curl_easy_perform(data->handle)))
+	{
+		clickhouse_log_error(data->handle, err);
+		goto out;
+	}
+
+
+	//curl_easy_setopt(data->handle, CURLOPT_URL, data->post_url);
+	curl_easy_setopt(data->handle, CURLOPT_URL, data->base_url);
+	zabbix_log(LOG_LEVEL_DEBUG, "recieved from clickhouse: %s", page.data);
+		
+	
+	char *end_str;
+	if (NULL !=page.data && page.data[0]!=0) {
+
+	    //zabbix_log(LOG_LEVEL_DEBUG, "Parcing line by line");
+	    int line_count=0, field_count=0;
+
+
+	    char *line_ptr = strtok_r(page.data, "\n", &end_str);
+
+	    while (line_ptr != NULL)
+	    {
+			char *end_field;
+			char *field_ptr = strtok_r(line_ptr, "\t", &end_field);
+			char *fields[MAX_HISTORY_CLICKHOUSE_FIELDS];
+
+			zabbix_log(LOG_LEVEL_DEBUG, "Parsing line '%s'", line_ptr);
+
+			for (i=0; i++; i<field_count)  fields[i]=NULL; 
+
+			while (field_ptr != NULL && MAX_HISTORY_CLICKHOUSE_FIELDS>field_count) 
+			{	
+				fields[field_count++]=field_ptr;
+				field_ptr = strtok_r(NULL, "\t", &end_field);
+			}
+			
+			//the fields order  must be in sync with SQL query above
+			//OR TODO: make it via some proper interface, perhaps JSON or whatever clickhouse supports to 
+			//be able to distingiosh wich value is from what field name, not depending on the order in SQL request
+
+
+			zabbix_log(LOG_LEVEL_TRACE, "Parsed line %d clock:'%s', ns:'%s', value:'%s', value_dbl:'%s' '",line_count, fields[0],fields[1],fields[2],fields[3]);
+
+			if (NULL != fields[4]) 
+			{
+				//we've got at least three fields
+				hr.timestamp.sec = atoi(fields[0]);
+				hr.timestamp.ns = atoi(fields[1]);
+				switch (hist->value_type)
+				{
+					case ITEM_VALUE_TYPE_UINT64:
+						zabbix_log(LOG_LEVEL_TRACE, "Parsed  as UINT64 %s",fields[2]);
+			    		hr.value = history_str2value(fields[2], hist->value_type);
+						break;
+
+					case ITEM_VALUE_TYPE_FLOAT: 
+						zabbix_log(LOG_LEVEL_TRACE, "Parsed  as DBL field %s",fields[3]);
+			    		hr.value = history_str2value(fields[3], hist->value_type);
+						break;
+					case ITEM_VALUE_TYPE_STR:
+					case ITEM_VALUE_TYPE_TEXT:
+						//!!!! for some reason there are major memory leak when reading 
+						//string values from history.
+						//remove the following goto statement if you really need it
+						goto out;
+
+						zabbix_log(LOG_LEVEL_TRACE, "Parsed  as STR/TEXT type %s",fields[4]);
+						hr.value = history_str2value(fields[4], hist->value_type);
+					case ITEM_VALUE_TYPE_LOG:
+						//todo: if i ever need this, but for now there is no log write to clickhouse
+						goto out;
+				}				
+				//adding to zabbix vector
+				zbx_vector_history_record_append_ptr(values, &hr);
+
+				ret=SUCCEED;
+				line_count++;
+			} else {
+				zabbix_log(LOG_LEVEL_DEBUG, "Skipping the result, not enough fields");
+			}
+			
+			line_ptr = strtok_r(NULL, "\n", &end_str);
+	    }
+	    page.data[0]=0;	
+	} else 
+	{
+	    zabbix_log(LOG_LEVEL_DEBUG, "No data from clickhouse");
+	    ret = SUCCEED;
+	}
+
+
+out:
+	clickhouse_close(hist);
+	curl_slist_free_all(curl_headers);
+	zbx_free(sql_buffer);
+
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
+	return SUCCEED;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_add_values                                                     *
+ *                                                                                  *
+ * Purpose: sends history data to the storage                                       *
+ *                                                                                  *
+ * Parameters:  hist    - [IN] the history storage interface                        *
+ *              history - [IN] the history data vector (may have mixed value types) *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_add_values(zbx_history_iface_t *hist, const zbx_vector_ptr_t *history)
+{
+	const char	*__function_name = "clickhouse_add_values";
+
+	char *tmp_buffer=NULL;	
+	size_t tmp_alloc=0, tmp_offset=0;
+
+	zbx_clickhouse_data_t	*data = hist->data;
+	int			i, j, num = 0;
+	ZBX_DC_HISTORY		*h;
+
+	size_t			buf_alloc = 0, buf_offset = 0;
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s()", __function_name);
+	
+
+	zbx_snprintf_alloc(&tmp_buffer,&tmp_alloc,&tmp_offset,"INSERT INTO %s VALUES ", CONFIG_HISTORY_STORAGE_TABLE_NAME );
+
+	for (i = 0; i < history->values_num; i++)
+	{
+		h = (ZBX_DC_HISTORY *)history->values[i];
+
+		if (hist->value_type != h->value_type)
+			continue;
+
+		
+		 if (ITEM_VALUE_TYPE_UINT64 == h->value_type) {
+		    //zabbix_log(LOG_LEVEL_DEBUG, "Parsing value as UIN64 type");
+		    zbx_snprintf_alloc(&tmp_buffer,&tmp_alloc,&tmp_offset,"(CAST(%d as date) ,%ld,%d,%d,%ld,0,''),",
+					h->ts.sec,h->itemid,h->ts.sec,h->ts.ns,h->value.ui64);
+		}
+
+		 if (ITEM_VALUE_TYPE_FLOAT == h->value_type) {
+		    //zabbix_log(LOG_LEVEL_DEBUG, "Parsing value as float type");
+		    zbx_snprintf_alloc(&tmp_buffer,&tmp_alloc,&tmp_offset,"(CAST(%d as date) ,%ld,%d,%d,0,%f,''),",
+					h->ts.sec,h->itemid,h->ts.sec,h->ts.ns,h->value.dbl);
+		}
+
+		 if (ITEM_VALUE_TYPE_STR == h->value_type || 
+		 	 ITEM_VALUE_TYPE_TEXT == h->value_type ) {
+		    //zabbix_log(LOG_LEVEL_DEBUG, "Parsing value as string or text type");
+			for (j = 0; j < strlen(h->value.str); j++) {
+				if ('\'' == h->value.str[j]) { 
+					h ->value.str[j]=' ';
+				}
+			}
+		    zbx_snprintf_alloc(&tmp_buffer,&tmp_alloc,&tmp_offset,"(CAST(%d as date) ,%ld,%d,%d,0,0,'%s'),",
+					h->ts.sec,h->itemid,h->ts.sec,h->ts.ns,h->value.str);
+		}
+
+		if (ITEM_VALUE_TYPE_LOG == h->value_type)
+		{
+			const zbx_log_value_t	*log;
+			log = h->value.log;
+		}
+
+		num++;
+	}
+
+	if (num > 0)
+	{ 
+		zbx_snprintf_alloc(&data->buf, &buf_alloc, &buf_offset, "%s\n", tmp_buffer);
+		zabbix_log(LOG_LEVEL_DEBUG, "will insert to clickhouse: %s",data->buf);
+	
+		//data->post_url = zbx_dsprintf(NULL, "%s", data->base_url);
+		clickhouse_writer_add_iface(hist);
+	}
+
+	zbx_free(tmp_buffer);
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
+	
+	return num;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_flush                                                          *
+ *                                                                                  *
+ * Purpose: flushes the history data to storage                                     *
+ *                                                                                  *
+ * Parameters:  hist    - [IN] the history storage interface                        *
+ *                                                                                  *
+ * Comments: This function will try to flush the data until it succeeds or          *
+ *           unrecoverable error occurs                                             *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_flush(zbx_history_iface_t *hist)
+{
+	ZBX_UNUSED(hist);
+
+	return clickhouse_writer_flush();
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: zbx_history_clickhouse_init                                               *
+ *                                                                                  *
+ * Purpose: initializes history storage interface                                   *
+ *                                                                                  *
+ * Parameters:  hist       - [IN] the history storage interface                     *
+ *              value_type - [IN] the target value type                             *
+ *              error      - [OUT] the error message                                *
+ *                                                                                  *
+ * Return value: SUCCEED - the history storage interface was initialized            *
+ *               FAIL    - otherwise                                                *
+ *                                                                                  *
+ ************************************************************************************/
+int	zbx_history_clickhouse_init(zbx_history_iface_t *hist, unsigned char value_type, char **error)
+{
+	zbx_clickhouse_data_t	*data;
+
+	if (0 != curl_global_init(CURL_GLOBAL_ALL))
+	{
+		*error = zbx_strdup(*error, "Cannot initialize cURL library");
+		return FAIL;
+	}
+
+	data = zbx_malloc(NULL, sizeof(zbx_clickhouse_data_t));
+	memset(data, 0, sizeof(zbx_clickhouse_data_t));
+	data->base_url = zbx_strdup(NULL, CONFIG_HISTORY_STORAGE_URL);
+	zbx_rtrim(data->base_url, "/");
+	data->buf = NULL;
+	//data->post_url = NULL;
+	data->handle = NULL;
+
+	hist->value_type = value_type;
+	hist->data = data;
+	hist->destroy = clickhouse_destroy;
+	hist->add_values = clickhouse_add_values;
+	hist->flush = clickhouse_flush;
+	hist->get_values = clickhouse_get_values;
+	hist->requires_trends = 0;
+
+	return SUCCEED;
+}
+
+#else
+
+int	zbx_history_clickhouse_init(zbx_history_iface_t *hist, unsigned char value_type, char **error)
+{
+	ZBX_UNUSED(hist);
+	ZBX_UNUSED(value_type);
+
+	*error = zbx_strdup(*error, "cURL library support >= 7.28.0 is required for clickhouse history backend");
+	return FAIL;
+}
+
+#endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/libs/zbxhistory/history.h xe-rabbix/src/libs/zbxhistory/history.h
--- zabbix-4.0.1/src/libs/zbxhistory/history.h	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/libs/zbxhistory/history.h	2018-12-14 11:20:58.422477678 +0500
@@ -49,4 +49,7 @@
 /* elastic hist */
 int	zbx_history_elastic_init(zbx_history_iface_t *hist, unsigned char value_type, char **error);
 
+/* clickhouse hist */
+int	zbx_history_clickhouse_init(zbx_history_iface_t *hist, unsigned char value_type, char **error);
+
 #endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/libs/zbxhistory/Makefile.am xe-rabbix/src/libs/zbxhistory/Makefile.am
--- zabbix-4.0.1/src/libs/zbxhistory/Makefile.am	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/libs/zbxhistory/Makefile.am	2018-12-14 11:20:58.422477678 +0500
@@ -5,4 +5,5 @@
 libzbxhistory_a_SOURCES = \
 	history.c history.h \
 	history_sql.c \
-	history_elastic.c 
+	history_elastic.c \
+	history_clickhouse.c
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/libs/zbxhistory/Makefile.in xe-rabbix/src/libs/zbxhistory/Makefile.in
--- zabbix-4.0.1/src/libs/zbxhistory/Makefile.in	2018-10-29 22:36:11.000000000 +0500
+++ xe-rabbix/src/libs/zbxhistory/Makefile.in	2018-12-14 11:20:58.422477678 +0500
@@ -121,7 +121,7 @@
 libzbxhistory_a_AR = $(AR) $(ARFLAGS)
 libzbxhistory_a_LIBADD =
 am_libzbxhistory_a_OBJECTS = history.$(OBJEXT) history_sql.$(OBJEXT) \
-	history_elastic.$(OBJEXT)
+	history_elastic.$(OBJEXT) history_clickhouse.$(OBJEXT) 
 libzbxhistory_a_OBJECTS = $(am_libzbxhistory_a_OBJECTS)
 AM_V_P = $(am__v_P_@AM_V@)
 am__v_P_ = $(am__v_P_@AM_DEFAULT_V@)
@@ -381,7 +381,8 @@
 libzbxhistory_a_SOURCES = \
 	history.c history.h \
 	history_sql.c \
-	history_elastic.c 
+	history_elastic.c \
+	history_clickhouse.c 
 
 all: all-am
 
@@ -434,6 +435,7 @@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/history.Po@am__quote@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/history_elastic.Po@am__quote@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/history_sql.Po@am__quote@
+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/history_clickhouse.Po@am__quote@
 
 .c.o:
 @am__fastdepCC_TRUE@	$(AM_V_CC)depbase=`echo $@ | sed 's|[^/]*$$|$(DEPDIR)/&|;s|\.o$$||'`;\
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/libs/zbxicmpping/icmpping.c xe-rabbix/src/libs/zbxicmpping/icmpping.c
--- zabbix-4.0.1/src/libs/zbxicmpping/icmpping.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/libs/zbxicmpping/icmpping.c	2018-12-14 11:20:58.422477678 +0500
@@ -24,10 +24,14 @@
 
 extern char	*CONFIG_SOURCE_IP;
 extern char	*CONFIG_FPING_LOCATION;
+extern char	*CONFIG_NMAP_LOCATION;
+extern char	*CONFIG_NMAP_PARAMS;
+
 #ifdef HAVE_IPV6
 extern char	*CONFIG_FPING6_LOCATION;
 #endif
 extern char	*CONFIG_TMPDIR;
+#define MAX_ICMP_NMAP_FIELDS		10
 
 /* old official fping (2.4b2_to_ipv6) did not support source IP address */
 /* old patched versions (2.4b2_to_ipv6) provided either -I or -S options */
@@ -73,6 +77,7 @@
 	*checked = 1;
 }
 
+
 static int	process_ping(ZBX_FPING_HOST *hosts, int hosts_count, int count, int interval, int size, int timeout,
 		char *error, int max_error_len)
 {
@@ -242,134 +247,287 @@
 
 	fclose(f);
 
-	zabbix_log(LOG_LEVEL_DEBUG, "%s", tmp);
+	//use 1 packet as an indication that we want to use nmap
+	//since it's turned out that doing one packet check via vping is also a good idea, 
+	// timeout =1 (not realistic value ) used to indicate we want nmap to be invoked
+	// this also allows to runtime modification of the utility
+	if ( 1 == count ) 
+	{
+		//for 1-packet probes use nmap as accesibility utility
+		//ipv6 ??? i guess it won't work, but who knows: todo: check and fix ipv6 as soon as we have it
+
+		if (-1 == size ) size=32;
+		
+		zbx_snprintf(tmp, sizeof(tmp), "%s --data-length=%d %s -iL %s 2>&1",
+								CONFIG_NMAP_LOCATION,size,CONFIG_NMAP_PARAMS,filename);
 
-	if (NULL == (f = popen(tmp, "r")))
-	{
-		zbx_snprintf(error, max_error_len, "%s: %s", tmp, zbx_strerror(errno));
 
-		unlink(filename);
-
-		return ret;
-	}
+		zabbix_log(LOG_LEVEL_DEBUG, "Will run %s", tmp);
 
-	if (NULL == fgets(tmp, sizeof(tmp), f))
-	{
-		strscpy(tmp, "no output");
-	}
-	else
-	{
 		for (i = 0; i < hosts_count; i++)
 		{
-			hosts[i].status = (char *)zbx_malloc(NULL, count);
-			memset(hosts[i].status, 0, count);
+			hosts[i].rcv=0;
+			hosts[i].cnt=count;
 		}
 
+		if ( NULL == (f = popen(tmp, "r")))
+		{
+			zbx_snprintf(error, max_error_len, "%s: %s", tmp, zbx_strerror(errno));
+			unlink(filename);
+			return ret;
+		}
+
+		//	memset(tmp,0,sizeof(char)*
+		if ( NULL == fgets(tmp, sizeof(tmp), f)) {
+			zbx_snprintf(error, max_error_len, "Nmap failed: empty output");
+			return ret;
+		}
+		
 		do
 		{
+			char *fields[MAX_ICMP_NMAP_FIELDS];
+			char *end_field;
+			char *latency;
+
 			zbx_rtrim(tmp, "\n");
 			zabbix_log(LOG_LEVEL_DEBUG, "read line [%s]", tmp);
 
+			if (25 > strnlen(tmp,MAX_STRING_LEN) ) {
+				zabbix_log(LOG_LEVEL_DEBUG, "skipping too short line");
+				continue;
+			} 
+
+			//splitting line into fields
+			char *field_ptr = strtok_r(tmp, " ", &end_field);
+			int field_count=0;
+
+			for (i=0; i++; i<field_count) 
+				fields[i]=NULL; 
+
+			while ( field_ptr != NULL && MAX_ICMP_NMAP_FIELDS > field_count) 
+			{	
+				zabbix_log(LOG_LEVEL_DEBUG, "read field %d [%s]",field_count, field_ptr);
+			    fields[field_count++]=field_ptr;
+			    field_ptr = strtok_r(NULL, " ", &end_field);
+			}
+
+			if ( NULL == fields[4]) {
+				zabbix_log(LOG_LEVEL_DEBUG, "String 1 has not enough fields ");
+				continue;
+			}
+			
+			if (strcmp("Nmap",fields[0]) != 0 ||
+				strcmp("scan",fields[1]) !=0  ||
+				strcmp("report", fields[2]) !=0 )  
+			{  
+				zabbix_log(LOG_LEVEL_DEBUG, "String doesn't match 'Nmap scan for', skipping");
+				continue;
+			}
+
 			host = NULL;
 
-			if (NULL != (c = strchr(tmp, ' ')))
+			for (i = 0; i < hosts_count; i++)
 			{
-				*c = '\0';
-				for (i = 0; i < hosts_count; i++)
-					if (0 == strcmp(tmp, hosts[i].addr))
-					{
-						host = &hosts[i];
-						break;
-					}
-				*c = ' ';
+				if (0 == strcmp(fields[4], hosts[i].addr))
+				{
+					host = &hosts[i];
+					zabbix_log(LOG_LEVEL_DEBUG, "Host has been found %s", fields[4]);
+					break;
+				}
 			}
 
-			if (NULL == host)
+			if (NULL == host) {
+				zabbix_log(LOG_LEVEL_DEBUG, "Host hasn't been found in the request");
 				continue;
+			} else {
+				zabbix_log(LOG_LEVEL_DEBUG, "Host has been found %s", fields[4]);
+			}
 
-			if (NULL == (c = strstr(tmp, " : ")))
+			if (NULL == fgets(tmp, sizeof(tmp), f)) {
+				zabbix_log(LOG_LEVEL_DEBUG, "Couldn't read second line");
 				continue;
+			}
+
+			zabbix_log(LOG_LEVEL_DEBUG, "read line %s", tmp);
+			zbx_rtrim(tmp, "\n");
 
-			/* when NIC bonding is used, there are also lines like */
-			/* 192.168.1.2 : duplicate for [0], 96 bytes, 0.19 ms */
+			field_ptr = strtok_r(tmp, " ", &end_field);
 
-			if (NULL != strstr(tmp, "duplicate for"))
-				continue;
+			for (i = 0; i++; i<field_count)
+				fields[i]=NULL;
+
+			field_count=0;
 
-			c += 3;
+			while (field_ptr != NULL && MAX_ICMP_NMAP_FIELDS>field_count) 
+			{	
+				zabbix_log(LOG_LEVEL_DEBUG, "String 2 parced field %s",field_ptr);
+				fields[field_count++]=field_ptr;
+				field_ptr = strtok_r(NULL, " ", &end_field);
+			}
+
+			if (NULL == fields[3]) {
+				zabbix_log(LOG_LEVEL_DEBUG, "String too short");
+				continue;
+			}
 
-			/* The were two issues with processing only the fping's final status line:  */
-			/*   1) pinging broadcast addresses could have resulted in responses from   */
-			/*      different hosts, which were counted as the target host responses;   */
-			/*   2) there is a bug in fping (v3.8 at least) where pinging broadcast     */
-			/*      address will result in no individual responses, but the final       */
-			/*      status line might contain a bogus value.                            */
-			/* Because of the above issues we must monitor the individual responses     */
-			/* and mark the valid ones.                                                 */
-			if ('[' == *c)
+			if ( 0 != strncmp(fields[0], "Host", 2) ||
+				 0 != strncmp(fields[1], "is", 2)  ||
+				 0 != strncmp(fields[2], "up", 2) ) 
 			{
-				/* Fping appends response source address in format '[<- 10.3.0.10]' */
-				/* if it does not match the target address. Ignore such responses.  */
-				if (NULL != strstr(c + 1, "[<-"))
-					continue;
+				zabbix_log(LOG_LEVEL_DEBUG, "String 2 doesn't match 'Host is up', skipping");
+				continue;
+			}
 
-				/* get the index of individual ping response */
-				index = atoi(c + 1);
+			latency=fields[3]+1;
+			zbx_rtrim(latency,"s");
+			sec=atof(latency);
+
+			host->rcv=count;
+			host->min=sec;
+			host->max=sec;
+			host->sum=sec*count;
 
-				if (0 > index || index >= count)
-					continue;
+			zabbix_log(LOG_LEVEL_DEBUG, "Final parced info is host=%s , latency=%f",host->addr,sec);
 
-				host->status[index] = 1;
+			ret = SUCCEED;
+		}
+		while (NULL != fgets(tmp, sizeof(tmp), f));
 
-				continue;
+		if (NOTSUPPORTED == ret)
+			zbx_snprintf(error, max_error_len, "Nmap failed");
+
+	} else 
+	{
+		//doing things fping way
+		zabbix_log(LOG_LEVEL_DEBUG, "%s", tmp);
+
+		if (NULL == (f = popen(tmp, "r")))
+		{
+			zbx_snprintf(error, max_error_len, "%s: %s", tmp, zbx_strerror(errno));
+			unlink(filename);
+			return ret;
+		}
+
+		if (NULL == fgets(tmp, sizeof(tmp), f))
+		{
+			strscpy(tmp, "no output");
+		}
+		else
+		{
+			for (i = 0; i < hosts_count; i++)
+			{
+				hosts[i].status = (char *)zbx_malloc(NULL, count);
+				memset(hosts[i].status, 0, count);
 			}
 
-			/* process status line for a host */
-			index = 0;
 			do
 			{
-				if (1 == host->status[index])
+				zbx_rtrim(tmp, "\n");
+				zabbix_log(LOG_LEVEL_DEBUG, "read line [%s]", tmp);
+
+				host = NULL;
+
+				if (NULL != (c = strchr(tmp, ' ')))
+				{
+					*c = '\0';
+					for (i = 0; i < hosts_count; i++)
+						if (0 == strcmp(tmp, hosts[i].addr))
+						{
+							host = &hosts[i];
+							break;
+						}
+					*c = ' ';
+				}
+
+				if (NULL == host)
+					continue;
+
+				if (NULL == (c = strstr(tmp, " : ")))
+					continue;
+
+				/* when NIC bonding is used, there are also lines like */
+				/* 192.168.1.2 : duplicate for [0], 96 bytes, 0.19 ms */
+
+				if (NULL != strstr(tmp, "duplicate for"))
+					continue;
+
+				c += 3;
+
+				/* The were two issues with processing only the fping's final status line:  */
+				/*   1) pinging broadcast addresses could have resulted in responses from   */
+				/*      different hosts, which were counted as the target host responses;   */
+				/*   2) there is a bug in fping (v3.8 at least) where pinging broadcast     */
+				/*      address will result in no individual responses, but the final       */
+				/*      status line might contain a bogus value.                            */
+				/* Because of the above issues we must monitor the individual responses     */
+				/* and mark the valid ones.                                                 */
+				if ('[' == *c)
 				{
-					sec = atof(c) / 1000; /* convert ms to seconds */
+					/* Fping appends response source address in format '[<- 10.3.0.10]' */
+					/* if it does not match the target address. Ignore such responses.  */
+					if (NULL != strstr(c + 1, "[<-"))
+						continue;
+
+					/* get the index of individual ping response */
+					index = atoi(c + 1);
+
+					if (0 > index || index >= count)
+						continue;
 
-					if (0 == host->rcv || host->min > sec)
-						host->min = sec;
-					if (0 == host->rcv || host->max < sec)
-						host->max = sec;
-					host->sum += sec;
-					host->rcv++;
+					host->status[index] = 1;
+
+					continue;
 				}
-			}
-			while (++index < count && NULL != (c = strchr(c + 1, ' ')));
 
-			host->cnt += count;
+				/* process status line for a host */
+				index = 0;
+				do
+				{
+					if (1 == host->status[index])
+					{
+						sec = atof(c) / 1000; /* convert ms to seconds */
+
+						if (0 == host->rcv || host->min > sec)
+							host->min = sec;
+						if (0 == host->rcv || host->max < sec)
+							host->max = sec;
+						host->sum += sec;
+						host->rcv++;
+					}
+				}
+				while (++index < count && NULL != (c = strchr(c + 1, ' ')));
+
+				host->cnt += count;
 #ifdef HAVE_IPV6
-			if (host->cnt == count && NULL == CONFIG_SOURCE_IP &&
-					0 != (fping_existence & FPING_EXISTS) &&
-					0 != (fping_existence & FPING6_EXISTS))
-			{
-				memset(host->status, 0, count);	/* reset response statuses for IPv6 */
-			}
+				if (host->cnt == count && NULL == CONFIG_SOURCE_IP &&
+						0 != (fping_existence & FPING_EXISTS) &&
+						0 != (fping_existence & FPING6_EXISTS))
+				{
+					memset(host->status, 0, count);	/* reset response statuses for IPv6 */
+				}
 #endif
-			ret = SUCCEED;
+				ret = SUCCEED;
+			}
+			while (NULL != fgets(tmp, sizeof(tmp), f));
+
+			for (i = 0; i < hosts_count; i++)
+				zbx_free(hosts[i].status);
 		}
-		while (NULL != fgets(tmp, sizeof(tmp), f));
 
-		for (i = 0; i < hosts_count; i++)
-			zbx_free(hosts[i].status);
+		if (NOTSUPPORTED == ret)
+			zbx_snprintf(error, max_error_len, "fping failed: %s", tmp);
 	}
-	pclose(f);
 
+	pclose(f);
 	unlink(filename);
 
-	if (NOTSUPPORTED == ret)
-		zbx_snprintf(error, max_error_len, "fping failed: %s", tmp);
 
 	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
 
 	return ret;
 }
 
+
 /******************************************************************************
  *                                                                            *
  * Function: do_ping                                                          *
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/libs/zbxself/selfmon.c xe-rabbix/src/libs/zbxself/selfmon.c
--- zabbix-4.0.1/src/libs/zbxself/selfmon.c	2018-10-29 22:36:01.000000000 +0500
+++ xe-rabbix/src/libs/zbxself/selfmon.c	2018-12-14 11:20:58.446478174 +0500
@@ -89,6 +89,8 @@
 extern char	*CONFIG_FILE;
 extern int	CONFIG_POLLER_FORKS;
 extern int	CONFIG_UNREACHABLE_POLLER_FORKS;
+extern int	CONFIG_ASYNC_SNMP_POLLER_FORKS;
+extern int	CONFIG_ASYNC_AGENT_POLLER_FORKS;
 extern int	CONFIG_IPMIPOLLER_FORKS;
 extern int	CONFIG_PINGER_FORKS;
 extern int	CONFIG_JAVAPOLLER_FORKS;
@@ -138,6 +140,10 @@
 	{
 		case ZBX_PROCESS_TYPE_POLLER:
 			return CONFIG_POLLER_FORKS;
+		case ZBX_PROCESS_TYPE_ASYNC_AGENT:
+			return CONFIG_ASYNC_AGENT_POLLER_FORKS;
+		case ZBX_PROCESS_TYPE_ASYNC_SNMP:
+			return CONFIG_ASYNC_SNMP_POLLER_FORKS;
 		case ZBX_PROCESS_TYPE_UNREACHABLE:
 			return CONFIG_UNREACHABLE_POLLER_FORKS;
 		case ZBX_PROCESS_TYPE_IPMIPOLLER:
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/libs/zbxserver/expression.c xe-rabbix/src/libs/zbxserver/expression.c
--- zabbix-4.0.1/src/libs/zbxserver/expression.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/libs/zbxserver/expression.c	2018-12-14 11:20:58.446478174 +0500
@@ -3758,6 +3758,11 @@
 					ret = DBget_trigger_value(event->trigger.expression, &replace_to, N_functionid,
 							ZBX_REQUEST_HOST_DNS);
 				}
+				else if (0 == strcmp(m, MVAR_HOST_DESCRIPTION))
+				{
+					ret = DBget_trigger_value(event->trigger.expression, &replace_to, N_functionid,
+							ZBX_REQUEST_HOST_DESCRIPTION);
+				}
 				else if (0 == strcmp(m, MVAR_HOST_CONN))
 				{
 					ret = DBget_trigger_value(event->trigger.expression, &replace_to, N_functionid,
@@ -4660,7 +4665,7 @@
 	zbx_hashset_iter_t	iter;
 
 	zabbix_log(LOG_LEVEL_DEBUG, "In %s() funcs_num:%d", __function_name, funcs->num_data);
-
+	
 	zbx_vector_uint64_create(&itemids);
 	zbx_vector_uint64_reserve(&itemids, funcs->num_data);
 
@@ -4675,7 +4680,6 @@
 	errcodes = (int *)zbx_malloc(errcodes, sizeof(int) * (size_t)itemids.values_num);
 
 	DCconfig_get_items_by_itemids(items, itemids.values, errcodes, itemids.values_num);
-
 	zbx_hashset_iter_reset(funcs, &iter);
 	while (NULL != (func = (zbx_func_t *)zbx_hashset_iter_next(&iter)))
 	{
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_proxy/proxy.c xe-rabbix/src/zabbix_proxy/proxy.c
--- zabbix-4.0.1/src/zabbix_proxy/proxy.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_proxy/proxy.c	2018-12-14 11:20:58.450478256 +0500
@@ -144,6 +144,7 @@
 int	CONFIG_PINGER_FORKS		= 1;
 int	CONFIG_POLLER_FORKS		= 5;
 int	CONFIG_UNREACHABLE_POLLER_FORKS	= 1;
+int	CONFIG_ASYNC_POLLER_FORKS	= 2;
 int	CONFIG_HTTPPOLLER_FORKS		= 1;
 int	CONFIG_IPMIPOLLER_FORKS		= 0;
 int	CONFIG_TRAPPER_FORKS		= 5;
@@ -262,6 +263,13 @@
 
 char	*CONFIG_HISTORY_STORAGE_URL		= NULL;
 char	*CONFIG_HISTORY_STORAGE_OPTS		= NULL;
+char	*CONFIG_HISTORY_STORAGE_TYPE		= NULL;
+char	*CONFIG_HISTORY_STORAGE_TABLE_NAME		= NULL;
+
+
+char *CONFIG_NMAP_PARAMS = NULL;
+char *CONFIG_NMAP_LOCATION = NULL;
+
 int	CONFIG_HISTORY_STORAGE_PIPELINES	= 0;
 
 int	get_process_info_by_thread(int local_server_num, unsigned char *local_process_type, int *local_process_num);
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_server/events.c xe-rabbix/src/zabbix_server/events.c
--- zabbix-4.0.1/src/zabbix_server/events.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_server/events.c	2018-12-14 11:20:58.450478256 +0500
@@ -1716,7 +1716,11 @@
 		zbx_hashset_clear(&hosts);
 		zbx_vector_uint64_clear(&hostids);
 
-		zbx_problems_export_write(json.buffer, json.buffer_size);
+		if (SUCCEED == zbx_is_export_enabled())
+			zbx_problems_export_write(json.buffer, json.buffer_size);
+
+		zbx_register_problem(events[i].eventid, json.buffer);
+
 	}
 
 	zbx_hashset_iter_reset(&event_recovery, &iter);
@@ -1734,8 +1738,10 @@
 		zbx_json_addint64(&json, ZBX_PROTO_TAG_VALUE, event->value);
 		zbx_json_adduint64(&json, ZBX_PROTO_TAG_EVENTID, event->eventid);
 		zbx_json_adduint64(&json, ZBX_PROTO_TAG_PROBLEM_EVENTID, recovery->eventid);
-
-		zbx_problems_export_write(json.buffer, json.buffer_size);
+		
+		if (SUCCEED == zbx_is_export_enabled())
+			zbx_problems_export_write(json.buffer, json.buffer_size);
+		zbx_register_problem_recovery(recovery->eventid);
 	}
 
 	zbx_problems_export_flush();
@@ -2563,8 +2569,11 @@
 		DCconfig_triggers_apply_changes(&trigger_diff);
 		DBupdate_itservices(&trigger_diff);
 
-		if (SUCCEED == zbx_is_export_enabled())
-			zbx_export_events();
+		//export is used to keep problems hash in memory, but data is flushed to dissk only if export is enabled
+		//inside zbx_export_events() 
+		
+		//if (SUCCEED == zbx_is_export_enabled())
+		zbx_export_events();
 
 		zbx_clean_events();
 		zbx_vector_ptr_clear_ext(&trigger_diff, (zbx_clean_func_t)zbx_trigger_diff_free);
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_server/pinger/pinger.c xe-rabbix/src/zabbix_server/pinger/pinger.c
--- zabbix-4.0.1/src/zabbix_server/pinger/pinger.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_server/pinger/pinger.c	2018-12-14 11:20:58.450478256 +0500
@@ -411,13 +411,20 @@
 static void	get_pinger_hosts(icmpitem_t **icmp_items, int *icmp_items_alloc, int *icmp_items_count)
 {
 	const char		*__function_name = "get_pinger_hosts";
-	DC_ITEM			items[MAX_PINGER_ITEMS];
+	DC_ITEM			*items;
 	int			i, num, count, interval, size, timeout, rc, errcode = SUCCEED;
 	char			error[MAX_STRING_LEN], *addr = NULL;
 	icmpping_t		icmpping;
 	icmppingsec_type_t	type;
 
 	zabbix_log(LOG_LEVEL_DEBUG, "In %s()", __function_name);
+	
+
+	if (NULL == (items=zbx_malloc(NULL,sizeof(DC_ITEM)*MAX_PINGER_ITEMS))) 
+	{
+		zabbix_log(LOG_LEVEL_WARNING,"Cannot allocate memory for pinger items");
+		return;
+	}
 
 	num = DCconfig_get_poller_items(ZBX_POLLER_TYPE_PINGER, items);
 
@@ -455,9 +462,8 @@
 	}
 
 	DCconfig_clean_items(items, NULL, num);
-
+	zbx_free(items);
 	zbx_preprocessor_flush();
-
 	zabbix_log(LOG_LEVEL_DEBUG, "End of %s():%d", __function_name, *icmp_items_count);
 }
 
@@ -540,7 +546,8 @@
 		if (i == items_count - 1 || items[i].count != items[i + 1].count || items[i].interval != items[i + 1].interval ||
 				items[i].size != items[i + 1].size || items[i].timeout != items[i + 1].timeout)
 		{
-			zbx_setproctitle("%s #%d [pinging hosts]", get_process_type_string(process_type), process_num);
+			//that useless as most of the time process status is "pinging hosts"
+			//zbx_setproctitle("%s #%d [pinging hosts]", get_process_type_string(process_type), process_num);
 
 			zbx_timespec(&ts);
 
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_server/poller/checks_agent.c xe-rabbix/src/zabbix_server/poller/checks_agent.c
--- zabbix-4.0.1/src/zabbix_server/poller/checks_agent.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_server/poller/checks_agent.c	2018-12-14 11:20:58.450478256 +0500
@@ -152,3 +152,297 @@
 
 	return ret;
 }
+
+#define INIT			10
+#define SKIPPED			11
+#define SOCKET_CREATED	12
+#define CONNECT_SENT	13
+#define REQ_SENT		14
+#define	CLOSED			15
+#define ZBX_AGENT_MAX_RESPONSE_TIME 2
+
+//this function follows the socket status and 
+//handles operations according to the socket state
+void handle_socket_operation(zbx_socket_t *socket, DC_ITEM * item, int *errcode, int *conn_status, 
+						 AGENT_RESULT *result, int *active_agents) 
+{
+	
+	ZBX_SOCKADDR	servaddr_in;
+	struct hostent	*hp;
+	ssize_t		received_len;
+	
+	int status;
+
+	switch (*conn_status) {
+		case SOCKET_CREATED:
+			zabbix_log(LOG_LEVEL_DEBUG,"Starting connect to item");
+
+			if (NULL == (hp = gethostbyname(item->interface.addr)))
+			{
+				SET_MSG_RESULT(result, zbx_strdup(NULL, "Cannot get hostname for the ip."));
+				*conn_status=FAIL;
+				*errcode=CONFIG_ERROR;
+				break;	
+			}
+#if !defined(_WINDOWS) && !SOCK_CLOEXEC
+			fcntl(socket->socket, F_SETFD, FD_CLOEXEC);
+#endif
+			servaddr_in.sin_family = AF_INET;
+			servaddr_in.sin_addr.s_addr = ((struct in_addr *)(hp->h_addr))->s_addr;
+			servaddr_in.sin_port = htons(item->interface.port);
+			
+			zabbix_log(LOG_LEVEL_DEBUG,"Doing connect to host %s",item->interface.addr);
+
+			status = connect(socket->socket, (const struct sockaddr *)&servaddr_in, sizeof(servaddr_in));
+			
+			//async connects will return immediately with the error status and EINPROGRESS as errno
+			if (ZBX_PROTO_ERROR == status && EINPROGRESS != errno )
+			{	
+				zabbix_log(LOG_LEVEL_DEBUG,"Connect fail");
+				*conn_status = FAIL;
+				*errcode = CONFIG_ERROR;
+				SET_MSG_RESULT(result, zbx_strdup(NULL, "Cannot  connect to the host"));
+				break;	
+			}
+
+			*conn_status=CONNECT_SENT;
+			break;
+
+		case CONNECT_SENT:
+			zabbix_log(LOG_LEVEL_DEBUG,"Sending data to the socket");
+
+			if (SUCCEED != zbx_tcp_send(socket, item->key))
+			{
+				*errcode = NETWORK_ERROR;
+				*conn_status = FAIL;
+				SET_MSG_RESULT(result, zbx_strdup(NULL, "Cannot send request to the agent"));
+				zabbix_log(LOG_LEVEL_DEBUG,"Data send fail, aborting session");
+			}
+			
+			*conn_status=REQ_SENT;
+			break;
+
+		case REQ_SENT:
+			if (FAIL != (received_len = zbx_tcp_recv_ext(socket, 0)))
+			{
+				*errcode = SUCCEED;
+				zabbix_log(LOG_LEVEL_DEBUG, "get value from agent result: '%s'", socket->buffer);
+
+				zbx_rtrim(socket->buffer, " \r\n");
+				zbx_ltrim(socket->buffer, " ");
+
+				if (0 == strcmp(socket->buffer, ZBX_NOTSUPPORTED))
+				{
+					/* 'ZBX_NOTSUPPORTED\0<error message>' */
+					if (sizeof(ZBX_NOTSUPPORTED) < socket->read_bytes)
+						SET_MSG_RESULT(result, zbx_dsprintf(NULL, "%s", socket->buffer + sizeof(ZBX_NOTSUPPORTED)));
+					else
+						SET_MSG_RESULT(result, zbx_strdup(NULL, "Not supported by Zabbix Agent"));
+						*errcode = NOTSUPPORTED;
+				}
+				else if (0 == strcmp(socket->buffer, ZBX_ERROR))
+				{
+					SET_MSG_RESULT(result, zbx_strdup(NULL, "Zabbix Agent non-critical error"));
+					*errcode = AGENT_ERROR;
+				}
+				else if (0 == received_len)
+				{
+					SET_MSG_RESULT(result, zbx_dsprintf(NULL, "Received empty response from Zabbix Agent at [%s]."
+						" Assuming that agent dropped connection because of access permissions.", item->interface.addr));
+					*errcode = NETWORK_ERROR;
+				}
+				else
+					set_result_type(result, ITEM_VALUE_TYPE_TEXT, socket->buffer);
+			} else 
+			{
+					zabbix_log(LOG_LEVEL_DEBUG, "Get value from agent failed: %s", zbx_socket_strerror());
+					SET_MSG_RESULT(result, zbx_dsprintf(NULL, "Get value from agent failed: %s", zbx_socket_strerror()));
+					*errcode=NETWORK_ERROR;
+			}					
+		
+			zbx_tcp_close(socket);				
+			
+			socket->socket=0;
+			*conn_status=FAIL;
+			
+			*active_agents=*active_agents-1;
+			
+			zabbix_log(LOG_LEVEL_DEBUG, "finished socket processing %d",*active_agents);
+			break;
+	} 
+
+}
+
+
+int	get_value_agent_async(DC_ITEM *items, AGENT_RESULT *results, int *errcodes, int num)
+{
+	const char	*__function_name = "get_value_agent_async";
+	zbx_socket_t	*s;	
+	char		*tls_arg1, *tls_arg2;
+	int			i,	ret=SUCCEED,	max_socket;
+	// connects=0;
+	int 		*conn_status;
+	unsigned int active_agents=0;
+	unsigned int starttime;
+
+
+	zabbix_log(LOG_LEVEL_DEBUG,"Started async agent polling for %d items", num);
+
+	if (NULL == (s=zbx_malloc(NULL, num*sizeof(zbx_socket_t)))) {
+		zabbix_log(LOG_LEVEL_WARNING,"Couldn't allocate memory for sockets");
+		return FAIL;
+	};
+
+	memset(s, 0, num*sizeof(zbx_socket_t));
+	
+	if (NULL == (conn_status=zbx_malloc(NULL, num*sizeof(unsigned int))))
+	{
+		zabbix_log(LOG_LEVEL_WARNING,"Couldn't allocate memory for sockets");
+		return FAIL;
+	};
+
+	//starting connections
+	for ( i = 0; i < num; i++ ) 
+	{
+		conn_status[i]=INIT;
+		s[i].buf_type = ZBX_BUF_TYPE_STAT;
+
+		//cheick if the item is agent type
+		if (  ITEM_TYPE_ZABBIX != items[i].type )	
+		{	
+			conn_status[i]=SKIPPED;
+			continue;
+		}
+			
+		zabbix_log(LOG_LEVEL_TRACE, "In %s() host:'%s' addr:'%s' key:'%s' conn:'%s'", __function_name,
+				items[i].host.host, items[i].interface.addr, items[i].key,
+				zbx_tcp_connection_type_name(items[i].host.tls_connect));
+
+		switch (items[i].host.tls_connect)
+		{
+			case ZBX_TCP_SEC_UNENCRYPTED:
+				tls_arg1 = NULL;
+				tls_arg2 = NULL;
+				break;
+#if defined(HAVE_POLARSSL) || defined(HAVE_GNUTLS) || defined(HAVE_OPENSSL)
+			case ZBX_TCP_SEC_TLS_CERT:
+				tls_arg1 = item->host.tls_issuer;
+				tls_arg2 = item->host.tls_subject;
+				break;
+			case ZBX_TCP_SEC_TLS_PSK:
+				tls_arg1 = items[i].host.tls_psk_identity;
+				tls_arg2 = items[i].host.tls_psk;
+				break;
+#else
+			case ZBX_TCP_SEC_TLS_CERT:
+			case ZBX_TCP_SEC_TLS_PSK:
+				SET_MSG_RESULT(&results[i], zbx_dsprintf(NULL, "A TLS connection is configured to be used with agent"
+					" but support for TLS was not compiled into %s.",
+					get_program_type_string(program_type)));
+				conn_status[i]=SKIPPED;
+				errcodes[i]=CONFIG_ERROR;
+				continue;
+#endif
+			default:
+				THIS_SHOULD_NEVER_HAPPEN;
+				SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Invalid TLS connection parameters."));
+				conn_status[i]=SKIPPED;
+				errcodes[i]=CONFIG_ERROR;
+				continue;
+		}
+
+				
+		if (ZBX_SOCKET_ERROR == (s[i].socket = socket(AF_INET,  SOCK_STREAM | SOCK_NONBLOCK |  SOCK_CLOEXEC, 0)))
+		{
+			conn_status[i]=SKIPPED;
+			errcodes[i]=CONFIG_ERROR;
+			SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Couldn't create socket"));
+			continue;
+		}
+		conn_status[i]=SOCKET_CREATED;
+		max_socket=s[i].socket;
+		active_agents++;
+		
+		//todo: binding to the source ip code
+				
+		handle_socket_operation(&s[i],&items[i],&errcodes[i],&conn_status[i],&results[i],&active_agents);
+		
+	}
+			
+	starttime=time(NULL);
+	zabbix_log(LOG_LEVEL_DEBUG,"Starting waiting for %d sockets to connect",active_agents);
+
+	while (active_agents>0 && (time(NULL)-starttime)< ZBX_AGENT_MAX_RESPONSE_TIME *2) 
+	{
+		
+		//this was the simplest and compact way to implement async io
+		//i has tried select() + FD_ISSET, while its seems to work
+		//it requires much more CPU for large batches of hosts
+		//probably it's worth of trying libevent if some problems arise, especially it's already 
+		//used and linked to the daemon, but one usleep hanles all that 
+		
+		usleep(10000);
+		
+		for ( i=0; i<num; i++) 
+		{
+			if (SKIPPED == conn_status[i] || FAIL == conn_status[i] || CLOSED == conn_status[i]) 
+				continue;
+
+			//the socket is in connection phase, checking that it's ready to be written to
+			if (CONNECT_SENT == conn_status[i]) {
+				int result,ret;
+				socklen_t result_len = sizeof(result);
+				
+				ret=getsockopt(s[i].socket, SOL_SOCKET, SO_ERROR, &result, &result_len); 
+				if (ret<0)
+				{
+    				zabbix_log(LOG_LEVEL_DEBUG, "Connection is not ready yet %d", ret);
+    				continue;
+				}
+				if ( 0!= result ) {
+					zabbix_log(LOG_LEVEL_DEBUG, "Connection %d has failed", i);
+					SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Connection to the host failed: check firewall rules and agent is running"));
+					conn_status[i]==CLOSED;
+					errcodes[i]=NETWORK_ERROR;
+					continue;
+				}
+				
+			} else 	if (REQ_SENT == conn_status[i] ) 
+			{ 
+				//checking if there are some data waiting for us in the socket
+				int count;
+				ioctl(s[i].socket, FIONREAD, &count);
+			
+				if ( 0 == count) continue;  
+				
+			} else {
+				//self-check zabbix team syle: this should never happen :)
+				THIS_SHOULD_NEVER_HAPPEN;
+				continue;
+			}
+
+			handle_socket_operation(&s[i],&items[i],&errcodes[i],&conn_status[i],&results[i],&active_agents);
+		}
+		
+	} 
+	
+	zabbix_log(LOG_LEVEL_DEBUG,"There are %d active connections timed-out",active_agents); 
+
+	//closing sockets for timed out items
+	for ( i = 0; i < num; i++) 
+	{
+		if (s[i].socket) zbx_tcp_close(&s[i]);
+
+		if (REQ_SENT == conn_status[i] || CONNECT_SENT ==conn_status[i]) {
+			zabbix_log(LOG_LEVEL_DEBUG, "Connection %d has timed out while waiting for responce", num);
+			SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Waiting for responce timed out"));
+			errcodes[i]=TIMEOUT_ERROR;
+			continue;
+		}
+	}
+
+	zbx_free(s);
+	zbx_free(conn_status);
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s: %d agents, %d succesifull",__function_name, num, num-active_agents);
+}
+
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_server/poller/checks_agent.h xe-rabbix/src/zabbix_server/poller/checks_agent.h
--- zabbix-4.0.1/src/zabbix_server/poller/checks_agent.h	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_server/poller/checks_agent.h	2018-12-14 11:20:58.450478256 +0500
@@ -27,4 +27,8 @@
 
 int	get_value_agent(DC_ITEM *item, AGENT_RESULT *result);
 
+//this is coming soon 
+int	get_value_agent_async(DC_ITEM *items, AGENT_RESULT *results, int *errcodes, int num);
+
+
 #endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_server/poller/checks_snmp.c xe-rabbix/src/zabbix_server/poller/checks_snmp.c
--- zabbix-4.0.1/src/zabbix_server/poller/checks_snmp.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_server/poller/checks_snmp.c	2019-01-23 10:22:25.413276811 +0500
@@ -24,6 +24,7 @@
 #define SNMP_NO_DEBUGGING		/* disabling debugging messages from Net-SNMP library */
 #include <net-snmp/net-snmp-config.h>
 #include <net-snmp/net-snmp-includes.h>
+#include <net-snmp/library/large_fd_set.h>
 
 #include "comms.h"
 #include "zbxalgo.h"
@@ -1548,14 +1549,23 @@
 	static zbx_mib_norm_t mibs[] =
 	{
 		/* the most popular items first */
+		{LEN_STR("ifHCOutUcastPkts"),".1.3.6.1.2.1.31.1.1.1.11"},
+		{LEN_STR("ifHCInUcastPkts"),".1.3.6.1.2.1.31.1.1.1.7"},
+		{LEN_STR("ifHCInOctets"),	".1.3.6.1.2.1.31.1.1.1.6"},
+		{LEN_STR("ifHCOutOctets"),	".1.3.6.1.2.1.31.1.1.1.10"},
+		{LEN_STR("ifHCOutOctets"),	".1.3.6.1.2.1.31.1.1.1.10"},
+		{LEN_STR("rmon.19.2.0"),	".1.3.6.1.2.1.16.19.2.0"},
+		{LEN_STR("ifHighSpeed"),	".1.3.6.1.2.1.31.1.1.1.15"},
+ 		{LEN_STR("ifAlias"),		".1.3.6.1.2.1.31.1.1.1.18"},
 		{LEN_STR("ifDescr"),		".1.3.6.1.2.1.2.2.1.2"},
 		{LEN_STR("ifInOctets"),		".1.3.6.1.2.1.2.2.1.10"},
 		{LEN_STR("ifOutOctets"),	".1.3.6.1.2.1.2.2.1.16"},
+		{LEN_STR("sysName"),		".1.3.6.1.2.1.1.5"},
 		{LEN_STR("ifAdminStatus"),	".1.3.6.1.2.1.2.2.1.7"},
 		{LEN_STR("ifOperStatus"),	".1.3.6.1.2.1.2.2.1.8"},
 		{LEN_STR("ifIndex"),		".1.3.6.1.2.1.2.2.1.1"},
-		{LEN_STR("ifType"),		".1.3.6.1.2.1.2.2.1.3"},
-		{LEN_STR("ifMtu"),		".1.3.6.1.2.1.2.2.1.4"},
+		{LEN_STR("ifType"),		    ".1.3.6.1.2.1.2.2.1.3"},
+		{LEN_STR("ifMtu"),	  	    ".1.3.6.1.2.1.2.2.1.4"},
 		{LEN_STR("ifSpeed"),		".1.3.6.1.2.1.2.2.1.5"},
 		{LEN_STR("ifPhysAddress"),	".1.3.6.1.2.1.2.2.1.6"},
 		{LEN_STR("ifInUcastPkts"),	".1.3.6.1.2.1.2.2.1.11"},
@@ -1568,6 +1578,10 @@
 		{LEN_STR("ifOutDiscards"),	".1.3.6.1.2.1.2.2.1.19"},
 		{LEN_STR("ifOutErrors"),	".1.3.6.1.2.1.2.2.1.20"},
 		{LEN_STR("ifOutQLen"),		".1.3.6.1.2.1.2.2.1.21"},
+		{LEN_STR("IF-MIB::ifHCOutOctets"),	".1.3.6.1.2.1.31.1.1.1.10"},
+		{LEN_STR("IF-MIB::ifHCInOctets"),	".1.3.6.1.2.1.31.1.1.1.6"},
+		{LEN_STR("IF-MIB::ifOutUcastPkts"),	".1.3.6.1.2.1.2.2.1.17"},
+		{LEN_STR("IF-MIB::ifInUcastPkts"),	".1.3.6.1.2.1.2.2.1.11"},
 		{0}
 	};
 #undef LEN_STR
@@ -2083,46 +2097,38 @@
 
 	struct snmp_session	*ss;
 	char			error[MAX_STRING_LEN];
-	int			i, j, err = SUCCEED, max_succeed = 0, min_fail = MAX_SNMP_ITEMS + 1,
+	int			i,  err = SUCCEED, max_succeed = 0, min_fail = MAX_SNMP_ITEMS + 1,
 				bulk = SNMP_BULK_ENABLED;
 
 	zabbix_log(LOG_LEVEL_DEBUG, "In %s() host:'%s' addr:'%s' num:%d",
 			__function_name, items[0].host.host, items[0].interface.addr, num);
+	
 
-	for (j = 0; j < num; j++)	/* locate first supported item to use as a reference */
-	{
-		if (SUCCEED == errcodes[j])
-			break;
-	}
-
-	if (j == num)	/* all items already NOTSUPPORTED (with invalid key, port or SNMP parameters) */
-		goto out;
-
-	if (NULL == (ss = zbx_snmp_open_session(&items[j], error, sizeof(error))))
+	if (NULL == (ss = zbx_snmp_open_session(&items[0], error, sizeof(error))))
 	{
 		err = NETWORK_ERROR;
 		goto exit;
 	}
 
-	if (0 != (ZBX_FLAG_DISCOVERY_RULE & items[j].flags) || 0 == strncmp(items[j].snmp_oid, "discovery[", 10))
+	if (0 != (ZBX_FLAG_DISCOVERY_RULE & items[0].flags) || 0 == strncmp(items[0].snmp_oid, "discovery[", 10))
 	{
 		int	max_vars;
 
-		max_vars = DCconfig_get_suggested_snmp_vars(items[j].interface.interfaceid, &bulk);
+		max_vars = DCconfig_get_suggested_snmp_vars(items[0].interface.interfaceid, &bulk);
 
-		err = zbx_snmp_process_discovery(ss, &items[j], &results[j], &errcodes[j], error, sizeof(error),
+		err = zbx_snmp_process_discovery(ss, &items[0], &results[0], &errcodes[0], error, sizeof(error),
 				&max_succeed, &min_fail, max_vars, bulk);
 	}
-	else if (NULL != strchr(items[j].snmp_oid, '['))
+	else if (NULL != strchr(items[0].snmp_oid, '['))
 	{
-		(void)DCconfig_get_suggested_snmp_vars(items[j].interface.interfaceid, &bulk);
+		(void)DCconfig_get_suggested_snmp_vars(items[0].interface.interfaceid, &bulk);
 
-		err = zbx_snmp_process_dynamic(ss, items + j, results + j, errcodes + j, num - j, error, sizeof(error),
+		err = zbx_snmp_process_dynamic(ss, items, results, errcodes, num , error, sizeof(error),
 				&max_succeed, &min_fail, bulk);
 	}
 	else
 	{
-		err = zbx_snmp_process_standard(ss, items + j, results + j, errcodes + j, num - j, error, sizeof(error),
+		err = zbx_snmp_process_standard(ss, items, results, errcodes, num , error, sizeof(error),
 				&max_succeed, &min_fail);
 	}
 
@@ -2131,19 +2137,12 @@
 	if (SUCCEED != err)
 	{
 		zabbix_log(LOG_LEVEL_DEBUG, "getting SNMP values failed: %s", error);
-
-		for (i = j; i < num; i++)
-		{
-			if (SUCCEED != errcodes[i])
-				continue;
-
-			SET_MSG_RESULT(&results[i], zbx_strdup(NULL, error));
-			errcodes[i] = err;
-		}
+		SET_MSG_RESULT(&results[0], zbx_strdup(NULL, error));
+		errcodes[0] = err;
 	}
 	else if (SNMP_BULK_ENABLED == bulk && (0 != max_succeed || MAX_SNMP_ITEMS + 1 != min_fail))
 	{
-		DCconfig_update_interface_snmp_stats(items[j].interface.interfaceid, max_succeed, min_fail);
+		DCconfig_update_interface_snmp_stats(items[0].interface.interfaceid, max_succeed, min_fail);
 	}
 out:
 	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
@@ -2154,4 +2153,423 @@
 	init_snmp(progname);
 }
 
+
+
+//to do: consider giving up this function, it's pretty useless, could be replaced by one if statement
+int async_submit_result (int status, struct snmp_session *sp, struct snmp_pdu *response, AGENT_RESULT *result)
+{
+	const char	*__function_name = "async_submit_result";
+	struct variable_list *var;
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In: %s() started ",__function_name);
+
+
+	switch (status) 
+	{
+		case STAT_SUCCESS:
+			var = response->variables;
+		 	zabbix_log(LOG_LEVEL_DEBUG, "In: %s() stat_success %ld",__function_name,response->errstat);
+
+			if (SNMP_ERR_NOERROR == response->errstat) 
+			{
+				zabbix_log(LOG_LEVEL_DEBUG, "In: %s() before while ",__function_name);
+				while (var) 
+				{
+					zabbix_log(LOG_LEVEL_DEBUG, "%s() calling zbx_snmp_set_result ",__function_name);
+					zbx_snmp_set_result(var, result);
+					var = var->next_variable;
+				}
+			} else 
+			{
+				zabbix_log(LOG_LEVEL_DEBUG, "%s() there was an error in SNMP responce from the host",__function_name);
+			}
+			return SUCCEED;
+
+			case STAT_TIMEOUT:
+				zabbix_log(LOG_LEVEL_DEBUG, "%s() there was a timeout in SNMP request to %s",__function_name,sp->peername);
+				return FAIL;
+
+			case STAT_ERROR:
+				zabbix_log(LOG_LEVEL_DEBUG, "%s() there was an error in SNMP responce from %s",__function_name,sp->peername);
+				return 0;
+	}
+	return 0;
+}
+
+/* structures keep thread safe per session configuration to be used in snmp callbacks */
+struct async_snmp_conf
+{
+	size_t	parsed_oid_lens[MAX_ASYNC_SNMP_ITEMS];
+	char	oids_translated[MAX_ASYNC_SNMP_ITEMS][ITEM_SNMP_OID_LEN_MAX];
+	oid		parsed_oids[MAX_ASYNC_SNMP_ITEMS][MAX_OID_LEN];
+
+	int				*errcodes;
+	AGENT_RESULT	*results;
+	const DC_ITEM	*items;
+	int				active_hosts; /* hosts that we have not completed */
+
+};
+
+struct async_snmp_session 
+{
+	struct			snmp_session *sess;		/* SNMP session data */
+	int				current_item;		/* Items index  in the items array we've processing */
+	int				max_items;		//items count int the items array, to stop iterating
+	struct			async_snmp_conf *conf;
+};
+/*
+ * SNMP callback  responce handler
+ */
+int asynch_response(int operation, struct snmp_session *sp, int reqid,
+		    struct snmp_pdu *pdu, void *magic)
+{
+
+	const char	*__function_name = "asynch_response";
+
+	struct async_snmp_session *sess = (struct async_snmp_session *)magic;
+	struct async_snmp_conf *conf=sess->conf;
+
+	struct snmp_pdu *req;
+	zbx_uint64_t	prev_hostid;
+
+	prev_hostid=conf->items[sess->current_item].host.hostid;
+//	zabbix_log(LOG_LEVEL_DEBUG, "In %s() callout hostid %d responce is %u", __function_name,prev_hostid,pdu);
+
+	if (operation != NETSNMP_CALLBACK_OP_RECEIVED_MESSAGE) {
+
+		SET_MSG_RESULT(&conf->results[sess->current_item], zbx_strdup(NULL, "snmp timeout"));
+		conf->errcodes[sess->current_item]=TIMEOUT_ERROR;
+		async_submit_result(STAT_TIMEOUT, sp, pdu,&conf->results[sess->current_item]);
+
+		conf->active_hosts--;
+		return 1;
+	} else 
+	{
+		async_submit_result(STAT_SUCCESS, sess->sess, pdu, &conf->results[sess->current_item]);
+		conf->errcodes[sess->current_item]=SUCCEED;
+	}
+
+	//iterating to next snmp item in the list while processing the same host
+	//and skipping any non-snmp type items 
+	sess->current_item++;
+	while (sess->current_item < sess->max_items ) {
+		if  (SUCCEED == is_snmp_type(conf->items[sess->current_item].type)) {
+			zabbix_log(LOG_LEVEL_DEBUG, "In %s() found snmp item",__function_name);
+			break;
+		}
+		sess->current_item++;
+		zabbix_log(LOG_LEVEL_DEBUG, "In %s() skipping non-snmp item",__function_name);
+	}
+
+	//checking if we're not at the end of items list
+	if ( sess->current_item < sess->max_items) {
+
+		//and still processing the same host
+		if (conf->items[sess->current_item].host.hostid == prev_hostid ) {
+
+			//then sending next oid query in case there is an oid
+			if ( conf->items[sess->current_item].snmp_oid ) {
+
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() Parsing oids and adding null vals", __function_name);
+				conf->parsed_oid_lens[sess->current_item] = MAX_OID_LEN;
+
+				//oid translation
+				if (NULL != conf->items[sess->current_item].snmp_oid )	
+				{
+					zbx_snmp_translate(	conf->oids_translated[sess->current_item], 
+										conf->items[sess->current_item].snmp_oid,
+										sizeof(conf->oids_translated[sess->current_item]));
+				}  else 
+				{
+					SET_MSG_RESULT(	&conf->results[sess->current_item], 
+									zbx_dsprintf(NULL, "zbx_snmp_translate(): cannot parse OID \"%s\".",
+									conf->oids_translated[sess->current_item]));
+					zabbix_log(	LOG_LEVEL_DEBUG, "In %s() cannot translate oid %s for hostid %ld", 
+								__function_name,
+								conf->oids_translated[sess->current_item],
+								conf->items[sess->current_item].host.hostid);
+
+					conf->errcodes[sess->current_item] = CONFIG_ERROR;
+					conf->active_hosts--;
+					return 1;
+				}
+
+				if (NULL == snmp_parse_oid(	conf->oids_translated[sess->current_item],
+											conf->parsed_oids[sess->current_item], 
+											&conf->parsed_oid_lens[sess->current_item])) 
+				{
+					SET_MSG_RESULT(	&conf->results[sess->current_item], 
+									zbx_dsprintf(NULL, "snmp_parse_oid(): cannot parse OID \"%s\".",
+												conf->oids_translated[sess->current_item]));
+
+					zabbix_log(	LOG_LEVEL_DEBUG, 
+								"In %s() cannot snmp_parse_oid %s for hostid %ld", 
+								__function_name,
+								conf->oids_translated[sess->current_item],
+								conf->items[sess->current_item].host.hostid);
+
+					conf->errcodes[sess->current_item] = CONFIG_ERROR;
+					conf->active_hosts--;
+					return 1;
+				}
+
+				if (NULL == (req = snmp_pdu_create(SNMP_MSG_GET))) 
+				{
+					zabbix_log(LOG_LEVEL_DEBUG, "In %s() cannot create pdu for hostid %ld", 
+							__function_name,conf->items[sess->current_item].host.hostid);
+
+					conf->errcodes[sess->current_item]=CONFIG_ERROR;
+					conf->active_hosts--;
+					return 1;
+				}
+
+				if (NULL == snmp_add_null_var(req, conf->parsed_oids[sess->current_item], conf->parsed_oid_lens[sess->current_item]))
+				{
+					SET_MSG_RESULT(&conf->results[sess->current_item], zbx_strdup(NULL, "snmp_add_null_var(): cannot add null variable."));
+					zabbix_log(LOG_LEVEL_DEBUG, "In %s() cannot add  vars  hostid %ld", 
+							__function_name,conf->items[sess->current_item].host.hostid);
+
+					conf->errcodes[sess->current_item] = CONFIG_ERROR;
+					snmp_free_pdu(req);
+					conf->active_hosts--;
+					return 1;
+				}
+
+				if (snmp_send(sp, req)) {
+					return 1;
+				} else {
+					snmp_perror("snmp_send");
+					snmp_free_pdu(req);
+
+					zabbix_log(LOG_LEVEL_DEBUG, "In %s() couldn't send snmp request for  hostid %ld", 
+							__function_name,conf->items[sess->current_item].host.hostid);
+
+					SET_MSG_RESULT(&conf->results[sess->current_item], zbx_strdup(NULL, "snmp_send couldn't send a packet"));
+					conf->errcodes[sess->current_item] = NETWORK_ERROR;
+				}
+			}
+		}
+	}
+
+	conf->active_hosts--;
+	return 1;
+}
+
+
+void	get_values_snmp_async(const DC_ITEM *items, AGENT_RESULT *results, int *errcodes, int num)
+{
+	const char		*__function_name = "get_values_snmp";
+
+	char				error[MAX_STRING_LEN];
+	struct snmp_session	*ss [MAX_ASYNC_SNMP_ITEMS];
+	int					i, err = SUCCEED, max_succeed = 0,ret=0;
+	struct snmp_pdu		*pdus[MAX_ASYNC_SNMP_ITEMS], *response;
+
+	size_t			max_error_len;
+
+	struct		variable_list *var;
+	int			snmp_sessions=0;
+	struct		async_snmp_session *hs;
+	struct		async_snmp_conf *conf;
+
+	zbx_uint64_t	last_hostid=0;
+
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s() Started. Got num:%d OIDs to parse",
+			__function_name, num);
+
+
+	if (NULL == (hs = zbx_malloc(NULL, sizeof(struct async_snmp_session) * MAX_ASYNC_SNMP_ITEMS))) 	return;
+	if (NULL == (conf = zbx_malloc(NULL,sizeof(struct async_snmp_conf)))) return;
+
+	
+	conf->items=items;
+	conf->results=results;
+	conf->errcodes=errcodes;
+	conf->active_hosts=0;
+
+
+	for ( i = 0; i < num; i++) 
+	{
+
+		if (SUCCEED != is_snmp_type( items[i].type )) {
+			zabbix_log(LOG_LEVEL_DEBUG, "skipping non-snmp item %d",i);
+			continue;	
+		}
+		
+
+		if (  
+			0 != (ZBX_FLAG_DISCOVERY_RULE & items[i].flags) ||
+			0 == strncmp(items[i].snmp_oid, "discovery[", 10) || 
+			NULL != strchr(items[i].snmp_oid, '[')
+			)
+		{
+			//skipping any dynamic items, they will be processed slow-old-sync way
+			zabbix_log(LOG_LEVEL_DEBUG, "skipping discovery item %d",i);
+			continue;
+		}
+
+		//setting fail code by default to disable for a while items we haven't been able to access
+		errcodes[i]=TIMEOUT_ERROR;
+
+		if (items[i].host.hostid != last_hostid) 
+		{
+			last_hostid=items[i].host.hostid;
+			zabbix_log(LOG_LEVEL_DEBUG, "In %s() found new host host id %ld, session is %d", __function_name,last_hostid,snmp_sessions);
+
+			hs[snmp_sessions].conf=conf;
+			hs[snmp_sessions].current_item=i;
+			hs[snmp_sessions].max_items=num;
+
+			conf->parsed_oid_lens[i] = MAX_OID_LEN;
+
+			zabbix_log(LOG_LEVEL_DEBUG, "In %s() init completed %ld", __function_name,last_hostid);
+
+			//starting new session for it:
+			if (NULL == (ss[snmp_sessions]=zbx_snmp_open_session(&items[i], error, sizeof(error))))
+			{
+				err = CONFIG_ERROR;
+				errcodes[i]=NETWORK_ERROR;
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() Opening snmp sessions: failed to open session for item %d", __function_name,i);
+				SET_MSG_RESULT(&results[i], zbx_dsprintf(NULL, "Couldn't open snmp session"));
+				
+				continue;
+			} 
+
+#define SNMP_RETRIES	1
+#define SNMP_TIMEOUT	2
+			ss[snmp_sessions]->callback = asynch_response;
+			ss[snmp_sessions]->callback_magic = &hs[snmp_sessions];
+			ss[snmp_sessions]->retries=SNMP_RETRIES;
+			ss[snmp_sessions]->timeout=SNMP_TIMEOUT*1000*1000;
+
+			zabbix_log(LOG_LEVEL_DEBUG, "In %s() session is opened %ld", __function_name,last_hostid);
+
+			if (NULL != items[i].snmp_oid )
+			{
+				zbx_snmp_translate(conf->oids_translated[i], items[i].snmp_oid, sizeof(conf->oids_translated[i]));
+			}  else 
+			{
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() cannot translate empty oid %s for hostid %ld", __function_name, 
+						conf->oids_translated[i],items[i].host.hostid);
+
+				SET_MSG_RESULT(&results[i], zbx_dsprintf(NULL, "snmp_parse_oid(): empty OID"));
+				errcodes[i] = CONFIG_ERROR;
+				continue;
+			}
+
+			//zabbix_log(LOG_LEVEL_DEBUG, "In %s() Opening snmp sessions: created session for item %d, code is %d", __function_name,i,errcodes[i]);
+
+			if (NULL == snmp_parse_oid(conf->oids_translated[i], conf->parsed_oids[i], &conf->parsed_oid_lens[i]))
+			{
+				SET_MSG_RESULT(&results[i], zbx_dsprintf(NULL, "snmp_parse_oid(): cannot parse OID \"%s\".",
+						conf->oids_translated[i]));
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() cannot snmp_parse_oid %s for hostid %ld", __function_name,
+					conf->oids_translated[i], items[i].host.hostid);
+				errcodes[i] = CONFIG_ERROR;
+				continue;
+			}
+
+			if (NULL == (pdus[snmp_sessions] = snmp_pdu_create(SNMP_MSG_GET)))
+			{
+				SET_MSG_RESULT(&results[i], zbx_dsprintf(NULL, "snmp_pdu_create(): cannot create PDU object "));
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() cannot create pdu for hostid %ld",__function_name,conf->items[i].host.hostid);
+				errcodes[i]=CONFIG_ERROR;
+				continue;
+			}
+
+
+			if (NULL == snmp_add_null_var(pdus[snmp_sessions], conf->parsed_oids[i], conf->parsed_oid_lens[i]))
+			{
+				SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "snmp_add_null_var(): cannot add null variable."));
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() cannot add  vars  hostid %ld",__function_name,conf->items[i].host.hostid);
+				errcodes[i] = CONFIG_ERROR;
+				snmp_free_pdu(pdus[snmp_sessions]);
+				//zbx_snmp_close_session(ss[snmp_sessions]);
+				continue;
+			}
+
+
+			zabbix_log(LOG_LEVEL_DEBUG, "In %s() Sending packet ",__function_name);
+
+			if (snmp_send(ss[snmp_sessions], pdus[snmp_sessions]))
+				conf->active_hosts++;
+			else {
+				snmp_perror("snmp_send");
+
+				snmp_free_pdu(pdus[snmp_sessions]);
+				//zbx_snmp_close_session(ss[snmp_sessions]);
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() couldn't send snmp request for hostid %ld",__function_name,conf->items[i].host.hostid);
+				SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Couldn't send snmp packet"));
+				errcodes[i] = NETWORK_ERROR;
+				continue;
+			}
+
+			snmp_sessions++;
+		    
+		} else {
+			//the next item belogns to the same host as before.
+			//iterating to the next item
+			zabbix_log(LOG_LEVEL_DEBUG, "%s() Skipping item %d as it belongs to the same host",__function_name,i);
+			continue;
+		}
+
+	} //iteration over the items array
+	int starttime=time(NULL);
+
+
+#define SNMP_MAX_BATCH_TIME (SNMP_RETRIES+1)*SNMP_TIMEOUT
+
+	 while (conf->active_hosts > 0  && (time(NULL)-starttime)< SNMP_MAX_BATCH_TIME) {
+
+		int fds = 0, block = 1, sessions;
+		netsnmp_large_fd_set fdset;
+		struct timeval timeout;
+
+		timeout.tv_sec=SNMP_TIMEOUT;
+		timeout.tv_usec=0;
+
+		//FD_ZERO(&fdset);
+		netsnmp_large_fd_set_init(&fdset, MAX_ASYNC_SNMP_ITEMS);
+
+
+		snmp_select_info2(&fds,&fdset,&timeout,&block);
+
+		fds = netsnmp_large_fd_set_select(fds, &fdset, NULL, NULL, block ? NULL : &timeout);
+
+		if (fds < 0) {
+			zabbix_log(LOG_LEVEL_DEBUG, "End of %s() Something unexpected happened with fds ", __function_name);
+			break;
+		}
+
+		if (fds) {
+//			zbx_alarm_on(SNMP_MAX_BATCH_TIME); //to exit out of use netsnm large fdset glitch if it happens
+			snmp_read2(&fdset);
+//			zbx_alarm_off();
+		}
+		else
+			snmp_timeout();
+		zabbix_log(LOG_LEVEL_DEBUG, "In %s() : waiting for %d pollers to finish", __function_name, conf->active_hosts);
+	}
+
+	/* sessions cleanup */
+	for (i = 0; i < snmp_sessions; i++ ) 
+	{
+		zabbix_log(LOG_LEVEL_DEBUG, "End of %s() freeing session for  item %d", __function_name,i);
+		zbx_snmp_close_session(ss[i]);
+	}
+
+	//if something sill left open, it will be closed
+	snmp_close_sessions();
+
+	zbx_free(hs);
+	zbx_free(conf);
+
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s():%s", __function_name, zbx_result_string(ret));
+
+	return;
+}
+
+
+
 #endif	/* HAVE_NETSNMP */
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_server/poller/checks_snmp.h xe-rabbix/src/zabbix_server/poller/checks_snmp.h
--- zabbix-4.0.1/src/zabbix_server/poller/checks_snmp.h	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_server/poller/checks_snmp.h	2018-12-14 11:20:58.502479329 +0500
@@ -32,6 +32,7 @@
 void	zbx_init_snmp(void);
 int	get_value_snmp(const DC_ITEM *item, AGENT_RESULT *result);
 void	get_values_snmp(const DC_ITEM *items, AGENT_RESULT *results, int *errcodes, int num);
+void	get_values_snmp_async(const DC_ITEM *items, AGENT_RESULT *results, int *errcodes, int num);
 #endif
 
 #endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_server/poller/poller.c xe-rabbix/src/zabbix_server/poller/poller.c
--- zabbix-4.0.1/src/zabbix_server/poller/poller.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_server/poller/poller.c	2019-01-23 10:21:49.756521032 +0500
@@ -496,23 +496,62 @@
  * Author: Alexei Vladishev                                                   *
  *                                                                            *
  * Comments: processes single item at a time except for Java, SNMP items,     *
+ * 				agent
+ * 		    																  *
  *           see DCconfig_get_poller_items()                                  *
  *                                                                            *
  ******************************************************************************/
-static int	get_values(unsigned char poller_type, int *nextcheck)
+static int	get_values(unsigned char poller_type, int *nextcheck,int *processed_num)
 {
 	const char		*__function_name = "get_values";
-	DC_ITEM			items[MAX_POLLER_ITEMS];
-	AGENT_RESULT		results[MAX_POLLER_ITEMS];
-	int			errcodes[MAX_POLLER_ITEMS];
+	//stack is noet enough for 8k items
+	DC_ITEM			*items;//[MAX_POLLER_ITEMS];
+	AGENT_RESULT		*results;//[MAX_POLLER_ITEMS];
+	int			*errcodes;//[MAX_POLLER_ITEMS];
 	zbx_timespec_t		timespec;
 	char			*port = NULL, error[ITEM_ERROR_LEN_MAX];
-	int			i, num, last_available = HOST_AVAILABLE_UNKNOWN;
+	int			i, num_collected=0, num, last_available = HOST_AVAILABLE_UNKNOWN, MAX_ITEMS=1;
 	zbx_vector_ptr_t	add_results;
-
+	
 	zabbix_log(LOG_LEVEL_DEBUG, "In %s()", __function_name);
 
+	switch (poller_type)
+	{
+		case ZBX_POLLER_TYPE_ASYNC_AGENT:
+			MAX_ITEMS=MAX_ASYNC_AGENT_ITEMS;
+			break;
+		case ZBX_POLLER_TYPE_ASYNC_SNMP:
+			MAX_ITEMS=MAX_ASYNC_SNMP_ITEMS;
+			break;
+		case ZBX_POLLER_TYPE_UNREACHABLE:
+			MAX_ITEMS=MAX_UNREACH_ITEMS;
+			break;
+		default: 
+			MAX_ITEMS=MAX_POLLER_ITEMS;
+	}
+
+	if (NULL == (items=zbx_malloc(NULL,sizeof(DC_ITEM)*MAX_ITEMS))) 
+	{
+		zabbix_log(LOG_LEVEL_WARNING,"Cannot allocate memory for polling");
+		return FAIL;
+	};
+	if (NULL == (results=zbx_malloc(NULL,sizeof(AGENT_RESULT)*MAX_ITEMS))) 
+	{
+		zabbix_log(LOG_LEVEL_WARNING,"Cannot allocate memory for polling");
+		return FAIL;
+	};
+	if (NULL == (errcodes=zbx_malloc(NULL,sizeof(int)*MAX_ITEMS))) 
+	{
+		zabbix_log(LOG_LEVEL_WARNING,"Cannot allocate memory for polling");
+		return FAIL;
+	};
+ 
+
 	num = DCconfig_get_poller_items(poller_type, items);
+	*processed_num=num;
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s(), got %d items", __function_name,num);
+
 
 	if (0 == num)
 	{
@@ -524,7 +563,7 @@
 	for (i = 0; i < num; i++)
 	{
 		init_result(&results[i]);
-		errcodes[i] = SUCCEED;
+		errcodes[i] = NOT_PROCESSED;
 
 		ZBX_STRDUP(items[i].key, items[i].key_orig);
 		if (SUCCEED != substitute_key_macros(&items[i].key, NULL, &items[i], NULL,
@@ -700,41 +739,55 @@
 	}
 
 	zbx_free(port);
-
 	zbx_vector_ptr_create(&add_results);
 
-	/* retrieve item values */
-	if (SUCCEED == is_snmp_type(items[0].type))
-	{
 #ifdef HAVE_NETSNMP
-		/* SNMP checks use their own timeouts */
-		get_values_snmp(items, results, errcodes, num);
-#else
-		for (i = 0; i < num; i++)
-		{
-			if (SUCCEED != errcodes[i])
-				continue;
-
-			SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Support for SNMP checks was not compiled in."));
-			errcodes[i] = CONFIG_ERROR;
-		}
-#endif
-	}
-	else if (ITEM_TYPE_JMX == items[0].type)
-	{
-		zbx_alarm_on(CONFIG_TIMEOUT);
-		get_values_java(ZBX_JAVA_GATEWAY_REQUEST_JMX, items, results, errcodes, num);
+	if (ZBX_POLLER_TYPE_ASYNC_SNMP == poller_type  || ZBX_POLLER_TYPE_UNREACHABLE == poller_type) {
+		zbx_alarm_on(CONFIG_TIMEOUT*2);
+		get_values_snmp_async(items, results, errcodes, num);
 		zbx_alarm_off();
 	}
-	else if (1 == num)
+#endif
+	if (ZBX_POLLER_TYPE_ASYNC_AGENT == poller_type || ZBX_POLLER_TYPE_UNREACHABLE == poller_type) 
 	{
-		if (SUCCEED == errcodes[0])
-			errcodes[0] = get_value(&items[0], &results[0], &add_results);
+		zbx_alarm_on(CONFIG_TIMEOUT*2);
+		get_value_agent_async(items, results, errcodes, num);
+		zbx_alarm_off();
 	}
-	else
-		THIS_SHOULD_NEVER_HAPPEN;
 
+	/* by design normal threads where not likely to get */
+	/* more then one item to process, but for future  */
+	/* to allow poller to take several tasks, this 	  */
+	/* part is fixed to be ready for it 		  */
+	for (i = 0; i < num; i++) {
+		/* it maybe that some items are already processed by async methods, skipping them */		
+		if ( NOT_PROCESSED == errcodes[i]) {
+			/* retrieve item values */
+			if (SUCCEED == is_snmp_type(items[i].type))
+			{	
+#ifdef HAVE_NETSNMP
+				/* SNMP checks use their own timeouts */
+				get_values_snmp(items+i, results+i, errcodes+i, 1);
+#else
+				SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Support for SNMP checks was not compiled in."));
+				errcodes[i] = CONFIG_ERROR;
+#endif
+			}
+			else if (ITEM_TYPE_JMX == items[i].type)
+			{
+				zbx_alarm_on(CONFIG_TIMEOUT);
+				get_values_java(ZBX_JAVA_GATEWAY_REQUEST_JMX, items+i, results+i, errcodes+i, 1);
+				zbx_alarm_off();
+			}
+			else 
+			{	
+				errcodes[i] = get_value(&items[i], &results[i], &add_results);
+			}
+		}	
+	}
+	
 	zbx_timespec(&timespec);
+	
 
 	/* process item values */
 	for (i = 0; i < num; i++)
@@ -753,12 +806,20 @@
 			case NETWORK_ERROR:
 			case GATEWAY_ERROR:
 			case TIMEOUT_ERROR:
-				if (HOST_AVAILABLE_FALSE != last_available)
+				/* for mass problems don't mark host as unreach for async and unreach pollers, because:
+				first, that sometimes causes a "poll" bug in mysql lib (100% thread load on waiting in a poll for mysql, probably solvable by alarm)
+				second, there seems to be no reason for that, async pollers live just fine having even all hosts unreachable */
+				if ( HOST_AVAILABLE_FALSE != last_available && 
+						(ZBX_POLLER_TYPE_NORMAL == poller_type || 
+						 ZBX_POLLER_TYPE_JAVA == poller_type ) )
 				{
 					zbx_deactivate_item_host(&items[i], &timespec, results[i].msg);
 					last_available = HOST_AVAILABLE_FALSE;
 				}
 				break;
+			case NOT_PROCESSED:
+				//this might happen on async processing for snmp
+				//when a host fails answering an item, next ones are not requested
 			case CONFIG_ERROR:
 				/* nothing to do */
 				break;
@@ -772,6 +833,7 @@
 			if (0 == add_results.values_num)
 			{
 				items[i].state = ITEM_STATE_NORMAL;
+				num_collected++;
 				zbx_preprocess_item_value(items[i].itemid, items[i].value_type, items[i].flags,
 						&results[i], &timespec, items[i].state, NULL);
 			}
@@ -789,6 +851,7 @@
 					if (ISSET_MSG(add_result))
 					{
 						items[i].state = ITEM_STATE_NOTSUPPORTED;
+						num_collected++;
 						zbx_preprocess_item_value(items[i].itemid, items[i].value_type,
 								items[i].flags, NULL, &ts_tmp, items[i].state,
 								add_result->msg);
@@ -796,6 +859,7 @@
 					else
 					{
 						items[i].state = ITEM_STATE_NORMAL;
+						num_collected++;
 						zbx_preprocess_item_value(items[i].itemid, items[i].value_type,
 								items[i].flags, add_result, &ts_tmp, items[i].state,
 								NULL);
@@ -813,12 +877,13 @@
 		else if (NOTSUPPORTED == errcodes[i] || AGENT_ERROR == errcodes[i] || CONFIG_ERROR == errcodes[i])
 		{
 			items[i].state = ITEM_STATE_NOTSUPPORTED;
+			num_collected++;
 			zbx_preprocess_item_value(items[i].itemid, items[i].value_type, items[i].flags, NULL, &timespec,
 					items[i].state, results[i].msg);
 		}
 
 		DCpoller_requeue_items(&items[i].itemid, &items[i].state, &timespec.sec, &errcodes[i], 1, poller_type,
-				nextcheck);
+					nextcheck);
 
 		zbx_free(items[i].key);
 
@@ -863,21 +928,28 @@
 				zbx_free(items[i].jmx_endpoint);
 				break;
 		}
-
 		free_result(&results[i]);
 	}
-
+	
 	zbx_preprocessor_flush();
 	zbx_vector_ptr_clear_ext(&add_results, (zbx_mem_free_func_t)free_result_ptr);
 	zbx_vector_ptr_destroy(&add_results);
 
 	DCconfig_clean_items(items, NULL, num);
-exit:
-	zabbix_log(LOG_LEVEL_DEBUG, "End of %s():%d", __function_name, num);
 
-	return num;
+exit:	
+
+	zbx_free(items);
+	zbx_free(results);
+	zbx_free(errcodes);
+
+
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s():%d", __function_name, num);
+	return num_collected;
 }
 
+
+
 ZBX_THREAD_ENTRY(poller_thread, args)
 {
 	int		nextcheck, sleeptime = -1, processed = 0, old_processed = 0;
@@ -897,7 +969,7 @@
 	zabbix_log(LOG_LEVEL_INFORMATION, "%s #%d started [%s #%d]", get_program_type_string(program_type),
 			server_num, get_process_type_string(process_type), process_num);
 #ifdef HAVE_NETSNMP
-	if (ZBX_POLLER_TYPE_NORMAL == poller_type || ZBX_POLLER_TYPE_UNREACHABLE == poller_type)
+	if (ZBX_POLLER_TYPE_NORMAL == poller_type || ZBX_POLLER_TYPE_UNREACHABLE == poller_type || ZBX_POLLER_TYPE_ASYNC_SNMP == poller_type )
 		zbx_init_snmp();
 #endif
 
@@ -921,7 +993,7 @@
 					old_total_sec);
 		}
 
-		processed += get_values(poller_type, &nextcheck);
+		processed += get_values(poller_type, &nextcheck,&processed);
 		total_sec += zbx_time() - sec;
 
 		sleeptime = calculate_sleeptime(nextcheck, POLLER_DELAY);
@@ -951,3 +1023,4 @@
 
 #undef STAT_INTERVAL
 }
+
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_server/preprocessor/preprocessing.h xe-rabbix/src/zabbix_server/preprocessor/preprocessing.h
--- zabbix-4.0.1/src/zabbix_server/preprocessor/preprocessing.h	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_server/preprocessor/preprocessing.h	2018-12-14 11:20:58.502479329 +0500
@@ -25,6 +25,7 @@
 #include "dbcache.h"
 
 #define ZBX_IPC_SERVICE_PREPROCESSING	"preprocessing"
+#define ZBX_IPC_SERVICE_PREPROCESSING_WORKER	"preprocessing_worker"
 
 #define ZBX_IPC_PREPROCESSOR_WORKER	1
 #define ZBX_IPC_PREPROCESSOR_REQUEST	2
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_server/preprocessor/preproc_manager.c xe-rabbix/src/zabbix_server/preprocessor/preproc_manager.c
--- zabbix-4.0.1/src/zabbix_server/preprocessor/preproc_manager.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_server/preprocessor/preproc_manager.c	2018-12-14 11:20:58.502479329 +0500
@@ -40,6 +40,10 @@
 #define ZBX_PREPROC_PRIORITY_NONE	0
 #define ZBX_PREPROC_PRIORITY_FIRST	1
 
+//this must be big enough to hold buffer for occasional slowdownds, so 10-15 threads might submit data without stucking
+#define ZBX_PREPROCESSING_MAX_QUEUE_TRESHOLD 1000000
+
+
 typedef enum
 {
 	REQUEST_STATE_QUEUED		= 0,		/* requires preprocessing */
@@ -1003,7 +1007,8 @@
 
 ZBX_THREAD_ENTRY(preprocessing_manager_thread, args)
 {
-	zbx_ipc_service_t		service;
+	zbx_ipc_service_t	service_requests;
+	zbx_ipc_service_t	service_results;
 	char				*error = NULL;
 	zbx_ipc_client_t		*client;
 	zbx_ipc_message_t		*message;
@@ -1023,7 +1028,14 @@
 	zabbix_log(LOG_LEVEL_INFORMATION, "%s #%d started [%s #%d]", get_program_type_string(program_type),
 			server_num, get_process_type_string(process_type), process_num);
 
-	if (FAIL == zbx_ipc_service_start(&service, ZBX_IPC_SERVICE_PREPROCESSING, &error))
+	if (FAIL == zbx_ipc_service_start(&service_requests, ZBX_IPC_SERVICE_PREPROCESSING, &error))
+	{
+		zabbix_log(LOG_LEVEL_CRIT, "cannot start preprocessing service for requests: %s", error);
+		zbx_free(error);
+		exit(EXIT_FAILURE);
+	}
+
+	if (FAIL == zbx_ipc_service_start(&service_results, ZBX_IPC_SERVICE_PREPROCESSING_WORKER, &error))
 	{
 		zabbix_log(LOG_LEVEL_CRIT, "cannot start preprocessing service: %s", error);
 		zbx_free(error);
@@ -1057,7 +1069,22 @@
 		}
 
 		update_selfmon_counter(ZBX_PROCESS_STATE_IDLE);
-		ret = zbx_ipc_service_recv(&service, ZBX_PREPROCESSING_MANAGER_DELAY, &client, &message);
+
+		if (manager.queued_num > ZBX_PREPROCESSING_MAX_QUEUE_TRESHOLD )
+		{
+			ret = zbx_ipc_service_recv(&service_results,0, &client, &message);
+			preprocessor_assign_tasks(&manager);
+			preprocessing_flush_queue(&manager);
+		 } else
+		{
+			ret = zbx_ipc_service_recv(&service_results, 0, &client, &message);
+			if (NULL == message)
+				ret = zbx_ipc_service_recv(&service_requests, 0, &client, &message);
+			/* CPU burn prevention */
+			if (NULL == message)	
+					usleep(1000);			
+		}
+
 		update_selfmon_counter(ZBX_PROCESS_STATE_BUSY);
 		sec = zbx_time();
 		zbx_update_env(sec);
@@ -1100,7 +1127,8 @@
 		}
 	}
 
-	zbx_ipc_service_close(&service);
+	zbx_ipc_service_close(&service_requests);
+	zbx_ipc_service_close(&service_results);
 	preprocessor_destroy_manager(&manager);
 
 	return 0;
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_server/preprocessor/preproc_worker.c xe-rabbix/src/zabbix_server/preprocessor/preproc_worker.c
--- zabbix-4.0.1/src/zabbix_server/preprocessor/preproc_worker.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_server/preprocessor/preproc_worker.c	2018-12-14 11:20:58.502479329 +0500
@@ -123,7 +123,7 @@
 
 	zbx_ipc_message_init(&message);
 
-	if (FAIL == zbx_ipc_socket_open(&socket, ZBX_IPC_SERVICE_PREPROCESSING, 10, &error))
+	if (FAIL == zbx_ipc_socket_open(&socket, ZBX_IPC_SERVICE_PREPROCESSING_WORKER, 10, &error))
 	{
 		zabbix_log(LOG_LEVEL_CRIT, "cannot connect to preprocessing service: %s", error);
 		zbx_free(error);
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_server/server.c xe-rabbix/src/zabbix_server/server.c
--- zabbix-4.0.1/src/zabbix_server/server.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_server/server.c	2018-12-14 11:20:58.502479329 +0500
@@ -158,6 +158,8 @@
 int	CONFIG_PINGER_FORKS		= 1;
 int	CONFIG_POLLER_FORKS		= 5;
 int	CONFIG_UNREACHABLE_POLLER_FORKS	= 1;
+int	CONFIG_ASYNC_SNMP_POLLER_FORKS	= 1;
+int	CONFIG_ASYNC_AGENT_POLLER_FORKS	= 1;
 int	CONFIG_HTTPPOLLER_FORKS		= 1;
 int	CONFIG_IPMIPOLLER_FORKS		= 0;
 int	CONFIG_TIMER_FORKS		= 1;
@@ -212,6 +214,11 @@
 char	*CONFIG_TMPDIR			= NULL;
 char	*CONFIG_FPING_LOCATION		= NULL;
 char	*CONFIG_FPING6_LOCATION		= NULL;
+char	*CONFIG_NMAP_LOCATION		= NULL;
+char	*CONFIG_NMAP_PARAMS		= NULL;
+char	*CONFIG_HISTORY_STORAGE_TYPE	= NULL;
+char	*CONFIG_HISTORY_STORAGE_TABLE_NAME = NULL;
+
 char	*CONFIG_DBHOST			= NULL;
 char	*CONFIG_DBNAME			= NULL;
 char	*CONFIG_DBSCHEMA		= NULL;
@@ -377,6 +384,16 @@
 		*local_process_type = ZBX_PROCESS_TYPE_UNREACHABLE;
 		*local_process_num = local_server_num - server_count + CONFIG_UNREACHABLE_POLLER_FORKS;
 	}
+	else if (local_server_num <= (server_count += CONFIG_ASYNC_SNMP_POLLER_FORKS))
+	{
+		*local_process_type = ZBX_PROCESS_TYPE_ASYNC_SNMP;
+		*local_process_num = local_server_num - server_count + CONFIG_ASYNC_SNMP_POLLER_FORKS;
+	}
+	else if (local_server_num <= (server_count += CONFIG_ASYNC_AGENT_POLLER_FORKS))
+	{
+		*local_process_type = ZBX_PROCESS_TYPE_ASYNC_AGENT;
+		*local_process_num = local_server_num - server_count + CONFIG_ASYNC_AGENT_POLLER_FORKS;
+	}
 	else if (local_server_num <= (server_count += CONFIG_TRAPPER_FORKS))
 	{
 		*local_process_type = ZBX_PROCESS_TYPE_TRAPPER;
@@ -445,6 +462,18 @@
 	if (NULL == CONFIG_FPING6_LOCATION)
 		CONFIG_FPING6_LOCATION = zbx_strdup(CONFIG_FPING6_LOCATION, "/usr/sbin/fping6");
 #endif
+	if (NULL == CONFIG_NMAP_LOCATION)
+		CONFIG_NMAP_LOCATION = zbx_strdup(CONFIG_NMAP_LOCATION, "/usr/bin/nmap");
+
+	if (NULL == CONFIG_NMAP_PARAMS)
+		CONFIG_NMAP_PARAMS = zbx_strdup(CONFIG_NMAP_PARAMS, "-n -sn -PE");
+	
+	if (NULL == CONFIG_HISTORY_STORAGE_TYPE)
+		CONFIG_HISTORY_STORAGE_TYPE = zbx_strdup(CONFIG_HISTORY_STORAGE_TYPE, "clickhouse");
+
+	if (NULL == CONFIG_HISTORY_STORAGE_TABLE_NAME)
+		CONFIG_HISTORY_STORAGE_TABLE_NAME = zbx_strdup(CONFIG_HISTORY_STORAGE_TABLE_NAME, "zabbix.history");
+
 	if (NULL == CONFIG_EXTERNALSCRIPTS)
 		CONFIG_EXTERNALSCRIPTS = zbx_strdup(CONFIG_EXTERNALSCRIPTS, DEFAULT_EXTERNAL_SCRIPTS_PATH);
 #ifdef HAVE_LIBCURL
@@ -580,6 +609,10 @@
 			PARM_OPT,	0,			1000},
 		{"StartPollersUnreachable",	&CONFIG_UNREACHABLE_POLLER_FORKS,	TYPE_INT,
 			PARM_OPT,	0,			1000},
+		{"StartPollersAsyncSNMP",	&CONFIG_ASYNC_SNMP_POLLER_FORKS,	TYPE_INT,
+			PARM_OPT,	0,			100},
+		{"StartPollersAsyncAGENT",	&CONFIG_ASYNC_AGENT_POLLER_FORKS,	TYPE_INT,
+			PARM_OPT,	0,			100},
 		{"StartIPMIPollers",		&CONFIG_IPMIPOLLER_FORKS,		TYPE_INT,
 			PARM_OPT,	0,			1000},
 		{"StartTimers",			&CONFIG_TIMER_FORKS,			TYPE_INT,
@@ -618,6 +651,10 @@
 			PARM_OPT,	0,			0},
 		{"FpingLocation",		&CONFIG_FPING_LOCATION,			TYPE_STRING,
 			PARM_OPT,	0,			0},
+		{"NmapLocation",		&CONFIG_NMAP_LOCATION,			TYPE_STRING,
+			PARM_OPT,	0,			0},
+		{"NmapParams",		&CONFIG_NMAP_PARAMS,			TYPE_STRING,
+			PARM_OPT,	0,			0},
 		{"Fping6Location",		&CONFIG_FPING6_LOCATION,		TYPE_STRING,
 			PARM_OPT,	0,			0},
 		{"Timeout",			&CONFIG_TIMEOUT,			TYPE_INT,
@@ -722,6 +759,10 @@
 			PARM_OPT,	0,			0},
 		{"ExportFileSize",		&CONFIG_EXPORT_FILE_SIZE,		TYPE_UINT64,
 			PARM_OPT,	ZBX_MEBIBYTE,	ZBX_GIBIBYTE},
+		{"HistoryStorageType",		&CONFIG_HISTORY_STORAGE_TYPE,		TYPE_STRING,
+			PARM_OPT,	1,			0},
+		{"HistoryStorageTableName",		&CONFIG_HISTORY_STORAGE_TABLE_NAME,		TYPE_STRING,
+			PARM_OPT,	1,			0},
 		{NULL}
 	};
 
@@ -766,6 +807,7 @@
 	ZBX_TASK_EX	t = {ZBX_TASK_START};
 	char		ch, *error = NULL;
 	int		opt_c = 0, opt_r = 0;
+	struct rlimit limits;
 
 #if defined(PS_OVERWRITE_ARGV) || defined(PS_PSTAT_ARGV)
 	argv = setproctitle_save_env(argc, argv);
@@ -854,6 +896,27 @@
 		zbx_free(error);
 		exit(EXIT_FAILURE);
 	}
+	//for async version we need lots of sockets 
+	//to be opened. Checking for that limit
+	getrlimit(RLIMIT_NOFILE,&limits);
+
+        if (ZBX_MIN_OPEN_FILES>limits.rlim_cur ) {
+	    zbx_error("WARNING!!! the system has only %ld open files limit, which is too low for ASYNC version",limits.rlim_cur);
+	    zbx_error("Will try to set the limit to %d:",ZBX_DESIRED_OPEN_FILES);
+
+	    limits.rlim_cur=ZBX_DESIRED_OPEN_FILES;
+	    limits.rlim_max=ZBX_DESIRED_OPEN_FILES;
+
+	    setrlimit(RLIMIT_NOFILE,&limits);
+	    getrlimit(RLIMIT_NOFILE,&limits);
+
+	    if (ZBX_MIN_OPEN_FILES>limits.rlim_cur ) {
+		zbx_error("Couldn't set max open files to %d. Please set it manualy via ulimit -n. Exisiting now.",ZBX_DESIRED_OPEN_FILES);
+		exit(EXIT_FAILURE);
+	    } else {
+		zbx_error("Succesifully set max open files to %d. But it's better to set it manualy via ulimit -n. ",ZBX_DESIRED_OPEN_FILES);
+	    }
+	}
 
 	return daemon_start(CONFIG_ALLOW_ROOT, CONFIG_USER, t.flags);
 }
@@ -945,7 +1008,7 @@
 	zabbix_log(LOG_LEVEL_INFORMATION, "VMware monitoring:         " VMWARE_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "SMTP authentication:       " SMTP_AUTH_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "Jabber notifications:      " JABBER_FEATURE_STATUS);
-	zabbix_log(LOG_LEVEL_INFORMATION, "Ez Texting notifications:  " LIBCURL_FEATURE_STATUS);
+	zabbix_log(LOG_LEVEL_INFORMATION, "CURL support:		" LIBCURL_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "ODBC:                      " ODBC_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "SSH2 support:              " SSH2_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "IPv6 support:              " IPV6_FEATURE_STATUS);
@@ -1061,7 +1124,8 @@
 	zbx_vc_enable();
 
 	threads_num = CONFIG_CONFSYNCER_FORKS + CONFIG_POLLER_FORKS
-			+ CONFIG_UNREACHABLE_POLLER_FORKS + CONFIG_TRAPPER_FORKS + CONFIG_PINGER_FORKS
+			+ CONFIG_UNREACHABLE_POLLER_FORKS + CONFIG_ASYNC_SNMP_POLLER_FORKS 
+			+ CONFIG_ASYNC_AGENT_POLLER_FORKS + CONFIG_TRAPPER_FORKS + CONFIG_PINGER_FORKS
 			+ CONFIG_ALERTER_FORKS + CONFIG_HOUSEKEEPER_FORKS + CONFIG_TIMER_FORKS
 			+ CONFIG_HTTPPOLLER_FORKS + CONFIG_DISCOVERER_FORKS + CONFIG_HISTSYNCER_FORKS
 			+ CONFIG_ESCALATOR_FORKS + CONFIG_IPMIPOLLER_FORKS + CONFIG_JAVAPOLLER_FORKS
@@ -1113,6 +1177,16 @@
 				thread_args.args = &poller_type;
 				threads[i] = zbx_thread_start(poller_thread, &thread_args);
 				break;
+			case ZBX_PROCESS_TYPE_ASYNC_SNMP:
+				poller_type = ZBX_POLLER_TYPE_ASYNC_SNMP;
+				thread_args.args = &poller_type;
+				threads[i] = zbx_thread_start(poller_thread, &thread_args);
+				break;
+			case ZBX_PROCESS_TYPE_ASYNC_AGENT:
+				poller_type = ZBX_POLLER_TYPE_ASYNC_AGENT;
+				thread_args.args = &poller_type;
+				threads[i] = zbx_thread_start(poller_thread, &thread_args);
+				break;
 			case ZBX_PROCESS_TYPE_TRAPPER:
 				thread_args.args = &listen_sock;
 				threads[i] = zbx_thread_start(trapper_thread, &thread_args);
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.1/src/zabbix_server/trapper/trapper.c xe-rabbix/src/zabbix_server/trapper/trapper.c
--- zabbix-4.0.1/src/zabbix_server/trapper/trapper.c	2018-10-29 22:36:00.000000000 +0500
+++ xe-rabbix/src/zabbix_server/trapper/trapper.c	2018-12-14 11:20:58.502479329 +0500
@@ -822,7 +822,85 @@
 
 	zbx_status_counters_free();
 }
+/******************************************************************************
+ *                                                                            *
+ * Function: recv_getproblems                                                 *
+ *                                                                            *
+ * Purpose: process problems request                                           *
+ *                                                                            *
+ * Parameters:  sock  - [IN] the request socket                               *
+ *              jp    - [IN] the request data                                 *
+ *                                                                            *
+ * Return value:  SUCCEED - processed successfully                            *
+ *                FAIL - an error occurred                                    *
+ *                                                                            *
+ ******************************************************************************/
+static int	recv_getproblems(zbx_socket_t *sock, struct zbx_json_parse *jp)
+{
+
+#define ZBX_GET_STATUS_UNKNOWN	-1
+#define ZBX_GET_STATUS_PING	0
+#define ZBX_GET_STATUS_FULL	1
 
+	const char		*__function_name = "recv_getstatus";
+	zbx_user_t		user;
+	int			ret = FAIL, request_type = ZBX_GET_STATUS_UNKNOWN;
+	char			type[MAX_STRING_LEN], sessionid[MAX_STRING_LEN];
+	struct zbx_json		json;
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s()", __function_name);
+
+	if (SUCCEED != zbx_json_value_by_name(jp, ZBX_PROTO_TAG_SID, sessionid, sizeof(sessionid)) ||
+			SUCCEED != DBget_user_by_active_session(sessionid, &user))
+	{
+		zbx_send_response(sock, ret, "Permission denied.", CONFIG_TIMEOUT);
+		goto out;
+	}
+
+	if (SUCCEED == zbx_json_value_by_name(jp, ZBX_PROTO_TAG_TYPE, type, sizeof(type)))
+	{
+		if (0 == strcmp(type, ZBX_PROTO_VALUE_GET_STATUS_PING))
+		{
+			request_type = ZBX_GET_STATUS_PING;
+		}
+		else if (0 == strcmp(type, ZBX_PROTO_VALUE_GET_STATUS_FULL))
+		{
+			request_type = ZBX_GET_STATUS_FULL;
+		}
+	}
+
+	if (ZBX_GET_STATUS_UNKNOWN == request_type)
+	{
+		zbx_send_response(sock, ret, "Unsupported request type.", CONFIG_TIMEOUT);
+		goto out;
+	}
+
+		
+//	zbx_json_init(&json, ZBX_JSON_STAT_BUF_LEN);
+	zbx_json_init(&json, ZBX_JSON_PROBLEMS_BUF_LEN);
+	zbx_json_addstring(&json, ZBX_PROTO_TAG_RESPONSE, ZBX_PROTO_VALUE_SUCCESS, ZBX_JSON_TYPE_STRING);
+	zbx_json_addobject(&json, ZBX_PROTO_TAG_DATA);
+	//zbx_json_addstring(&json, "hello","world", ZBX_JSON_TYPE_STRING);	
+	zbx_dump_problems_to_json(&json);
+
+	//zbx_json_close(&json);
+	//zabbix_log(LOG_LEVEL_DEBUG, "%s() json.buffer:'%s'", __function_name, json.buffer);
+
+	(void)zbx_tcp_send(sock, json.buffer);
+
+	zbx_json_free(&json);
+
+out:
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s():%s", __function_name);
+
+	return 1;
+
+#undef ZBX_GET_STATUS_UNKNOWN
+#undef ZBX_GET_STATUS_PING
+#undef ZBX_GET_STATUS_FULL
+
+
+}
 /******************************************************************************
  *                                                                            *
  * Function: recv_getstatus                                                   *
@@ -1040,6 +1118,9 @@
 			{
 				if (0 != (program_type & ZBX_PROGRAM_TYPE_SERVER))
 					ret = recv_getstatus(sock, &jp);
+			} else if (0 == strcmp(value, ZBX_PROTO_VALUE_GET_PROBLEMS))
+			{
+					ret = recv_getproblems(sock, &jp);
 			}
 			else
 				zabbix_log(LOG_LEVEL_WARNING, "unknown request received [%s]", value);
