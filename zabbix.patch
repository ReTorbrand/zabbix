diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/frontends/php/app/views/monitoring.widget.problems.view.php xe-rabbix/frontends/php/app/views/monitoring.widget.problems.view.php
--- zabbix-4.0.1rc1/frontends/php/app/views/monitoring.widget.problems.view.php	2018-10-22 13:32:49.000000000 +0500
+++ xe-rabbix/frontends/php/app/views/monitoring.widget.problems.view.php	2018-10-25 22:53:33.341869349 +0500
@@ -50,7 +50,7 @@
 	->setHeader(array_merge($header, [
 		$show_recovery_data ? _('Recovery time') : null,
 		$show_recovery_data ? _('Status') : null,
-		_('Info'),
+//		_('Info'),
 		($data['sortfield'] === 'host') ? [_('Host'), $sort_div] : _('Host'),
 		[
 			($data['sortfield'] === 'name') ? [_('Problem'), $sort_div] : _('Problem'),
@@ -148,6 +148,18 @@
 		$info_icons[] = makeSuppressedProblemIcon($problem['suppression_data']);
 	}
 
+
+//	$description = (new CCol([$problem['name']
+//		
+//		(new CLinkAction($problem['name']))
+//			->setHint(
+//				make_popup_eventlist($trigger, $eventid, $backurl, $data['fullscreen'], $show_timeline, $sortorder),
+//				'',
+//				true
+//			)
+// 	]));
+
+
 	$description = (new CCol([
 		(new CLinkAction($problem['name']))
 			->setHint(
@@ -212,7 +224,7 @@
 	$table->addRow(array_merge($row, [
 		$show_recovery_data ? $cell_r_clock : null,
 		$show_recovery_data ? $cell_status : null,
-		makeInformationList($info_icons),
+//		makeInformationList($info_icons),
 		$triggers_hosts[$trigger['triggerid']],
 		$description,
 		(new CCol(zbx_date2age($problem['clock'], ($problem['r_eventid'] != 0) ? $problem['r_clock'] : 0)))
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/frontends/php/include/classes/api/managers/CHistoryManager.php xe-rabbix/frontends/php/include/classes/api/managers/CHistoryManager.php
--- zabbix-4.0.1rc1/frontends/php/include/classes/api/managers/CHistoryManager.php	2018-10-22 13:32:58.000000000 +0500
+++ xe-rabbix/frontends/php/include/classes/api/managers/CHistoryManager.php	2018-10-25 22:51:04.724614784 +0500
@@ -34,10 +34,15 @@
 	 * @return array    an array with items IDs as keys and arrays of history objects as values
 	 */
 	public function getLastValues(array $items, $limit = 1, $period = null) {
+
 		$results = [];
 		$grouped_items = self::getItemsGroupedByStorage($items);
 
-		if (array_key_exists(ZBX_HISTORY_SOURCE_ELASTIC, $grouped_items)) {
+		if (array_key_exists(ZBX_HISTORY_SOURCE_CLICKHOUSE, $grouped_items)) {
+			$results += $this->getLastValuesFromClickHouse($grouped_items[ZBX_HISTORY_SOURCE_CLICKHOUSE], $limit,
+					$period
+			);
+		} else if (array_key_exists(ZBX_HISTORY_SOURCE_ELASTIC, $grouped_items)) {
 			$results += $this->getLastValuesFromElasticsearch($grouped_items[ZBX_HISTORY_SOURCE_ELASTIC], $limit,
 					$period
 			);
@@ -55,6 +60,157 @@
 	 *
 	 * @see CHistoryManager::getLastValues
 	 */
+
+	/**
+	 * Clickhouse implementation of getLastValues.
+	 *
+	 */
+
+
+private function getLastValuesFromClickhouse($items, $limit, $period) {
+
+	global $HISTORY;
+	$results = [];
+	$itemslist='';
+
+	
+	foreach ($items as $item) {
+	    if (strlen($itemslist)>0) {
+	        $itemslist.=','.$item['itemid'];
+    	    } else {
+	        $itemslist.=$item['itemid'];
+		}
+	} 
+
+
+	$query_text='SELECT itemid, anyLast(toInt32(clock)) as clk,anyLast(ns),anyLast(value),anyLast(value_dbl),anyLast(value_str)'.
+	' FROM '.$HISTORY['tablename'].' h'.
+	' WHERE h.itemid in ( '.$itemslist.')'.
+	($period ? ' AND h.clock>'.(time() - $period) : '').
+	' GROUP BY itemid';
+
+        $values = CClickHouseHelper::query($query_text,1,array('itemid','clock','ns','value','value_dbl','value_str'));
+
+	foreach ($values as $res) 
+	{
+		$itemid=$res['itemid'];
+
+		//i know this is shit code, but it works much better then 
+		//checking for item type for some reason (see it celow)
+		$res['value']=floatval($res['value_dbl'])+intval($res['value']);		
+		if (strlen($res['value_str']>0)) $res['value']=$res['value_str'];
+
+		if (empty($results[$itemid])) 
+		    {
+			$results[$itemid]=[$res];
+		    }
+	}
+
+//	foreach ($items as $item) {
+//	    if ( !empty($results[$item['itemid']])) {
+//	    	if ($item['value_type'] ==  ITEM_VALUE_TYPE_FLOAT && !empty($results[$item['itemid']]['value_dbl'])) {
+//		    $results[$item['itemid']]['value']=$results[$item['itemid']]['value_dbl'];
+//	        }
+//		if ($item['value_type'] ==  ITEM_VALUE_TYPE_STR) {
+//		    $results[$item['itemid']]['value']=$results[$item['itemid']]['value_str'];
+//		}
+//	    }
+//	    
+//	}
+
+	return $results;
+
+//	foreach ($items as $item) {
+//	    if ($item['value_type'] ==  ITEM_VALUE_TYPE_FLOAT) {
+//    		if (strlen($float_itemslist)>0) {
+//		        $float_itemslist.=','.$item['itemid'];
+//    		} else {
+//		    $float_itemslist.=$item['itemid'];
+//		}
+//	    } else if ($item['value_type'] ==  ITEM_VALUE_TYPE_UINT64) {
+//		if (strlen($uint_itemslist)>0) {
+//		        $uint_itemslist.=','.$item['itemid'];
+//    		} else {
+//		    $uint_itemslist.=$item['itemid'];
+//		}
+//	    } else {
+//		if (strlen($str_itemslist)>0) {
+//		        $str_itemslist.=','.$item['itemid'];
+//    		} else {
+//		    $str_itemslist.=$item['itemid'];
+//		}
+//	    }
+//	}
+
+//	var_dump($itemslist);
+	
+//	$query_text='SELECT itemid, toInt32(clock) as clk,ns,value,value_dbl,value_str as value'.
+//	' FROM '.$HISTORY['tablename'].' h'.
+//	' WHERE h.itemid in ( '.$itemslist.')'.
+//	($period ? ' AND h.clock>'.(time() - $period) : '').
+//	' ORDER BY clk DESC';
+
+
+//	$query_text.=' UNION ALL SELECT itemid, toInt32(clock) as clk,ns,value as value'.
+//	' FROM '.$HISTORY['tablename'].' h'.
+//	' WHERE h.itemid in ( '.$uint_itemslist.')'.
+//	($period ? ' AND h.clock>'.(time() - $period) : '').
+//	' ORDER BY clk DESC';
+//
+//	$query_text.=' UNION ALL SELECT itemid, toInt32(clock) as clk,ns,value_str as value'.
+//	' FROM '.$HISTORY['tablename'].' h'.
+//	' WHERE h.itemid in ( '.$str_itemslist.')'.
+//	($period ? ' AND h.clock>'.(time() - $period) : '').
+//	' ORDER BY clk DESC';
+
+//	var_dump($query_text);
+    
+//        $values = CClickHouseHelper::query($query_text,1,array('itemid','clock','ns','value','value_dbl','value_str'));
+
+//var_dump($values);
+
+/*
+	foreach ($items as $item) {
+	    if ($item['value_type'] ==  ITEM_VALUE_TYPE_FLOAT) {
+		$query_text=	'SELECT itemid, toInt32(clock),ns,value_dbl'.
+		    ' FROM '.$HISTORY['tablename'].' h'.
+		    ' WHERE h.itemid= '.$item['itemid'].
+		    ($period ? ' AND h.clock>'.(time() - $period) : '').
+		    ' ORDER BY h.clock DESC';
+	    }
+
+	    if ($item['value_type'] ==  ITEM_VALUE_TYPE_UINT64) {
+		$query_text=	'SELECT itemid, toInt32(clock) as clock,ns,value'.
+		    ' FROM '.$HISTORY['tablename'].' h'.
+		    ' WHERE h.itemid= '.$item['itemid']. 
+		    ($period ? ' AND h.clock>'.(time() - $period) : '').
+		    ' ORDER BY h.clock DESC';
+	    }
+
+	    if ($item['value_type'] ==  ITEM_VALUE_TYPE_STR || $item['value_type'] ==  ITEM_VALUE_TYPE_TEXT ) {
+		$query_text=	'SELECT itemid, toInt32(clock) as clock,ns,value_str'.
+		    ' FROM '.$HISTORY['tablename'].' h'.
+		    ' WHERE h.itemid= '.$item['itemid']. 
+		    ($period ? ' AND h.clock>'.(time() - $period) : '').
+		    ' ORDER BY h.clock DESC';
+	    }
+
+	    if ($limit > 0) $query_text.=" LIMIT $limit";
+	    
+	    $values = CClickHouseHelper::query($query_text,1,array('itemid','clock','ns','value'));
+
+//	    var_dump($values);
+	    if ($values) {
+		$results[$item['itemid']] = $values;
+	    } else {
+//			    error("Got empty array, ommiting the result");
+	    }
+	}
+
+	return $results;
+*/
+    }
+
 	private function getLastValuesFromElasticsearch($items, $limit, $period) {
 		$terms = [];
 		$results = [];
@@ -137,6 +293,7 @@
 	 *
 	 * @see CHistoryManager::getLastValues
 	 */
+
 	private function getLastValuesFromSql($items, $limit, $period) {
 		$results = [];
 
@@ -171,6 +328,7 @@
 	 * @return array    history value aggregation for graphs
 	 */
 	public function getGraphAggregation(array $items, $time_from, $time_to, $width = null) {
+//		error("Hello wold");
 		if ($width !== null) {
 			$size = $time_to - $time_from;
 			$delta = $size - $time_from % $size;
@@ -183,7 +341,13 @@
 		$grouped_items = self::getItemsGroupedByStorage($items);
 
 		$results = [];
-		if (array_key_exists(ZBX_HISTORY_SOURCE_ELASTIC, $grouped_items)) {
+
+
+		if (array_key_exists(ZBX_HISTORY_SOURCE_CLICKHOUSE, $grouped_items)) {
+			$results += $this->getGraphAggregationFromClickhouse($grouped_items[ZBX_HISTORY_SOURCE_CLICKHOUSE],
+					$time_from, $time_to, $width, $size, $delta
+			);
+		} else if (array_key_exists(ZBX_HISTORY_SOURCE_ELASTIC, $grouped_items)) {
 			$results += $this->getGraphAggregationFromElasticsearch($grouped_items[ZBX_HISTORY_SOURCE_ELASTIC],
 					$time_from, $time_to, $width, $size, $delta
 			);
@@ -203,6 +367,57 @@
 	 *
 	 * @see CHistoryManager::getGraphAggregation
 	 */
+	private function getGraphAggregationFromClickhouse(array $items, $time_from, $time_to, $width, $size, $delta) {
+
+		global $HISTORY;
+		$group_by = 'itemid';
+		$sql_select_extra = '';
+
+		if ($width !== null && $size !== null && $delta !== null) {
+			// Required for 'group by' support of Oracle.
+			$calc_field = 'round('.$width.'*'.'modulo(toUInt32(clock)'.'+'.$delta.",$size)".'/('.$size.'),0)';
+
+			$sql_select_extra = ','.$calc_field.' AS i';
+			$group_by .= ','.$calc_field;
+		}
+
+		$results = [];
+
+		foreach ($items as $item) {
+			if ($item['value_type'] == ITEM_VALUE_TYPE_UINT64) {
+				$sql_select = 'COUNT(*) AS count,AVG(value) AS avg,MIN(value) AS min,MAX(value) AS max';
+			} else
+			{
+				$sql_select = 'COUNT(*) AS count,AVG(value_dbl) AS avg,MIN(value_dbl) AS min,MAX(value_dbl) AS max';
+			}
+
+			$query_text = 
+				'SELECT itemid,'.$sql_select.$sql_select_extra.',MAX(toUInt32(clock)) AS clock1'.
+				' FROM '. $HISTORY['tablename'] .
+				' WHERE itemid='.$item['itemid'].
+					' AND toUInt32(clock)>='.$time_from.
+					' AND toUInt32(clock)<='.$time_to.
+				' GROUP BY '.$group_by ;
+			
+//			file_put_contents('/var/log/nginx/chartlog.log', "Will do query '$query_text' \n",FILE_APPEND);
+
+			$values = CClickHouseHelper::query($query_text,1,array('itemid','count','avg','min','max','i','clock'));
+
+			$results[$item['itemid']]['source'] = 'history';
+			$results[$item['itemid']]['data'] = $values;
+		}
+
+//	    ob_start();
+//	    var_dump($results);
+//	    $dresult = ob_get_clean();
+//	    error("Dump of the result is '$dresult'");
+
+//	    file_put_contents('/var/log/nginx/chartlog.log', "Clickhouse Results structure is $dresult' \n",FILE_APPEND);
+
+		return $results;
+
+	}
+
 	private function getGraphAggregationFromElasticsearch(array $items, $time_from, $time_to, $width, $size, $delta) {
 		$terms = [];
 
@@ -423,6 +638,8 @@
 	 */
 	public function getAggregatedValue(array $item, $aggregation, $time_from) {
 		switch (self::getDataSourceType($item['value_type'])) {
+			case ZBX_HISTORY_SOURCE_CLICKHOUSE:
+				return $this->getAggregatedValueFromClickhouse($item, $aggregation, $time_from);
 			case ZBX_HISTORY_SOURCE_ELASTIC:
 				return $this->getAggregatedValueFromElasticsearch($item, $aggregation, $time_from);
 
@@ -431,6 +648,24 @@
 		}
 	}
 
+	private function getAggregatedValueFromClickhouse(array $item, $aggregation, $time_from) {
+
+		global $HISTORY;
+		$query_text =
+			'SELECT '.$aggregation.'(value) AS value'.
+			' FROM '. $HISTORY['tablename'].
+			' WHERE clock>toDateTime('.$time_from.')'.
+			' AND itemid='.$item['itemid'].
+			' HAVING COUNT(*)>0';
+		
+
+		$value = CClickHouseHelper::query($query_text,0,array());
+
+		return $value;
+
+	}
+
+
 	/**
 	 * Elasticsearch specific implementation of getAggregatedValue.
 	 *
@@ -623,8 +858,12 @@
 			global $HISTORY;
 
 			if (is_array($HISTORY) && array_key_exists('types', $HISTORY) && is_array($HISTORY['types'])) {
-				$cache[$value_type] = in_array(self::getTypeNameByTypeId($value_type), $HISTORY['types'])
-						? ZBX_HISTORY_SOURCE_ELASTIC : ZBX_HISTORY_SOURCE_SQL;
+					if ($HISTORY['storagetype']=='clickhouse') 
+							$cache[$value_type] = in_array(self::getTypeNameByTypeId($value_type), $HISTORY['types'])
+								? ZBX_HISTORY_SOURCE_CLICKHOUSE : ZBX_HISTORY_SOURCE_SQL;
+					else 
+							$cache[$value_type] = in_array(self::getTypeNameByTypeId($value_type), $HISTORY['types'])
+								? ZBX_HISTORY_SOURCE_ELASTIC : ZBX_HISTORY_SOURCE_SQL;
 			}
 			else {
 				// SQL is a fallback data source.
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/frontends/php/include/classes/api/services/CHistory.php xe-rabbix/frontends/php/include/classes/api/services/CHistory.php
--- zabbix-4.0.1rc1/frontends/php/include/classes/api/services/CHistory.php	2018-10-22 13:32:58.000000000 +0500
+++ xe-rabbix/frontends/php/include/classes/api/services/CHistory.php	2018-10-25 22:51:04.760614118 +0500
@@ -112,7 +112,10 @@
 		switch (CHistoryManager::getDataSourceType($options['history'])) {
 			case ZBX_HISTORY_SOURCE_ELASTIC:
 				return $this->getFromElasticsearch($options);
-
+				break;
+			case ZBX_HISTORY_SOURCE_CLICKHOUSE:
+				return $this->getFromClickHouse($options);
+				break;
 			default:
 				return $this->getFromSql($options);
 		}
@@ -239,6 +242,129 @@
 	}
 
 	/**
+	 * Clickhouse specific implementation of get.
+	 *
+	 * @see CHistory::get
+	 */
+	private function getFromClickHouse($options) {
+		global $HISTORY;
+		$result = [];
+		$sql_parts = [
+			'select'	=> ['history' => 'h.itemid'],
+			'from'		=> [],
+			'where'		=> [],
+			'group'		=> [],
+			'order'		=> [],
+			'limit'		=> null
+		];
+
+
+		$value_col='value';
+
+		if ($options['history']==ITEM_VALUE_TYPE_FLOAT) {
+		    $value_col='value_dbl';
+		}
+
+		if ($options['history']==ITEM_VALUE_TYPE_STR) {
+		    $value_col='value_str';
+		}
+
+
+		$table_name = $HISTORY['tablename'];
+
+		$sql_parts['from']['history'] = $table_name.' h';
+
+		// itemids
+		if ($options['itemids'] !== null) {
+			$sql_parts['where']['itemid'] = "h.itemid =". $options['itemids'][0];
+		}
+
+		// time_from
+		if ($options['time_from'] !== null) {
+			$sql_parts['where']['clock_from'] = 'h.clock>='.zbx_dbstr($options['time_from']);
+		}
+
+		// time_till
+		if ($options['time_till'] !== null) {
+			$sql_parts['where']['clock_till'] = 'h.clock<='.zbx_dbstr($options['time_till']);
+		}
+
+		// filter
+		if (is_array($options['filter'])) {
+			$this->dbFilter($sql_parts['from']['history'], $options, $sql_parts);
+		}
+
+		// search
+		if (is_array($options['search'])) {
+			zbx_db_search($sql_parts['from']['history'], $options, $sql_parts);
+		}
+
+		// output
+		if ($options['output'] == API_OUTPUT_EXTEND) {
+			unset($sql_parts['select']['clock']);
+			$sql_parts['select']['history'] = 'h.*';
+		}
+
+		// countOutput
+		if ($options['countOutput']) {
+			$options['sortfield'] = '';
+			$sql_parts['select'] = ['count(DISTINCT h.hostid) as rowscount'];
+
+			// groupCount
+			if ($options['groupCount']) {
+				foreach ($sql_parts['group'] as $key => $fields) {
+					$sql_parts['select'][$key] = $fields;
+				}
+			}
+		}
+
+		// sorting
+		$sql_parts = $this->applyQuerySortOptions($table_name, $this->tableAlias(), $options, $sql_parts);
+
+		// limit
+		if (zbx_ctype_digit($options['limit']) && $options['limit']) {
+			$sql_parts['limit'] = $options['limit'];
+		}
+
+		$sql_parts['select'] = array_unique($sql_parts['select']);
+		$sql_parts['from'] = array_unique($sql_parts['from']);
+		$sql_parts['where'] = array_unique($sql_parts['where']);
+		$sql_parts['order'] = array_unique($sql_parts['order']);
+
+		$sql_select = '';
+		$sql_from = '';
+		$sql_order = '';
+
+		if ($sql_parts['select']) {
+			$sql_select .= implode(',', $sql_parts['select']);
+		}
+
+		if ($sql_parts['from']) {
+			$sql_from .= implode(',', $sql_parts['from']);
+		}
+
+		$sql_where = $sql_parts['where'] ? ' WHERE '.implode(' AND ', $sql_parts['where']) : '';
+
+		if ($sql_parts['order']) {
+			$sql_order .= ' ORDER BY '.implode(',', $sql_parts['order']);
+		}
+
+		$sql_limit = $sql_parts['limit'];
+		$sql = "SELECT itemid, toInt32(clock), ns, $value_col".
+				' FROM '.$sql_from.
+				$sql_where.
+				$sql_order;
+
+		var_dump($sql);
+		$values = CClickHouseHelper::query($sql,1,array('itemid','clock','ns', 'value'));
+
+
+//		error("Will exec sql $sql");
+
+		return $values;
+	}
+
+	/**
 	 * Elasticsearch specific implementation of get.
 	 *
 	 * @see CHistory::get
@@ -315,4 +441,5 @@
 
 		return null;
 	}
+
 }
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/frontends/php/include/classes/helpers/CClickHouseHelper.php xe-rabbix/frontends/php/include/classes/helpers/CClickHouseHelper.php
--- zabbix-4.0.1rc1/frontends/php/include/classes/helpers/CClickHouseHelper.php	1970-01-01 05:00:00.000000000 +0500
+++ xe-rabbix/frontends/php/include/classes/helpers/CClickHouseHelper.php	2018-10-25 22:51:04.760614118 +0500
@@ -0,0 +1,99 @@
+<?php
+
+/*
+ * A helper class for working with ClickHouse database
+ */
+class CClickHouseHelper {
+
+	/**
+	 * Perform request(s) to Elasticsearch and parse the results.
+	 *
+	 * @param string $method      HTTP method to be used to perform request
+	 * @param string $endpoint    requested url
+	 * @param mixed  $request     data to be sent
+	 *
+	 * @return array    parsed result
+	 */
+	public static function query($request,$is_table_result,$columns) {
+		
+		global $HISTORY;
+//		error("CClikHouseHelper.query($request) ");
+		$ch = curl_init();
+
+		curl_setopt($ch, CURLOPT_URL,$HISTORY['url']['uint']);
+		curl_setopt($ch, CURLOPT_POST, 1);
+		curl_setopt($ch, CURLOPT_POSTFIELDS,$request);
+
+		// receive server response ...
+		curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
+
+		$server_output = curl_exec ($ch);
+		curl_close ($ch);
+
+//		error("Clickhouse returned '$server_output'");
+
+//		ob_start();
+//    		var_dump($request);
+//    		var_dump($server_output);
+
+//		$dresult = ob_get_clean();
+//	    error("Dump of the result is '$dresult'");
+
+//		file_put_contents('/var/log/nginx/clickhouse.log', "Clickhouse Results structure is $dresult' \n",FILE_APPEND);
+
+
+
+		return self::parseResult($server_output,$is_table_result,$columns);
+		
+	}
+
+	/**
+	 * Parse result and return two dimentional array of the result
+	 *
+	 * @param string $data        result as a string
+	 *
+	 * @return array    parsed result  two dimentional array of the result
+	 */
+	private static function parseResult($data,$is_table_result,$columns) {
+
+	    //to make processing simpler, lets distinguish results of two types - table (two dimensional array as result
+	    //returned or SINGLE, when one value (a number, probably) 
+	    if ($is_table_result) 
+	    {
+		$result=[];
+
+		$lines = explode("\n", $data);
+		$curline=0;
+
+		foreach ($lines as $line) {
+		    if (strlen(str_replace("\n",'',$line) ) > 0) 
+		    { 
+//			error("Processing line '$line'");
+//			error("Columns count is ".count($columns)." field count is ".count(explode("\t",$line)));
+			$result[$curline]=array_combine($columns,explode("\t",$line));
+			$curline++;
+
+		    } else {
+//			error("Got empty line, skipping");
+		    }
+		}
+
+	    } else
+	    {
+		//single result is here, stripping tabs,spaces and newlines
+		$result=str_replace(array("\r", "\n","\t"), '', $data);
+	    }
+
+/*	    ob_start();
+	    var_dump($result);
+	    $dresult = ob_get_clean();
+	    error("Dump of the result is '$dresult'");
+*/
+	    return $result;
+	}
+
+
+}
+
+
+
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/frontends/php/include/classes/macros/CMacrosResolverGeneral.php xe-rabbix/frontends/php/include/classes/macros/CMacrosResolverGeneral.php
--- zabbix-4.0.1rc1/frontends/php/include/classes/macros/CMacrosResolverGeneral.php	2018-10-22 13:32:57.000000000 +0500
+++ xe-rabbix/frontends/php/include/classes/macros/CMacrosResolverGeneral.php	2018-10-25 22:51:04.772613897 +0500
@@ -772,7 +772,7 @@
 		}
 
 		$result = DBselect(
-			'SELECT f.triggerid,f.functionid,h.hostid,h.host,h.name'.
+			'SELECT f.triggerid,f.functionid,h.hostid,h.host,h.name,h.description'.
 			' FROM functions f'.
 				' JOIN items i ON f.itemid=i.itemid'.
 				' JOIN hosts h ON i.hostid=h.hostid'.
@@ -781,6 +781,7 @@
 
 		while ($row = DBfetch($result)) {
 			foreach ($macros[$row['functionid']] as $macro => $tokens) {
+				//var_dump($row);
 				switch ($macro) {
 					case 'HOST.ID':
 						$value = $row['hostid'];
@@ -794,6 +795,10 @@
 					case 'HOST.NAME':
 						$value = $row['name'];
 						break;
+					case 'HOST.DESCRIPTION1':
+						$value = $row['description'];
+						break;
+
 				}
 
 				foreach ($tokens as $token) {
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/frontends/php/include/classes/macros/CMacrosResolver.php xe-rabbix/frontends/php/include/classes/macros/CMacrosResolver.php
--- zabbix-4.0.1rc1/frontends/php/include/classes/macros/CMacrosResolver.php	2018-10-22 13:32:57.000000000 +0500
+++ xe-rabbix/frontends/php/include/classes/macros/CMacrosResolver.php	2018-10-25 22:51:04.780613749 +0500
@@ -331,7 +331,7 @@
 
 		$types = [
 			'macros_n' => [
-				'host' => ['{HOSTNAME}', '{HOST.HOST}', '{HOST.NAME}'],
+				'host' => ['{HOSTNAME}', '{HOST.HOST}', '{HOST.NAME}', '{HOST.DESCRIPTION1}'],
 				'interface' => ['{IPADDRESS}', '{HOST.IP}', '{HOST.DNS}', '{HOST.CONN}', '{HOST.PORT}'],
 				'item' => ['{ITEM.LASTVALUE}', '{ITEM.VALUE}']
 			],
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/frontends/php/include/defines.inc.php xe-rabbix/frontends/php/include/defines.inc.php
--- zabbix-4.0.1rc1/frontends/php/include/defines.inc.php	2018-10-22 13:32:49.000000000 +0500
+++ xe-rabbix/frontends/php/include/defines.inc.php	2018-10-25 22:51:04.788613601 +0500
@@ -50,8 +50,10 @@
 
 // the maximum period to display history data for the latest data and item overview pages in seconds
 // by default set to 86400 seconds (24 hours)
-define('ZBX_HISTORY_PERIOD', 86400);
+define('ZBX_HISTORY_PERIOD', 7200);
 
+
+define('ZBX_HISTORY_SOURCE_CLICKHOUSE',	'clickhouse');
 define('ZBX_HISTORY_SOURCE_ELASTIC',	'elastic');
 define('ZBX_HISTORY_SOURCE_SQL',		'sql');
 
@@ -59,7 +61,7 @@
 define('ELASTICSEARCH_RESPONSE_AGGREGATION',	1);
 define('ELASTICSEARCH_RESPONSE_DOCUMENTS',		2);
 
-define('ZBX_WIDGET_ROWS', 20);
+define('ZBX_WIDGET_ROWS', 2000);
 
 define('ZBX_FONTPATH',				realpath('fonts')); // where to search for font (GD > 2.0.18)
 define('ZBX_GRAPH_FONT_NAME',		'DejaVuSans'); // font file name
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/include/common.h xe-rabbix/include/common.h
--- zabbix-4.0.1rc1/include/common.h	2018-10-22 13:32:47.000000000 +0500
+++ xe-rabbix/include/common.h	2018-10-25 22:54:06.105264055 +0500
@@ -87,6 +87,7 @@
 #define	AGENT_ERROR	-5
 #define	GATEWAY_ERROR	-6
 #define	CONFIG_ERROR	-7
+#define	NOT_PROCESSED	-8
 
 #define SUCCEED_OR_FAIL(result) (FAIL != (result) ? SUCCEED : FAIL)
 const char	*zbx_sysinfo_ret_string(int ret);
@@ -538,7 +539,9 @@
 #define ZBX_PROCESS_TYPE_ALERTMANAGER	25
 #define ZBX_PROCESS_TYPE_PREPROCMAN	26
 #define ZBX_PROCESS_TYPE_PREPROCESSOR	27
-#define ZBX_PROCESS_TYPE_COUNT		28	/* number of process types */
+#define ZBX_PROCESS_TYPE_ASYNC_SNMP	28
+#define ZBX_PROCESS_TYPE_ASYNC_AGENT	29
+#define ZBX_PROCESS_TYPE_COUNT		30	/* number of process types */
 #define ZBX_PROCESS_TYPE_UNKNOWN	255
 const char	*get_process_type_string(unsigned char process_type);
 int		get_process_type_by_name(const char *proc_type_str);
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/include/dbcache.h xe-rabbix/include/dbcache.h
--- zabbix-4.0.1rc1/include/dbcache.h	2018-10-22 13:32:47.000000000 +0500
+++ xe-rabbix/include/dbcache.h	2018-10-25 22:54:06.141263389 +0500
@@ -34,12 +34,17 @@
 #define	ZBX_POLLER_TYPE_IPMI		2
 #define	ZBX_POLLER_TYPE_PINGER		3
 #define	ZBX_POLLER_TYPE_JAVA		4
-#define	ZBX_POLLER_TYPE_COUNT		5	/* number of poller types */
+#define	ZBX_POLLER_TYPE_ASYNC_SNMP		5
+#define	ZBX_POLLER_TYPE_ASYNC_AGENT		6
+#define	ZBX_POLLER_TYPE_COUNT		7	/* number of poller types */
 
 #define MAX_JAVA_ITEMS		32
 #define MAX_SNMP_ITEMS		128
 #define MAX_POLLER_ITEMS	128	/* MAX(MAX_JAVA_ITEMS, MAX_SNMP_ITEMS) */
-#define MAX_PINGER_ITEMS	128
+#define MAX_PINGER_ITEMS	4096
+#define MAX_UNREACH_ITEMS		64 //we don't want this to be too big, but it's better for efficiency if thats more then one item 
+#define MAX_ASYNC_SNMP_ITEMS		4096
+#define MAX_ASYNC_AGENT_ITEMS		4096
 
 #define ZBX_TRIGGER_DEPENDENCY_LEVELS_MAX	32
 
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/include/zbxjson.h xe-rabbix/include/zbxjson.h
--- zabbix-4.0.1rc1/include/zbxjson.h	2018-10-22 13:32:47.000000000 +0500
+++ xe-rabbix/include/zbxjson.h	2018-10-25 22:54:06.145263316 +0500
@@ -117,6 +117,7 @@
 #define ZBX_PROTO_VALUE_JAVA_GATEWAY_JMX	"java gateway jmx"
 #define ZBX_PROTO_VALUE_GET_QUEUE		"queue.get"
 #define ZBX_PROTO_VALUE_GET_STATUS		"status.get"
+#define ZBX_PROTO_VALUE_GET_PROBLEMS	"problems.get"
 #define ZBX_PROTO_VALUE_PROXY_DATA		"proxy data"
 #define ZBX_PROTO_VALUE_PROXY_TASKS		"proxy tasks"
 
@@ -146,6 +147,7 @@
 zbx_json_status_t;
 
 #define ZBX_JSON_STAT_BUF_LEN 4096
+#define ZBX_JSON_PROBLEMS_BUF_LEN 51200000
 
 struct zbx_json
 {
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/src/libs/zbxcommon/str.c xe-rabbix/src/libs/zbxcommon/str.c
--- zabbix-4.0.1rc1/src/libs/zbxcommon/str.c	2018-10-22 13:32:48.000000000 +0500
+++ xe-rabbix/src/libs/zbxcommon/str.c	2018-10-25 22:54:06.153263168 +0500
@@ -1159,6 +1159,10 @@
 	{
 		case ZBX_PROCESS_TYPE_POLLER:
 			return "poller";
+		case ZBX_PROCESS_TYPE_ASYNC_SNMP:
+			return "async snmp poller";
+		case ZBX_PROCESS_TYPE_ASYNC_AGENT:
+			return "async agent poller";
 		case ZBX_PROCESS_TYPE_UNREACHABLE:
 			return "unreachable poller";
 		case ZBX_PROCESS_TYPE_IPMIPOLLER:
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/src/libs/zbxdbcache/dbconfig.c xe-rabbix/src/libs/zbxdbcache/dbconfig.c
--- zabbix-4.0.1rc1/src/libs/zbxdbcache/dbconfig.c	2018-10-22 13:32:47.000000000 +0500
+++ xe-rabbix/src/libs/zbxdbcache/dbconfig.c	2018-10-25 22:54:06.173262798 +0500
@@ -90,6 +90,8 @@
 
 extern unsigned char	program_type;
 extern int		CONFIG_TIMER_FORKS;
+extern int CONFIG_ASYNC_AGENT_POLLER_FORKS;
+extern int CONFIG_ASYNC_SNMP_POLLER_FORKS;
 
 ZBX_MEM_FUNC_IMPL(__config, config_mem)
 
@@ -202,10 +204,7 @@
 				return ZBX_POLLER_TYPE_PINGER;
 			}
 			/* break; is not missing here */
-		case ITEM_TYPE_ZABBIX:
-		case ITEM_TYPE_SNMPv1:
-		case ITEM_TYPE_SNMPv2c:
-		case ITEM_TYPE_SNMPv3:
+
 		case ITEM_TYPE_INTERNAL:
 		case ITEM_TYPE_AGGREGATE:
 		case ITEM_TYPE_EXTERNAL:
@@ -218,6 +217,34 @@
 				break;
 
 			return ZBX_POLLER_TYPE_NORMAL;
+		
+		case ITEM_TYPE_ZABBIX:
+			if (0 == CONFIG_ASYNC_AGENT_POLLER_FORKS ){
+				if (0 == CONFIG_POLLER_FORKS)
+					break;
+
+				return ZBX_POLLER_TYPE_NORMAL;
+			}
+			return ZBX_POLLER_TYPE_ASYNC_AGENT;
+
+		case ITEM_TYPE_SNMPv1:
+		case ITEM_TYPE_SNMPv2c:
+		case ITEM_TYPE_SNMPv3:
+			if (0 == CONFIG_ASYNC_SNMP_POLLER_FORKS ){
+				if (0 == CONFIG_POLLER_FORKS)
+					break;
+
+				return ZBX_POLLER_TYPE_NORMAL;
+			} else {
+				if ( 0 == strncmp(key, "discovery[", 10)  )
+				{
+					zabbix_log(LOG_LEVEL_INFORMATION,"Selecting normal poller for key %s",key);
+					return ZBX_POLLER_TYPE_NORMAL;
+				} else {
+					return ZBX_POLLER_TYPE_ASYNC_SNMP;
+				}
+			}
+
 		case ITEM_TYPE_IPMI:
 			if (0 == CONFIG_IPMIPOLLER_FORKS)
 				break;
@@ -5649,6 +5676,8 @@
 	CREATE_HASHSET(config->corr_conditions, 0);
 	CREATE_HASHSET(config->corr_operations, 0);
 	CREATE_HASHSET(config->hostgroups, 0);
+	CREATE_HASHSET(config->problems, 0);
+
 	zbx_vector_ptr_create_ext(&config->hostgroups_name, __config_mem_malloc_func, __config_mem_realloc_func,
 			__config_mem_free_func);
 
@@ -7600,6 +7629,18 @@
 		case ZBX_POLLER_TYPE_PINGER:
 			max_items = MAX_PINGER_ITEMS;
 			break;
+		case ZBX_POLLER_TYPE_NORMAL:
+			max_items = 1;
+			break;
+		case ZBX_POLLER_TYPE_ASYNC_SNMP:
+			max_items = MAX_ASYNC_SNMP_ITEMS;
+			break;
+		case ZBX_POLLER_TYPE_UNREACHABLE:
+			max_items = MAX_UNREACH_ITEMS;
+			break;
+		case ZBX_POLLER_TYPE_ASYNC_AGENT:
+			max_items = MAX_ASYNC_AGENT_ITEMS;
+			break;
 		default:
 			max_items = 1;
 	}
@@ -7617,22 +7658,18 @@
 		min = zbx_binary_heap_find_min(queue);
 		dc_item = (ZBX_DC_ITEM *)min->data;
 
+
 		if (dc_item->nextcheck > now)
 			break;
-
-		if (0 != num)
-		{
-			if (SUCCEED == is_snmp_type(dc_item_prev->type))
-			{
-				if (0 != __config_snmp_item_compare(dc_item_prev, dc_item))
-					break;
-			}
-			else if (ITEM_TYPE_JMX == dc_item_prev->type)
-			{
-				if (0 != __config_java_item_compare(dc_item_prev, dc_item))
-					break;
-			}
-		}
+		
+		if ( (0 != num) && 	( ZBX_POLLER_TYPE_NORMAL == poller_type ) && (SUCCEED == is_snmp_type(dc_item_prev->type))
+					 && (0 != __config_snmp_item_compare(dc_item_prev, dc_item)) )
+			break;
+		
+		
+		if ( (0 != num) && 	( ZBX_POLLER_TYPE_JAVA == poller_type )	&& (ITEM_TYPE_JMX == dc_item_prev->type) && 
+				(0 != __config_java_item_compare(dc_item_prev, dc_item)) )
+			break;
 
 		zbx_binary_heap_remove_min(queue);
 		dc_item->location = ZBX_LOC_NOWHERE;
@@ -7650,34 +7687,41 @@
 		}
 
 		/* don't apply unreachable item/host throttling for prioritized items */
-		if (ZBX_QUEUE_PRIORITY_HIGH != dc_item->queue_priority)
-		{
-			if (0 == (disable_until = DCget_disable_until(dc_item, dc_host)))
-			{
-				/* move reachable items on reachable hosts to normal pollers */
-				if (ZBX_POLLER_TYPE_UNREACHABLE == poller_type &&
-						ZBX_QUEUE_PRIORITY_LOW != dc_item->queue_priority)
-				{
-					dc_requeue_item(dc_item, dc_host, dc_item->state, ZBX_ITEM_COLLECTED, now);
-					continue;
-				}
-			}
-			else
-			{
-				/* move items on unreachable hosts to unreachable pollers or    */
-				/* postpone checks on hosts that have been checked recently and */
-				/* are still unreachable                                        */
-				if (ZBX_POLLER_TYPE_NORMAL == poller_type || ZBX_POLLER_TYPE_JAVA == poller_type ||
-						disable_until > now)
-				{
-					dc_requeue_item(dc_item, dc_host, dc_item->state,
-							ZBX_ITEM_COLLECTED | ZBX_HOST_UNREACHABLE, now);
-					continue;
-				}
-
-				DCincrease_disable_until(dc_item, dc_host, now);
-			}
-		}
+		/* and for async and unreachable pollers */
+		
+		//in async polling model there is NO problems with checking whatever we want
+		//whenever we want, so no prioritization required at all
+		//in fact, there is even no reason to pause quering such an items
+		
+//		if (ZBX_QUEUE_PRIORITY_HIGH != dc_item->queue_priority && ZBX_POLLER_TYPE_ASYNC != poller_type 
+//										&& ZBX_POLLER_TYPE_UNREACHABLE != poller_type)
+//		{
+//			if (0 == (disable_until = DCget_disable_until(dc_item, dc_host)))
+//			{
+//				/* move reachable items on reachable hosts to normal pollers */
+//				if (ZBX_POLLER_TYPE_UNREACHABLE == poller_type &&
+//						ZBX_QUEUE_PRIORITY_LOW != dc_item->queue_priority)
+//				{
+//					dc_requeue_item(dc_item, dc_host, dc_item->state, ZBX_ITEM_COLLECTED, now);
+//					continue;
+//				}
+//			}
+//			else
+//			{
+//				/* move items on unreachable hosts to unreachable pollers or    */
+//				/* postpone checks on hosts that have been checked recently and */
+//				/* are still unreachable                                        */
+//				if (ZBX_POLLER_TYPE_NORMAL == poller_type || ZBX_POLLER_TYPE_JAVA == poller_type ||
+//						disable_until > now)
+//				{
+//					dc_requeue_item(dc_item, dc_host, dc_item->state,
+//							ZBX_ITEM_COLLECTED | ZBX_HOST_UNREACHABLE, now);
+//					continue;
+//				}
+//
+//				DCincrease_disable_until(dc_item, dc_host, now);
+//			}
+//		}
 
 		dc_item_prev = dc_item;
 		dc_item->location = ZBX_LOC_POLLER;
@@ -7685,21 +7729,22 @@
 		DCget_item(&items[num], dc_item);
 		num++;
 
-		if (1 == num && ZBX_POLLER_TYPE_NORMAL == poller_type && SUCCEED == is_snmp_type(dc_item->type) &&
-				0 == (ZBX_FLAG_DISCOVERY_RULE & dc_item->flags))
-		{
-			ZBX_DC_SNMPITEM	*snmpitem;
-
-			snmpitem = (ZBX_DC_SNMPITEM *)zbx_hashset_search(&config->snmpitems, &dc_item->itemid);
+		//the following code never works anyway as MAX_SNMP_ITEMS is one for regular pollers
 
-			if (ZBX_SNMP_OID_TYPE_NORMAL == snmpitem->snmp_oid_type ||
-					ZBX_SNMP_OID_TYPE_DYNAMIC == snmpitem->snmp_oid_type)
-			{
-				max_items = DCconfig_get_suggested_snmp_vars_nolock(dc_item->interfaceid, NULL);
-			}
-		}
+//		if (1 == num && ZBX_POLLER_TYPE_NORMAL == poller_type && SUCCEED == is_snmp_type(dc_item->type) &&
+//				0 == (ZBX_FLAG_DISCOVERY_RULE & dc_item->flags))
+//		{
+//			ZBX_DC_SNMPITEM	*snmpitem;
+//
+//			snmpitem = (ZBX_DC_SNMPITEM *)zbx_hashset_search(&config->snmpitems, &dc_item->itemid);
+//
+//			if (ZBX_SNMP_OID_TYPE_NORMAL == snmpitem->snmp_oid_type ||
+//					ZBX_SNMP_OID_TYPE_DYNAMIC == snmpitem->snmp_oid_type)
+//			{
+//				max_items = DCconfig_get_suggested_snmp_vars_nolock(dc_item->interfaceid, NULL);
+//			}
+//		}
 	}
-
 	UNLOCK_CACHE;
 
 	zabbix_log(LOG_LEVEL_DEBUG, "End of %s():%d", __function_name, num);
@@ -7952,6 +7997,7 @@
 				dc_requeue_item(dc_item, dc_host, states[i], ZBX_ITEM_COLLECTED, lastclocks[i]);
 				break;
 			case NETWORK_ERROR:
+			case NOT_PROCESSED:
 			case GATEWAY_ERROR:
 			case TIMEOUT_ERROR:
 				dc_item->queue_priority = ZBX_QUEUE_PRIORITY_LOW;
@@ -7959,11 +8005,48 @@
 						time(NULL));
 				break;
 			default:
+				zabbix_log(LOG_LEVEL_INFORMATION,"Unknown errcode: %d", errcodes[i]);
 				THIS_SHOULD_NEVER_HAPPEN;
 		}
 	}
 }
 
+static void	dc_requeue_async_items(const zbx_uint64_t *itemids, const unsigned char *states, const int *lastclocks,
+		const int *errcodes, size_t num)
+{
+	size_t		i;
+	ZBX_DC_ITEM	*dc_item;
+	ZBX_DC_HOST	*dc_host;
+
+	for (i = 0; i < num; i++)
+	{
+		if (FAIL == errcodes[i])
+			continue;
+
+		if (NULL == (dc_item = (ZBX_DC_ITEM *)zbx_hashset_search(&config->items, &itemids[i])))
+			continue;
+
+		if (ZBX_LOC_POLLER == dc_item->location)
+			dc_item->location = ZBX_LOC_NOWHERE;
+
+		if (ITEM_STATUS_ACTIVE != dc_item->status)
+			continue;
+
+		if (NULL == (dc_host = (ZBX_DC_HOST *)zbx_hashset_search(&config->hosts, &dc_item->hostid)))
+			continue;
+
+		if (HOST_STATUS_MONITORED != dc_host->status)
+			continue;
+
+		if (SUCCEED != is_counted_in_item_queue(dc_item->type, dc_item->key))
+			continue;
+
+		//whatever the other return codes, we want the item to be polled again
+		dc_requeue_item(dc_item, dc_host, states[i], ZBX_ITEM_COLLECTED, lastclocks[i]);
+	}
+}
+
+
 void	DCrequeue_items(const zbx_uint64_t *itemids, const unsigned char *states, const int *lastclocks,
 		const int *errcodes, size_t num)
 {
@@ -7978,13 +8061,17 @@
 		const int *errcodes, size_t num, unsigned char poller_type, int *nextcheck)
 {
 	WRLOCK_CACHE;
-
-	dc_requeue_items(itemids, states, lastclocks, errcodes, num);
+	if (ZBX_POLLER_TYPE_ASYNC_AGENT == poller_type || ZBX_POLLER_TYPE_ASYNC_SNMP == poller_type) {
+		dc_requeue_async_items(itemids, states, lastclocks, errcodes, num);	
+	} else {
+		dc_requeue_items(itemids, states, lastclocks, errcodes, num);
+	}
 	*nextcheck = dc_config_get_queue_nextcheck(&config->queues[poller_type]);
 
 	UNLOCK_CACHE;
 }
 
+
 /******************************************************************************
  *                                                                            *
  * Function: zbx_dc_requeue_unreachable_items                                 *
@@ -11772,3 +11859,112 @@
 
 	UNLOCK_CACHE;
 }
+
+/******************************************************************************
+ *                                                                            *
+ * Function: zbx_XXXXX_problems			                                      *
+ *                                                                            *
+ * Purpose: keep in the hashset existing (active) problems                    *
+ *                                                                            *
+ ******************************************************************************/
+void zbx_clean_problems()
+{
+	static int lastclean=0;
+	ZBX_DC_PROBLEM *problem=NULL;
+	unsigned int timenow, count=0;
+	zbx_hashset_iter_t problems_iter;
+
+	
+	if ((time(NULL)-lastclean)>ZBX_PROBLEM_CLEAN_RUN) {
+		zabbix_log(LOG_LEVEL_DEBUG,"Doing problems cleanout");
+		timenow=time(NULL);
+
+		zbx_hashset_iter_reset(&config->problems,&problems_iter);
+
+		while (NULL!=(problem=zbx_hashset_iter_next(&problems_iter))){
+
+			if  ( (ZBX_PROBLEM_CLOSED == problem->state && ( timenow - problem->lastupdate > ZBX_PROBLEM_CLOSED_TIMEOUT )) ||
+				 (timenow - problem->lastupdate > ZBX_PROBLEM_OPEN_TIMEOUT))
+				{
+					//problem is aged, removing
+					zabbix_log(LOG_LEVEL_DEBUG,"Cleaning problem %u",problem->eventid);
+					zbx_hashset_remove_direct(&config->problems,problem);
+
+					//zbx_free(problem);
+					count++;
+			} 
+			
+		}
+		lastclean=time(NULL);
+		zabbix_log(LOG_LEVEL_DEBUG,"Problems cleanup: cleaned %u problems, left %u",count,config->problems.num_data);
+	}
+}
+	
+
+void zbx_register_problem(zbx_uint64_t id, char *problem_text) 
+{
+	ZBX_DC_PROBLEM problem,*tmpproblem;
+
+	WRLOCK_CACHE;
+
+	if ( NULL == (tmpproblem = zbx_hashset_search(&config->problems,&id)))
+	{
+		zabbix_log(LOG_LEVEL_DEBUG,"Adding event %d",id);
+		problem.eventid=id;
+		zbx_strlcpy(problem.description,problem_text,511);
+		problem.lastupdate=time(NULL);
+		problem.state=ZBX_PROBLEM_OPEN;
+		zbx_hashset_insert(&config->problems,(const void*)&problem,sizeof(ZBX_DC_PROBLEM));
+
+	} else {
+		zabbix_log(LOG_LEVEL_DEBUG,"Updating event %d",id);
+		zbx_strlcpy(problem.description,problem_text,511);
+		problem.lastupdate=time(NULL);
+	}
+	//zabbix_log(LOG_LEVEL_INFORMATION,"problem registered");
+	zbx_clean_problems();
+	UNLOCK_CACHE;
+}
+
+void zbx_register_problem_recovery(zbx_uint64_t  id)  {
+	zabbix_log(LOG_LEVEL_DEBUG,"Problem %u recovery call",id);
+
+	ZBX_DC_PROBLEM *problem=NULL;
+	WRLOCK_CACHE;
+
+	problem=zbx_hashset_search(&config->problems,&id);
+
+	if (NULL != problem) {
+		zabbix_log(LOG_LEVEL_DEBUG,"Closing problem %u",id);
+		problem->state=ZBX_PROBLEM_CLOSED;
+		problem->lastupdate=time(NULL);
+	} else {
+		zabbix_log(LOG_LEVEL_DEBUG,"Problem %u not found",id);
+	}
+	//zabbix_log(LOG_LEVEL_INFORMATION,"problem recovery registered");
+	zbx_clean_problems();
+	UNLOCK_CACHE;
+}
+
+void zbx_dump_problems_to_json(struct zbx_json *json) {
+	
+	zbx_hashset_iter_t problems_iter;
+	ZBX_DC_PROBLEM *problem;
+
+	WRLOCK_CACHE;
+	zbx_json_addarray(json, "problems");	
+
+	zbx_hashset_iter_reset(&config->problems,&problems_iter);
+
+	while (NULL!=(problem=(ZBX_DC_PROBLEM*)zbx_hashset_iter_next(&problems_iter))){
+		if (ZBX_PROBLEM_CLOSED != problem->state) {
+			zbx_json_addobject(json, NULL);	
+			zbx_json_adduint64(json, "eventid", problem->eventid);
+			zbx_json_addraw(json, "eventdata", problem->description);
+			zbx_json_close(json);	
+		}
+	}
+
+	zbx_json_close(json);	
+	UNLOCK_CACHE;
+}
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/src/libs/zbxdbcache/dbconfig.h xe-rabbix/src/libs/zbxdbcache/dbconfig.h
--- zabbix-4.0.1rc1/src/libs/zbxdbcache/dbconfig.h	2018-10-22 13:32:47.000000000 +0500
+++ xe-rabbix/src/libs/zbxdbcache/dbconfig.h	2018-10-25 22:54:06.193262429 +0500
@@ -760,9 +760,33 @@
 	ZBX_DC_CONFIG_TABLE	*config;
 	ZBX_DC_STATUS		*status;
 	zbx_hashset_t		strpool;
+	zbx_hashset_t		problems;
 }
 ZBX_DC_CONFIG;
 
+typedef struct
+{
+	zbx_uint64_t 	eventid;
+	char 			description[512];
+	unsigned int 	lastupdate;
+	unsigned int 	state;
+}
+ZBX_DC_PROBLEM;
+
+/* problem in memory cache-related defines */
+
+/* how often to run in memory problems cleanup */
+#define ZBX_PROBLEM_CLEAN_RUN 120 
+
+#define ZBX_PROBLEM_CLOSED	0
+#define ZBX_PROBLEM_OPEN	1
+
+/* delete problems from memory that's been there for more then 1 month */
+#define ZBX_PROBLEM_OPEN_TIMEOUT	30*86400
+/* and keep closed problems only for 1 hour */
+#define ZBX_PROBLEM_CLOSED_TIMEOUT	30
+
+
 extern int	sync_in_progress;
 extern ZBX_DC_CONFIG	*config;
 extern zbx_rwlock_t	config_lock;
@@ -818,11 +842,15 @@
 void	DCsync_maintenance_groups(zbx_dbsync_t *sync);
 void	DCsync_maintenance_hosts(zbx_dbsync_t *sync);
 
+/* trapper problems reporting */
+void zbx_dump_problems_to_json(struct zbx_json *json);
+void zbx_register_problem(zbx_uint64_t id, char *problem_text);
+void zbx_register_problem_recovery(zbx_uint64_t id);
+
 /* maintenance support */
 
 /* number of slots to store maintenance update flags */
 #define ZBX_MAINTENANCE_UPDATE_FLAGS_NUM()	\
 		((CONFIG_TIMER_FORKS + sizeof(uint64_t) * 8 - 1) / (sizeof(uint64_t) * 8))
 
-
 #endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/src/libs/zbxhistory/history.c xe-rabbix/src/libs/zbxhistory/history.c
--- zabbix-4.0.1rc1/src/libs/zbxhistory/history.c	2018-10-22 13:32:47.000000000 +0500
+++ xe-rabbix/src/libs/zbxhistory/history.c	2018-10-25 22:54:06.197262354 +0500
@@ -25,10 +25,11 @@
 
 #include "../zbxalgo/vectorimpl.h"
 
-ZBX_VECTOR_IMPL(history_record, zbx_history_record_t)
+ZBX_VECTOR_IMPL(history_record, zbx_history_record_t);
 
 extern char	*CONFIG_HISTORY_STORAGE_URL;
 extern char	*CONFIG_HISTORY_STORAGE_OPTS;
+extern char	*CONFIG_HISTORY_STORAGE_TYPE;
 
 zbx_history_iface_t	history_ifaces[ITEM_VALUE_TYPE_MAX];
 
@@ -53,10 +54,21 @@
 
 	for (i = 0; i < ITEM_VALUE_TYPE_MAX; i++)
 	{
-		if (NULL == CONFIG_HISTORY_STORAGE_URL || NULL == strstr(CONFIG_HISTORY_STORAGE_OPTS, opts[i]))
+		if (NULL == CONFIG_HISTORY_STORAGE_URL || NULL == strstr(CONFIG_HISTORY_STORAGE_OPTS, opts[i])) 
+		{
+			zabbix_log(LOG_LEVEL_INFORMATION, "Init SQL storage engine as history storage for type %s", opts[i]);
 			ret = zbx_history_sql_init(&history_ifaces[i], i, error);
-		else
+		}
+		else if ( NULL != strstr(CONFIG_HISTORY_STORAGE_TYPE,"clickhouse")) 
+		{
+			ret = zbx_history_clickhouse_init(&history_ifaces[i], i, error);
+			zabbix_log(LOG_LEVEL_INFORMATION, "Init Clickhouse storage engine as history storage for type %s", opts[i]);
+		}
+		else 
+		{
 			ret = zbx_history_elastic_init(&history_ifaces[i], i, error);
+			zabbix_log(LOG_LEVEL_INFORMATION, "Init ElasticsSearch storage engine as history storage for type %s", opts[i]);
+		}
 
 		if (FAIL == ret)
 			return FAIL;
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/src/libs/zbxhistory/history_clickhouse.c xe-rabbix/src/libs/zbxhistory/history_clickhouse.c
--- zabbix-4.0.1rc1/src/libs/zbxhistory/history_clickhouse.c	1970-01-01 05:00:00.000000000 +0500
+++ xe-rabbix/src/libs/zbxhistory/history_clickhouse.c	2018-10-25 22:54:06.197262354 +0500
@@ -0,0 +1,796 @@
+/*
+** Zabbix
+** Copyright (C) 2001-2018 Zabbix SIA
+**
+** This program is free software; you can redistribute it and/or modify
+** it under the terms of the GNU General Public License as published by
+** the Free Software Foundation; either version 2 of the License, or
+** (at your option) any later version.
+**
+** This program is distributed in the hope that it will be useful,
+** but WITHOUT ANY WARRANTY; without even the implied warranty of
+** MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+** GNU General Public License for more details.
+**
+** You should have received a copy of the GNU General Public License
+** along with this program; if not, write to the Free Software
+** Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+**/
+
+
+
+#include "common.h"
+#include "log.h"
+#include "zbxjson.h"
+#include "zbxalgo.h"
+#include "dbcache.h"
+#include "zbxhistory.h"
+#include "zbxself.h"
+#include "history.h"
+#include <stdio.h>
+#include <string.h>
+
+/* curl_multi_wait() is supported starting with version 7.28.0 (0x071c00) */
+#if defined(HAVE_LIBCURL) && LIBCURL_VERSION_NUM >= 0x071c00
+
+#define		ZBX_HISTORY_STORAGE_DOWN	10000 /* Timeout in milliseconds */
+#define		MAX_HISTORY_CLICKHOUSE_FIELDS	5 /* How many fields to parse from clickhouse output */
+
+//const char	*value_type_str[] = {"dbl", "str", "log", "uint", "text"};
+
+extern char	*CONFIG_HISTORY_STORAGE_URL;
+extern char *CONFIG_HISTORY_STORAGE_TABLE_NAME;
+
+typedef struct
+{
+	char	*base_url;
+
+//post_url  here from elastics where it was used for scrolling of data search results, 
+//post_url might be used to use some clickhouse options, so i've decided to leave it
+	//char	*post_url;
+	char	*buf;
+	CURL	*handle;
+}
+zbx_clickhouse_data_t;
+
+typedef struct
+{
+	unsigned char		initialized;
+	zbx_vector_ptr_t	ifaces;
+
+	CURLM			*handle;
+}
+zbx_clickhouse_writer_t;
+
+static zbx_clickhouse_writer_t	writer;
+
+typedef struct
+{
+	char	*data;
+	size_t	alloc;
+	size_t	offset;
+}
+zbx_httppage_t;
+
+static zbx_httppage_t	page;
+
+static size_t	curl_write_cb(void *ptr, size_t size, size_t nmemb, void *userdata)
+{
+	size_t	r_size = size * nmemb;
+
+	ZBX_UNUSED(userdata);
+
+	zbx_strncpy_alloc(&page.data, &page.alloc, &page.offset, ptr, r_size);
+
+	return r_size;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Comments: stub function for avoiding LibCURL to print on the standard output.    *
+ *           In case of success, elasticsearch return a JSON, but the HTTP error    *
+ *           code is enough                                                         *
+ *                                                                                  *
+ ************************************************************************************/
+static size_t	curl_write_send_cb(void *ptr, size_t size, size_t nmemb, void *userdata)
+{
+	ZBX_UNUSED(ptr);
+	ZBX_UNUSED(userdata);
+	return size * nmemb;
+}
+
+static history_value_t	history_str2value(char *str, unsigned char value_type)
+{
+	history_value_t	value;
+
+	switch (value_type)
+	{
+		case ITEM_VALUE_TYPE_LOG:
+			value.log = zbx_malloc(NULL, sizeof(zbx_log_value_t));
+			memset(value.log, 0, sizeof(zbx_log_value_t));
+			value.log->value = zbx_strdup(NULL, str);
+			break;
+		case ITEM_VALUE_TYPE_STR:
+		case ITEM_VALUE_TYPE_TEXT:
+			value.str = zbx_strdup(NULL, str);
+			break;
+		case ITEM_VALUE_TYPE_FLOAT:
+			value.dbl = atof(str);
+			break;
+		case ITEM_VALUE_TYPE_UINT64:
+			ZBX_STR2UINT64(value.ui64, str);
+			break;
+	}
+
+	return value;
+}
+
+static const char	*history_value2str(const ZBX_DC_HISTORY *h)
+{
+	static char	buffer[MAX_ID_LEN + 1];
+
+	switch (h->value_type)
+	{
+		case ITEM_VALUE_TYPE_STR:
+		case ITEM_VALUE_TYPE_TEXT:
+			return h->value.str;
+		case ITEM_VALUE_TYPE_LOG:
+			return h->value.log->value;
+		case ITEM_VALUE_TYPE_FLOAT:
+			zbx_snprintf(buffer, sizeof(buffer), ZBX_FS_DBL, h->value.dbl);
+			break;
+		case ITEM_VALUE_TYPE_UINT64:
+			zbx_snprintf(buffer, sizeof(buffer), ZBX_FS_UI64, h->value.ui64);
+			break;
+	}
+
+	return buffer;
+}
+
+static void	clickhouse_log_error(CURL *handle, CURLcode error)
+{
+	long	http_code;
+
+	if (CURLE_HTTP_RETURNED_ERROR == error)
+	{
+		curl_easy_getinfo(handle, CURLINFO_RESPONSE_CODE, &http_code);
+
+		if (0 != page.offset)
+		{
+			zabbix_log(LOG_LEVEL_ERR, "cannot get values from clickhouse, HTTP error: %ld,", http_code);
+		}
+		else
+			zabbix_log(LOG_LEVEL_ERR, "cannot get values from clickhouse, HTTP error: %ld", http_code);
+	}
+	else
+	{
+		zabbix_log(LOG_LEVEL_ERR, "cannot get values from clickhouse: %s", curl_easy_strerror(error));
+	}
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_close                                                          *
+ *                                                                                  *
+ * Purpose: closes connection and releases allocated resources                      *
+ *                                                                                  *
+ * Parameters:  hist - [IN] the history storage interface                           *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_close(zbx_history_iface_t *hist)
+{
+	zbx_clickhouse_data_t	*data = hist->data;
+
+	zbx_free(data->buf);
+	//zbx_free(data->post_url);
+
+	if (NULL != data->handle)
+	{
+		if (NULL != writer.handle)
+			curl_multi_remove_handle(writer.handle, data->handle);
+
+		curl_easy_cleanup(data->handle);
+		data->handle = NULL;
+	}
+}
+
+/******************************************************************************************************************
+ *                                                                                                                *
+ * common sql service support                                                                                     *
+ *                                                                                                                *
+ ******************************************************************************************************************/
+
+
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_init                                                    *
+ *                                                                                  *
+ * Purpose: initializes clickhouse writer for a new batch of history values            *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_writer_init()
+{
+	if (0 != writer.initialized)
+		return;
+
+	zbx_vector_ptr_create(&writer.ifaces);
+
+	if (NULL == (writer.handle = curl_multi_init()))
+	{
+		zbx_error("Cannot initialize cURL multi session");
+		exit(EXIT_FAILURE);
+	}
+
+	writer.initialized = 1;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_release                                                 *
+ *                                                                                  *
+ * Purpose: releases initialized clickhouse writer by freeing allocated resources and  *
+ *          setting its state to uninitialized.                                     *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_writer_release()
+{
+	int	i;
+
+	for (i = 0; i < writer.ifaces.values_num; i++)
+		clickhouse_close(writer.ifaces.values[i]);
+
+	curl_multi_cleanup(writer.handle);
+	writer.handle = NULL;
+
+	zbx_vector_ptr_destroy(&writer.ifaces);
+
+	writer.initialized = 0;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_add_iface                                               *
+ *                                                                                  *
+ * Purpose: adds history storage interface to be flushed later                      *
+ *                                                                                  *
+ * Parameters: db_insert - [IN] bulk insert data                                    *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_writer_add_iface(zbx_history_iface_t *hist)
+{
+	zbx_clickhouse_data_t	*data = hist->data;
+
+	clickhouse_writer_init();
+
+	if (NULL == (data->handle = curl_easy_init()))
+	{
+		zabbix_log(LOG_LEVEL_ERR, "cannot initialize cURL session");
+		return;
+	}
+
+	//curl_easy_setopt(data->handle, CURLOPT_URL, data->post_url);
+	curl_easy_setopt(data->handle, CURLOPT_URL, data->base_url);
+	curl_easy_setopt(data->handle, CURLOPT_POST, 1);
+	curl_easy_setopt(data->handle, CURLOPT_POSTFIELDS, data->buf);
+	curl_easy_setopt(data->handle, CURLOPT_WRITEFUNCTION, curl_write_send_cb);
+	curl_easy_setopt(data->handle, CURLOPT_FAILONERROR, 1L);
+
+	curl_multi_add_handle(writer.handle, data->handle);
+
+	zbx_vector_ptr_append(&writer.ifaces, hist);
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_writer_flush                                                   *
+ *                                                                                  *
+ * Purpose: posts historical data to clickhouse storage                                *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_writer_flush()
+{
+	const char		*__function_name = "clickhouse_writer_flush";
+
+	struct curl_slist	*curl_headers = NULL;
+	int			i, running, previous, msgnum;
+	CURLMsg			*msg;
+	zbx_vector_ptr_t	retries;
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s()", __function_name);
+
+	if (0 == writer.initialized)
+		return SUCCEED;
+
+	zbx_vector_ptr_create(&retries);
+
+	curl_headers = curl_slist_append(curl_headers, "Content-Type: application/x-ndjson");
+
+	for (i = 0; i < writer.ifaces.values_num; i++)
+	{
+		zbx_history_iface_t	*hist = (zbx_history_iface_t *)writer.ifaces.values[i];
+		zbx_clickhouse_data_t	*data = hist->data;
+
+		curl_easy_setopt(data->handle, CURLOPT_HTTPHEADER, curl_headers);
+
+		zabbix_log(LOG_LEVEL_DEBUG, "sending %s", data->buf);
+	}
+
+try_again:
+	previous = 0;
+
+	do
+	{
+		int		fds;
+		CURLMcode	code;
+
+		if (CURLM_OK != (code = curl_multi_perform(writer.handle, &running)))
+		{
+			zabbix_log(LOG_LEVEL_ERR, "cannot perform on curl multi handle: %s", curl_multi_strerror(code));
+			break;
+		}
+
+		if (CURLM_OK != (code = curl_multi_wait(writer.handle, NULL, 0, ZBX_HISTORY_STORAGE_DOWN, &fds)))
+		{
+			zabbix_log(LOG_LEVEL_ERR, "cannot wait on curl multi handle: %s", curl_multi_strerror(code));
+			break;
+		}
+
+		if (previous == running)
+			continue;
+
+		while (NULL != (msg = curl_multi_info_read(writer.handle, &msgnum)))
+		{
+			/* If the error is due to malformed data, there is no sense on re-trying to send. */
+			/* That's why we actually check for transport and curl errors separately */
+			if (CURLE_HTTP_RETURNED_ERROR == msg->data.result)
+			{
+				long int	err;
+
+				curl_easy_getinfo(msg->easy_handle, CURLINFO_RESPONSE_CODE, &err);
+
+				zabbix_log(LOG_LEVEL_ERR, "cannot send data to clickhouse, HTTP error %ld",  err);
+			}
+			else if (CURLE_OK != msg->data.result)
+			{
+				zabbix_log(LOG_LEVEL_WARNING, "%s: %s", "cannot send to clickhouse",
+						curl_easy_strerror(msg->data.result));
+
+				/* If the error is due to curl internal problems or unrelated */
+				/* problems with HTTP, we put the handle in a retry list and */
+				/* remove it from the current execution loop */
+				zbx_vector_ptr_append(&retries, msg->easy_handle);
+				curl_multi_remove_handle(writer.handle, msg->easy_handle);
+			}
+		}
+
+		previous = running;
+	}
+	while (running);
+
+	/* We check if we have handles to retry. If yes, we put them back in the multi */
+	/* handle and go to the beginning of the do while() for try sending the data again */
+	/* after sleeping for ZBX_HISTORY_STORAGE_DOWN / 1000 (seconds) */
+	if (0 < retries.values_num)
+	{
+		for (i = 0; i < retries.values_num; i++)
+			curl_multi_add_handle(writer.handle, retries.values[i]);
+
+		zbx_vector_ptr_clear(&retries);
+
+		sleep(ZBX_HISTORY_STORAGE_DOWN / 1000);
+		goto try_again;
+	}
+
+	curl_slist_free_all(curl_headers);
+
+	zbx_vector_ptr_destroy(&retries);
+
+	clickhouse_writer_release();
+
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
+	return SUCCEED;
+}
+
+/******************************************************************************************************************
+ *                                                                                                                *
+ * history interface support                                                                                      *
+ *                                                                                                                *
+ ******************************************************************************************************************/
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_destroy                                                        *
+ *                                                                                  *
+ * Purpose: destroys history storage interface                                      *
+ *                                                                                  *
+ * Parameters:  hist - [IN] the history storage interface                           *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_destroy(zbx_history_iface_t *hist)
+{
+	zbx_clickhouse_data_t	*data = hist->data;
+
+	clickhouse_close(hist);
+
+	zbx_free(data->base_url);
+	zbx_free(data);
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_get_values                                                     *
+ *                                                                                  *
+ * Purpose: gets item history data from history storage                             *
+ *                                                                                  *
+ * Parameters:  hist    - [IN] the history storage interface                        *
+ *              itemid  - [IN] the itemid                                           *
+ *              start   - [IN] the period start timestamp                           *
+ *              count   - [IN] the number of values to read                         *
+ *              end     - [IN] the period end timestamp                             *
+ *              values  - [OUT] the item history data values                        *
+ *                                                                                  *
+ * Return value: SUCCEED - the history data were read successfully                  *
+ *               FAIL - otherwise                                                   *
+ *                                                                                  *
+ * Comments: This function reads <count> values from ]<start>,<end>] interval or    *
+ *           all values from the specified interval if count is zero.               *
+ *                                                                                  *
+ ************************************************************************************/
+
+static int	clickhouse_get_values(zbx_history_iface_t *hist, zbx_uint64_t itemid, int start, int count, int end,
+		zbx_vector_history_record_t *values)
+{
+	const char		*__function_name = "clickhouse_get_values";
+	//static int first_run=0;
+	
+
+	zbx_clickhouse_data_t	*data = hist->data;
+
+	int			ret=SUCCEED;
+	int			i;
+
+	CURLcode		err;
+	struct curl_slist	*curl_headers = NULL;
+
+	char	*sql_buffer=NULL;
+	size_t			buf_alloc = 0, buf_offset = 0;
+
+	zbx_history_record_t	hr;
+
+
+	//if (0 == first_run) 
+	//	first_run = time(NULL);
+	
+	//just for testing to avoid history thread startup hummering
+	return ret;
+	
+	//fix to prevent ValueCache filling on zabbix server startup
+	//in case when there are lots of items it's usually faster to 
+	//fill them via polling and not to kill the database with millions 
+	//of requests
+	
+	//if (time(NULL)-first_run < ZBX_VALUECACHE_FILL_TIME) return (ret);
+	
+
+	//remove this after fixing segv on zabbix 4+
+	//but in reality, the server DOES NOT HAVE TO GO TO SLOW DB to get last year's average
+	//it better to plan your checks right or increase ValueCache mem size
+	//return (ret);
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s() Data request: we are asked for item%ld starting:%d ending:%d, count:%d", __function_name,itemid,start,end,count);
+
+
+	//HACK FIX TODO make it proper
+	//i see no reason to hold data in the value cache older then 1 day long 
+	//sure there must NOT be triggers with such a demand
+	//this is dirty workaround, has to fix like in ZABBIX history sql module
+	//trying to select data for several periods starting from day and extending 
+	//to month, but i am sure for triggering and alerting data from more then one 
+	//day long isn't really important
+	//
+	//to make things proper remove next condition, i put it here to resolver
+	//clickhouse overload problem but it was something else, amyway i've decided to leave it here
+
+	//if (end - start > 86400) {
+	  //  start=end-7*86400;
+	//} 
+
+
+	if (NULL == (data->handle = curl_easy_init()))
+	{
+		zabbix_log(LOG_LEVEL_ERR, "cannot initialize cURL session");
+		return FAIL;
+	}
+
+	zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, 
+		"SELECT  toUInt32(clock),ns,value,value_dbl,value_str FROM %s WHERE itemid=%ld ",
+		CONFIG_HISTORY_STORAGE_TABLE_NAME,itemid);
+
+
+	if (1 == end-start) {
+
+		zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "AND clock = %d ", end);
+
+	} else {
+		if (0 < start) {
+			zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "AND clock > %d ", start);
+		}
+		if (0 < end ) {
+			zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "AND clock <= %d ", end);
+		}
+	}
+
+	zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "ORDER BY clock DESC ");
+
+	if (0<count) 
+	{
+	    zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "LIMIT %d", count);
+	}
+
+	zabbix_log(LOG_LEVEL_DEBUG, "sending query to clickhouse: %s", sql_buffer);
+
+
+	curl_easy_setopt(data->handle, CURLOPT_URL, data->base_url);
+	curl_easy_setopt(data->handle, CURLOPT_POSTFIELDS, sql_buffer);
+	curl_easy_setopt(data->handle, CURLOPT_WRITEFUNCTION, curl_write_cb);
+	curl_easy_setopt(data->handle, CURLOPT_HTTPHEADER, curl_headers);
+	curl_easy_setopt(data->handle, CURLOPT_FAILONERROR, 1L);
+
+
+	page.offset = 0;
+
+	if (CURLE_OK != (err = curl_easy_perform(data->handle)))
+	{
+		clickhouse_log_error(data->handle, err);
+		goto out;
+	}
+
+
+	//curl_easy_setopt(data->handle, CURLOPT_URL, data->post_url);
+	curl_easy_setopt(data->handle, CURLOPT_URL, data->base_url);
+	zabbix_log(LOG_LEVEL_DEBUG, "recieved from clickhouse: %s", page.data);
+		
+	
+	char *end_str;
+	if (NULL !=page.data && page.data[0]!=0) {
+
+	    //zabbix_log(LOG_LEVEL_DEBUG, "Parcing line by line");
+	    int line_count=0, field_count=0;
+
+
+	    char *line_ptr = strtok_r(page.data, "\n", &end_str);
+
+	    while (line_ptr != NULL)
+	    {
+			char *end_field;
+			char *field_ptr = strtok_r(line_ptr, "\t", &end_field);
+			char *fields[MAX_HISTORY_CLICKHOUSE_FIELDS];
+
+			zabbix_log(LOG_LEVEL_DEBUG, "Parsing line '%s'", line_ptr);
+
+			for (i=0; i++; i<field_count)  fields[i]=NULL; 
+
+			while (field_ptr != NULL && MAX_HISTORY_CLICKHOUSE_FIELDS>field_count) 
+			{	
+				fields[field_count++]=field_ptr;
+				field_ptr = strtok_r(NULL, "\t", &end_field);
+			}
+			
+			//the fields order  must be in sync with SQL query above
+			//OR TODO: make it via some proper interface, perhaps JSON or whatever clickhouse supports to 
+			//be able to distingiosh wich value is from what field name, not depending on the order in SQL request
+
+
+			zabbix_log(LOG_LEVEL_TRACE, "Parsed line %d clock:'%s', ns:'%s', value:'%s', value_dbl:'%s' '",line_count, fields[0],fields[1],fields[2],fields[3]);
+
+			if (NULL != fields[4]) 
+			{
+				//we've got at least three fields
+				hr.timestamp.sec = atoi(fields[0]);
+				hr.timestamp.ns = atoi(fields[1]);
+				switch (hist->value_type)
+				{
+					case ITEM_VALUE_TYPE_UINT64:
+						zabbix_log(LOG_LEVEL_TRACE, "Parsed  as UINT64 %s",fields[2]);
+			    		hr.value = history_str2value(fields[2], hist->value_type);
+						break;
+
+					case ITEM_VALUE_TYPE_FLOAT: 
+						zabbix_log(LOG_LEVEL_TRACE, "Parsed  as DBL field %s",fields[3]);
+			    		hr.value = history_str2value(fields[3], hist->value_type);
+						break;
+					case ITEM_VALUE_TYPE_STR:
+					case ITEM_VALUE_TYPE_TEXT:
+						//!!!! for some reason there are major memory leak when reading 
+						//string values from history.
+						//remove the following goto statement if you really need it
+						goto out;
+
+						zabbix_log(LOG_LEVEL_TRACE, "Parsed  as STR/TEXT type %s",fields[4]);
+						hr.value = history_str2value(fields[4], hist->value_type);
+					case ITEM_VALUE_TYPE_LOG:
+						//todo: if i ever need this, but for now there is no log write to clickhouse
+						goto out;
+				}				
+				//adding to zabbix vector
+				zbx_vector_history_record_append_ptr(values, &hr);
+
+				ret=SUCCEED;
+				line_count++;
+			} else {
+				zabbix_log(LOG_LEVEL_DEBUG, "Skipping the result, not enough fields");
+			}
+			
+			line_ptr = strtok_r(NULL, "\n", &end_str);
+	    }
+	    page.data[0]=0;	
+	} else 
+	{
+	    zabbix_log(LOG_LEVEL_DEBUG, "No data from clickhouse");
+	    ret = SUCCEED;
+	}
+
+
+out:
+	clickhouse_close(hist);
+	curl_slist_free_all(curl_headers);
+	zbx_free(sql_buffer);
+
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
+	return SUCCEED;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_add_values                                                     *
+ *                                                                                  *
+ * Purpose: sends history data to the storage                                       *
+ *                                                                                  *
+ * Parameters:  hist    - [IN] the history storage interface                        *
+ *              history - [IN] the history data vector (may have mixed value types) *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_add_values(zbx_history_iface_t *hist, const zbx_vector_ptr_t *history)
+{
+	const char	*__function_name = "clickhouse_add_values";
+
+	char *tmp_buffer=NULL;	
+	size_t tmp_alloc=0, tmp_offset=0;
+
+	zbx_clickhouse_data_t	*data = hist->data;
+	int			i, num = 0;
+	ZBX_DC_HISTORY		*h;
+
+	size_t			buf_alloc = 0, buf_offset = 0;
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s()", __function_name);
+	
+
+	zbx_snprintf_alloc(&tmp_buffer,&tmp_alloc,&tmp_offset,"INSERT INTO %s VALUES ", CONFIG_HISTORY_STORAGE_TABLE_NAME );
+
+	for (i = 0; i < history->values_num; i++)
+	{
+		h = (ZBX_DC_HISTORY *)history->values[i];
+
+		if (hist->value_type != h->value_type)
+			continue;
+
+		
+		 if (ITEM_VALUE_TYPE_UINT64 == h->value_type) {
+		    //zabbix_log(LOG_LEVEL_DEBUG, "Parsing value as UIN64 type");
+		    zbx_snprintf_alloc(&tmp_buffer,&tmp_alloc,&tmp_offset,"(CAST(%d as date) ,%ld,%d,%d,%ld,0,''),",
+					h->ts.sec,h->itemid,h->ts.sec,h->ts.ns,h->value.ui64);
+		}
+
+		 if (ITEM_VALUE_TYPE_FLOAT == h->value_type) {
+		    //zabbix_log(LOG_LEVEL_DEBUG, "Parsing value as float type");
+		    zbx_snprintf_alloc(&tmp_buffer,&tmp_alloc,&tmp_offset,"(CAST(%d as date) ,%ld,%d,%d,0,%f,''),",
+					h->ts.sec,h->itemid,h->ts.sec,h->ts.ns,h->value.dbl);
+		}
+
+		 if (ITEM_VALUE_TYPE_STR == h->value_type || 
+		 	 ITEM_VALUE_TYPE_TEXT == h->value_type ) {
+		    //zabbix_log(LOG_LEVEL_DEBUG, "Parsing value as string or text type");
+		    zbx_snprintf_alloc(&tmp_buffer,&tmp_alloc,&tmp_offset,"(CAST(%d as date) ,%ld,%d,%d,0,0,'%s'),",
+					h->ts.sec,h->itemid,h->ts.sec,h->ts.ns,h->value.str);
+		}
+
+		if (ITEM_VALUE_TYPE_LOG == h->value_type)
+		{
+			const zbx_log_value_t	*log;
+			log = h->value.log;
+		}
+
+		num++;
+	}
+
+	if (num > 0)
+	{ 
+		zbx_snprintf_alloc(&data->buf, &buf_alloc, &buf_offset, "%s\n", tmp_buffer);
+		zabbix_log(LOG_LEVEL_DEBUG, "will insert to clickhouse: %s",data->buf);
+	
+		//data->post_url = zbx_dsprintf(NULL, "%s", data->base_url);
+		clickhouse_writer_add_iface(hist);
+	}
+
+	zbx_free(tmp_buffer);
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
+	
+	return num;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_flush                                                          *
+ *                                                                                  *
+ * Purpose: flushes the history data to storage                                     *
+ *                                                                                  *
+ * Parameters:  hist    - [IN] the history storage interface                        *
+ *                                                                                  *
+ * Comments: This function will try to flush the data until it succeeds or          *
+ *           unrecoverable error occurs                                             *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_flush(zbx_history_iface_t *hist)
+{
+	ZBX_UNUSED(hist);
+
+	return clickhouse_writer_flush();
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: zbx_history_clickhouse_init                                               *
+ *                                                                                  *
+ * Purpose: initializes history storage interface                                   *
+ *                                                                                  *
+ * Parameters:  hist       - [IN] the history storage interface                     *
+ *              value_type - [IN] the target value type                             *
+ *              error      - [OUT] the error message                                *
+ *                                                                                  *
+ * Return value: SUCCEED - the history storage interface was initialized            *
+ *               FAIL    - otherwise                                                *
+ *                                                                                  *
+ ************************************************************************************/
+int	zbx_history_clickhouse_init(zbx_history_iface_t *hist, unsigned char value_type, char **error)
+{
+	zbx_clickhouse_data_t	*data;
+
+	if (0 != curl_global_init(CURL_GLOBAL_ALL))
+	{
+		*error = zbx_strdup(*error, "Cannot initialize cURL library");
+		return FAIL;
+	}
+
+	data = zbx_malloc(NULL, sizeof(zbx_clickhouse_data_t));
+	memset(data, 0, sizeof(zbx_clickhouse_data_t));
+	data->base_url = zbx_strdup(NULL, CONFIG_HISTORY_STORAGE_URL);
+	zbx_rtrim(data->base_url, "/");
+	data->buf = NULL;
+	//data->post_url = NULL;
+	data->handle = NULL;
+
+	hist->value_type = value_type;
+	hist->data = data;
+	hist->destroy = clickhouse_destroy;
+	hist->add_values = clickhouse_add_values;
+	hist->flush = clickhouse_flush;
+	hist->get_values = clickhouse_get_values;
+	hist->requires_trends = 0;
+
+	return SUCCEED;
+}
+
+#else
+
+int	zbx_history_clickhouse_init(zbx_history_iface_t *hist, unsigned char value_type, char **error)
+{
+	ZBX_UNUSED(hist);
+	ZBX_UNUSED(value_type);
+
+	*error = zbx_strdup(*error, "cURL library support >= 7.28.0 is required for clickhouse history backend");
+	return FAIL;
+}
+
+#endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/src/libs/zbxhistory/history.h xe-rabbix/src/libs/zbxhistory/history.h
--- zabbix-4.0.1rc1/src/libs/zbxhistory/history.h	2018-10-22 13:32:47.000000000 +0500
+++ xe-rabbix/src/libs/zbxhistory/history.h	2018-10-25 22:54:06.201262281 +0500
@@ -49,4 +49,7 @@
 /* elastic hist */
 int	zbx_history_elastic_init(zbx_history_iface_t *hist, unsigned char value_type, char **error);
 
+/* clickhouse hist */
+int	zbx_history_clickhouse_init(zbx_history_iface_t *hist, unsigned char value_type, char **error);
+
 #endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/src/libs/zbxhistory/Makefile.am xe-rabbix/src/libs/zbxhistory/Makefile.am
--- zabbix-4.0.1rc1/src/libs/zbxhistory/Makefile.am	2018-10-22 13:32:47.000000000 +0500
+++ xe-rabbix/src/libs/zbxhistory/Makefile.am	2018-10-25 22:54:06.201262281 +0500
@@ -5,4 +5,5 @@
 libzbxhistory_a_SOURCES = \
 	history.c history.h \
 	history_sql.c \
-	history_elastic.c 
+	history_elastic.c \
+	history_clickhouse.c
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/src/libs/zbxhistory/Makefile.in xe-rabbix/src/libs/zbxhistory/Makefile.in
--- zabbix-4.0.1rc1/src/libs/zbxhistory/Makefile.in	2018-10-22 13:36:34.000000000 +0500
+++ xe-rabbix/src/libs/zbxhistory/Makefile.in	2018-10-25 22:54:06.201262281 +0500
@@ -112,7 +112,7 @@
 libzbxhistory_a_AR = $(AR) $(ARFLAGS)
 libzbxhistory_a_LIBADD =
 am_libzbxhistory_a_OBJECTS = history.$(OBJEXT) history_sql.$(OBJEXT) \
-	history_elastic.$(OBJEXT)
+	history_elastic.$(OBJEXT) history_clickhouse.$(OBJEXT) 
 libzbxhistory_a_OBJECTS = $(am_libzbxhistory_a_OBJECTS)
 AM_V_P = $(am__v_P_@AM_V@)
 am__v_P_ = $(am__v_P_@AM_DEFAULT_V@)
@@ -370,7 +370,8 @@
 libzbxhistory_a_SOURCES = \
 	history.c history.h \
 	history_sql.c \
-	history_elastic.c 
+	history_elastic.c \
+	history_clickhouse.c 
 
 all: all-am
 
@@ -424,6 +425,7 @@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/history.Po@am__quote@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/history_elastic.Po@am__quote@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/history_sql.Po@am__quote@
+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/history_clickhouse.Po@am__quote@
 
 .c.o:
 @am__fastdepCC_TRUE@	$(AM_V_CC)depbase=`echo $@ | sed 's|[^/]*$$|$(DEPDIR)/&|;s|\.o$$||'`;\
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/src/libs/zbxicmpping/icmpping.c xe-rabbix/src/libs/zbxicmpping/icmpping.c
--- zabbix-4.0.1rc1/src/libs/zbxicmpping/icmpping.c	2018-10-22 13:32:47.000000000 +0500
+++ xe-rabbix/src/libs/zbxicmpping/icmpping.c	2018-10-25 22:54:06.201262281 +0500
@@ -24,10 +24,14 @@
 
 extern char	*CONFIG_SOURCE_IP;
 extern char	*CONFIG_FPING_LOCATION;
+extern char	*CONFIG_NMAP_LOCATION;
+extern char	*CONFIG_NMAP_PARAMS;
+
 #ifdef HAVE_IPV6
 extern char	*CONFIG_FPING6_LOCATION;
 #endif
 extern char	*CONFIG_TMPDIR;
+#define MAX_ICMP_NMAP_FIELDS		10
 
 /* old official fping (2.4b2_to_ipv6) did not support source IP address */
 /* old patched versions (2.4b2_to_ipv6) provided either -I or -S options */
@@ -73,6 +77,7 @@
 	*checked = 1;
 }
 
+
 static int	process_ping(ZBX_FPING_HOST *hosts, int hosts_count, int count, int interval, int size, int timeout,
 		char *error, int max_error_len)
 {
@@ -242,134 +247,287 @@
 
 	fclose(f);
 
-	zabbix_log(LOG_LEVEL_DEBUG, "%s", tmp);
+	//use 1 packet as an indication that we want to use nmap
+	//since it's turned out that doing one packet check via vping is also a good idea, 
+	// timeout =1 (not realistic value ) used to indicate we want nmap to be invoked
+	// this also allows to runtime modification of the utility
+	if ( 1 == count ) 
+	{
+		//for 1-packet probes use nmap as accesibility utility
+		//ipv6 ??? i guess it won't work, but who knows: todo: check and fix ipv6 as soon as we have it
+
+		if (-1 == size ) size=32;
+		
+		zbx_snprintf(tmp, sizeof(tmp), "%s --data-length=%d %s -iL %s 2>&1",
+								CONFIG_NMAP_LOCATION,size,CONFIG_NMAP_PARAMS,filename);
 
-	if (NULL == (f = popen(tmp, "r")))
-	{
-		zbx_snprintf(error, max_error_len, "%s: %s", tmp, zbx_strerror(errno));
 
-		unlink(filename);
-
-		return ret;
-	}
+		zabbix_log(LOG_LEVEL_DEBUG, "Will run %s", tmp);
 
-	if (NULL == fgets(tmp, sizeof(tmp), f))
-	{
-		strscpy(tmp, "no output");
-	}
-	else
-	{
 		for (i = 0; i < hosts_count; i++)
 		{
-			hosts[i].status = (char *)zbx_malloc(NULL, count);
-			memset(hosts[i].status, 0, count);
+			hosts[i].rcv=0;
+			hosts[i].cnt=count;
 		}
 
+		if ( NULL == (f = popen(tmp, "r")))
+		{
+			zbx_snprintf(error, max_error_len, "%s: %s", tmp, zbx_strerror(errno));
+			unlink(filename);
+			return ret;
+		}
+
+		//	memset(tmp,0,sizeof(char)*
+		if ( NULL == fgets(tmp, sizeof(tmp), f)) {
+			zbx_snprintf(error, max_error_len, "Nmap failed: empty output");
+			return ret;
+		}
+		
 		do
 		{
+			char *fields[MAX_ICMP_NMAP_FIELDS];
+			char *end_field;
+			char *latency;
+
 			zbx_rtrim(tmp, "\n");
 			zabbix_log(LOG_LEVEL_DEBUG, "read line [%s]", tmp);
 
+			if (25 > strnlen(tmp,MAX_STRING_LEN) ) {
+				zabbix_log(LOG_LEVEL_DEBUG, "skipping too short line");
+				continue;
+			} 
+
+			//splitting line into fields
+			char *field_ptr = strtok_r(tmp, " ", &end_field);
+			int field_count=0;
+
+			for (i=0; i++; i<field_count) 
+				fields[i]=NULL; 
+
+			while ( field_ptr != NULL && MAX_ICMP_NMAP_FIELDS > field_count) 
+			{	
+				zabbix_log(LOG_LEVEL_DEBUG, "read field %d [%s]",field_count, field_ptr);
+			    fields[field_count++]=field_ptr;
+			    field_ptr = strtok_r(NULL, " ", &end_field);
+			}
+
+			if ( NULL == fields[4]) {
+				zabbix_log(LOG_LEVEL_DEBUG, "String 1 has not enough fields ");
+				continue;
+			}
+			
+			if (strcmp("Nmap",fields[0]) != 0 ||
+				strcmp("scan",fields[1]) !=0  ||
+				strcmp("report", fields[2]) !=0 )  
+			{  
+				zabbix_log(LOG_LEVEL_DEBUG, "String doesn't match 'Nmap scan for', skipping");
+				continue;
+			}
+
 			host = NULL;
 
-			if (NULL != (c = strchr(tmp, ' ')))
+			for (i = 0; i < hosts_count; i++)
 			{
-				*c = '\0';
-				for (i = 0; i < hosts_count; i++)
-					if (0 == strcmp(tmp, hosts[i].addr))
-					{
-						host = &hosts[i];
-						break;
-					}
-				*c = ' ';
+				if (0 == strcmp(fields[4], hosts[i].addr))
+				{
+					host = &hosts[i];
+					zabbix_log(LOG_LEVEL_DEBUG, "Host has been found %s", fields[4]);
+					break;
+				}
 			}
 
-			if (NULL == host)
+			if (NULL == host) {
+				zabbix_log(LOG_LEVEL_DEBUG, "Host hasn't been found in the request");
 				continue;
+			} else {
+				zabbix_log(LOG_LEVEL_DEBUG, "Host has been found %s", fields[4]);
+			}
 
-			if (NULL == (c = strstr(tmp, " : ")))
+			if (NULL == fgets(tmp, sizeof(tmp), f)) {
+				zabbix_log(LOG_LEVEL_DEBUG, "Couldn't read second line");
 				continue;
+			}
+
+			zabbix_log(LOG_LEVEL_DEBUG, "read line %s", tmp);
+			zbx_rtrim(tmp, "\n");
 
-			/* when NIC bonding is used, there are also lines like */
-			/* 192.168.1.2 : duplicate for [0], 96 bytes, 0.19 ms */
+			field_ptr = strtok_r(tmp, " ", &end_field);
 
-			if (NULL != strstr(tmp, "duplicate for"))
-				continue;
+			for (i = 0; i++; i<field_count)
+				fields[i]=NULL;
+
+			field_count=0;
 
-			c += 3;
+			while (field_ptr != NULL && MAX_ICMP_NMAP_FIELDS>field_count) 
+			{	
+				zabbix_log(LOG_LEVEL_DEBUG, "String 2 parced field %s",field_ptr);
+				fields[field_count++]=field_ptr;
+				field_ptr = strtok_r(NULL, " ", &end_field);
+			}
+
+			if (NULL == fields[3]) {
+				zabbix_log(LOG_LEVEL_DEBUG, "String too short");
+				continue;
+			}
 
-			/* The were two issues with processing only the fping's final status line:  */
-			/*   1) pinging broadcast addresses could have resulted in responses from   */
-			/*      different hosts, which were counted as the target host responses;   */
-			/*   2) there is a bug in fping (v3.8 at least) where pinging broadcast     */
-			/*      address will result in no individual responses, but the final       */
-			/*      status line might contain a bogus value.                            */
-			/* Because of the above issues we must monitor the individual responses     */
-			/* and mark the valid ones.                                                 */
-			if ('[' == *c)
+			if ( 0 != strncmp(fields[0], "Host", 2) ||
+				 0 != strncmp(fields[1], "is", 2)  ||
+				 0 != strncmp(fields[2], "up", 2) ) 
 			{
-				/* Fping appends response source address in format '[<- 10.3.0.10]' */
-				/* if it does not match the target address. Ignore such responses.  */
-				if (NULL != strstr(c + 1, "[<-"))
-					continue;
+				zabbix_log(LOG_LEVEL_DEBUG, "String 2 doesn't match 'Host is up', skipping");
+				continue;
+			}
 
-				/* get the index of individual ping response */
-				index = atoi(c + 1);
+			latency=fields[3]+1;
+			zbx_rtrim(latency,"s");
+			sec=atof(latency);
+
+			host->rcv=count;
+			host->min=sec;
+			host->max=sec;
+			host->sum=sec*count;
 
-				if (0 > index || index >= count)
-					continue;
+			zabbix_log(LOG_LEVEL_DEBUG, "Final parced info is host=%s , latency=%f",host->addr,sec);
 
-				host->status[index] = 1;
+			ret = SUCCEED;
+		}
+		while (NULL != fgets(tmp, sizeof(tmp), f));
 
-				continue;
+		if (NOTSUPPORTED == ret)
+			zbx_snprintf(error, max_error_len, "Nmap failed");
+
+	} else 
+	{
+		//doing things fping way
+		zabbix_log(LOG_LEVEL_DEBUG, "%s", tmp);
+
+		if (NULL == (f = popen(tmp, "r")))
+		{
+			zbx_snprintf(error, max_error_len, "%s: %s", tmp, zbx_strerror(errno));
+			unlink(filename);
+			return ret;
+		}
+
+		if (NULL == fgets(tmp, sizeof(tmp), f))
+		{
+			strscpy(tmp, "no output");
+		}
+		else
+		{
+			for (i = 0; i < hosts_count; i++)
+			{
+				hosts[i].status = (char *)zbx_malloc(NULL, count);
+				memset(hosts[i].status, 0, count);
 			}
 
-			/* process status line for a host */
-			index = 0;
 			do
 			{
-				if (1 == host->status[index])
+				zbx_rtrim(tmp, "\n");
+				zabbix_log(LOG_LEVEL_DEBUG, "read line [%s]", tmp);
+
+				host = NULL;
+
+				if (NULL != (c = strchr(tmp, ' ')))
+				{
+					*c = '\0';
+					for (i = 0; i < hosts_count; i++)
+						if (0 == strcmp(tmp, hosts[i].addr))
+						{
+							host = &hosts[i];
+							break;
+						}
+					*c = ' ';
+				}
+
+				if (NULL == host)
+					continue;
+
+				if (NULL == (c = strstr(tmp, " : ")))
+					continue;
+
+				/* when NIC bonding is used, there are also lines like */
+				/* 192.168.1.2 : duplicate for [0], 96 bytes, 0.19 ms */
+
+				if (NULL != strstr(tmp, "duplicate for"))
+					continue;
+
+				c += 3;
+
+				/* The were two issues with processing only the fping's final status line:  */
+				/*   1) pinging broadcast addresses could have resulted in responses from   */
+				/*      different hosts, which were counted as the target host responses;   */
+				/*   2) there is a bug in fping (v3.8 at least) where pinging broadcast     */
+				/*      address will result in no individual responses, but the final       */
+				/*      status line might contain a bogus value.                            */
+				/* Because of the above issues we must monitor the individual responses     */
+				/* and mark the valid ones.                                                 */
+				if ('[' == *c)
 				{
-					sec = atof(c) / 1000; /* convert ms to seconds */
+					/* Fping appends response source address in format '[<- 10.3.0.10]' */
+					/* if it does not match the target address. Ignore such responses.  */
+					if (NULL != strstr(c + 1, "[<-"))
+						continue;
+
+					/* get the index of individual ping response */
+					index = atoi(c + 1);
+
+					if (0 > index || index >= count)
+						continue;
 
-					if (0 == host->rcv || host->min > sec)
-						host->min = sec;
-					if (0 == host->rcv || host->max < sec)
-						host->max = sec;
-					host->sum += sec;
-					host->rcv++;
+					host->status[index] = 1;
+
+					continue;
 				}
-			}
-			while (++index < count && NULL != (c = strchr(c + 1, ' ')));
 
-			host->cnt += count;
+				/* process status line for a host */
+				index = 0;
+				do
+				{
+					if (1 == host->status[index])
+					{
+						sec = atof(c) / 1000; /* convert ms to seconds */
+
+						if (0 == host->rcv || host->min > sec)
+							host->min = sec;
+						if (0 == host->rcv || host->max < sec)
+							host->max = sec;
+						host->sum += sec;
+						host->rcv++;
+					}
+				}
+				while (++index < count && NULL != (c = strchr(c + 1, ' ')));
+
+				host->cnt += count;
 #ifdef HAVE_IPV6
-			if (host->cnt == count && NULL == CONFIG_SOURCE_IP &&
-					0 != (fping_existence & FPING_EXISTS) &&
-					0 != (fping_existence & FPING6_EXISTS))
-			{
-				memset(host->status, 0, count);	/* reset response statuses for IPv6 */
-			}
+				if (host->cnt == count && NULL == CONFIG_SOURCE_IP &&
+						0 != (fping_existence & FPING_EXISTS) &&
+						0 != (fping_existence & FPING6_EXISTS))
+				{
+					memset(host->status, 0, count);	/* reset response statuses for IPv6 */
+				}
 #endif
-			ret = SUCCEED;
+				ret = SUCCEED;
+			}
+			while (NULL != fgets(tmp, sizeof(tmp), f));
+
+			for (i = 0; i < hosts_count; i++)
+				zbx_free(hosts[i].status);
 		}
-		while (NULL != fgets(tmp, sizeof(tmp), f));
 
-		for (i = 0; i < hosts_count; i++)
-			zbx_free(hosts[i].status);
+		if (NOTSUPPORTED == ret)
+			zbx_snprintf(error, max_error_len, "fping failed: %s", tmp);
 	}
-	pclose(f);
 
+	pclose(f);
 	unlink(filename);
 
-	if (NOTSUPPORTED == ret)
-		zbx_snprintf(error, max_error_len, "fping failed: %s", tmp);
 
 	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
 
 	return ret;
 }
 
+
 /******************************************************************************
  *                                                                            *
  * Function: do_ping                                                          *
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/src/libs/zbxself/selfmon.c xe-rabbix/src/libs/zbxself/selfmon.c
--- zabbix-4.0.1rc1/src/libs/zbxself/selfmon.c	2018-10-22 13:32:48.000000000 +0500
+++ xe-rabbix/src/libs/zbxself/selfmon.c	2018-10-25 22:54:06.205262206 +0500
@@ -89,6 +89,8 @@
 extern char	*CONFIG_FILE;
 extern int	CONFIG_POLLER_FORKS;
 extern int	CONFIG_UNREACHABLE_POLLER_FORKS;
+extern int	CONFIG_ASYNC_SNMP_POLLER_FORKS;
+extern int	CONFIG_ASYNC_AGENT_POLLER_FORKS;
 extern int	CONFIG_IPMIPOLLER_FORKS;
 extern int	CONFIG_PINGER_FORKS;
 extern int	CONFIG_JAVAPOLLER_FORKS;
@@ -138,6 +140,10 @@
 	{
 		case ZBX_PROCESS_TYPE_POLLER:
 			return CONFIG_POLLER_FORKS;
+		case ZBX_PROCESS_TYPE_ASYNC_AGENT:
+			return CONFIG_ASYNC_AGENT_POLLER_FORKS;
+		case ZBX_PROCESS_TYPE_ASYNC_SNMP:
+			return CONFIG_ASYNC_SNMP_POLLER_FORKS;
 		case ZBX_PROCESS_TYPE_UNREACHABLE:
 			return CONFIG_UNREACHABLE_POLLER_FORKS;
 		case ZBX_PROCESS_TYPE_IPMIPOLLER:
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/src/libs/zbxserver/expression.c xe-rabbix/src/libs/zbxserver/expression.c
--- zabbix-4.0.1rc1/src/libs/zbxserver/expression.c	2018-10-22 13:32:47.000000000 +0500
+++ xe-rabbix/src/libs/zbxserver/expression.c	2018-10-25 22:54:06.213262059 +0500
@@ -3758,6 +3758,11 @@
 					ret = DBget_trigger_value(event->trigger.expression, &replace_to, N_functionid,
 							ZBX_REQUEST_HOST_DNS);
 				}
+				else if (0 == strcmp(m, MVAR_HOST_DESCRIPTION))
+				{
+					ret = DBget_trigger_value(event->trigger.expression, &replace_to, N_functionid,
+							ZBX_REQUEST_HOST_DESCRIPTION);
+				}
 				else if (0 == strcmp(m, MVAR_HOST_CONN))
 				{
 					ret = DBget_trigger_value(event->trigger.expression, &replace_to, N_functionid,
@@ -4660,7 +4665,7 @@
 	zbx_hashset_iter_t	iter;
 
 	zabbix_log(LOG_LEVEL_DEBUG, "In %s() funcs_num:%d", __function_name, funcs->num_data);
-
+	
 	zbx_vector_uint64_create(&itemids);
 	zbx_vector_uint64_reserve(&itemids, funcs->num_data);
 
@@ -4675,7 +4680,6 @@
 	errcodes = (int *)zbx_malloc(errcodes, sizeof(int) * (size_t)itemids.values_num);
 
 	DCconfig_get_items_by_itemids(items, itemids.values, errcodes, itemids.values_num);
-
 	zbx_hashset_iter_reset(funcs, &iter);
 	while (NULL != (func = (zbx_func_t *)zbx_hashset_iter_next(&iter)))
 	{
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x zabbix_server zabbix-4.0.1rc1/src/zabbix_proxy/proxy.c xe-rabbix/src/zabbix_proxy/proxy.c
--- zabbix-4.0.1rc1/src/zabbix_proxy/proxy.c	2018-10-22 13:32:47.000000000 +0500
+++ xe-rabbix/src/zabbix_proxy/proxy.c	2018-10-25 22:54:06.221261912 +0500
@@ -144,6 +144,7 @@
 int	CONFIG_PINGER_FORKS		= 1;
 int	CONFIG_POLLER_FORKS		= 5;
 int	CONFIG_UNREACHABLE_POLLER_FORKS	= 1;
+int	CONFIG_ASYNC_POLLER_FORKS	= 2;
 int	CONFIG_HTTPPOLLER_FORKS		= 1;
 int	CONFIG_IPMIPOLLER_FORKS		= 0;
 int	CONFIG_TRAPPER_FORKS		= 5;
@@ -262,6 +263,13 @@
 
 char	*CONFIG_HISTORY_STORAGE_URL		= NULL;
 char	*CONFIG_HISTORY_STORAGE_OPTS		= NULL;
+char	*CONFIG_HISTORY_STORAGE_TYPE		= NULL;
+char	*CONFIG_HISTORY_STORAGE_TABLE_NAME		= NULL;
+
+
+char *CONFIG_NMAP_PARAMS = NULL;
+char *CONFIG_NMAP_LOCATION = NULL;
+
 int	CONFIG_HISTORY_STORAGE_PIPELINES	= 0;
 
 int	get_process_info_by_thread(int local_server_num, unsigned char *local_process_type, int *local_process_num);
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' zabbix-4.0.0/src/zabbix_server/server.c xe-rabbix/src/zabbix_server/server.c
--- zabbix-4.0.0/src/zabbix_server/server.c	2018-10-01 13:35:59.000000000 +0500
+++ xe-rabbix/src/zabbix_server/server.c	2018-10-22 11:07:02.000000000 +0500
@@ -157,6 +157,8 @@
 int	CONFIG_PINGER_FORKS		= 1;
 int	CONFIG_POLLER_FORKS		= 5;
 int	CONFIG_UNREACHABLE_POLLER_FORKS	= 1;
+int	CONFIG_ASYNC_SNMP_POLLER_FORKS	= 1;
+int	CONFIG_ASYNC_AGENT_POLLER_FORKS	= 1;
 int	CONFIG_HTTPPOLLER_FORKS		= 1;
 int	CONFIG_IPMIPOLLER_FORKS		= 0;
 int	CONFIG_TIMER_FORKS		= 1;
@@ -211,6 +213,11 @@
 char	*CONFIG_TMPDIR			= NULL;
 char	*CONFIG_FPING_LOCATION		= NULL;
 char	*CONFIG_FPING6_LOCATION		= NULL;
+char	*CONFIG_NMAP_LOCATION		= NULL;
+char	*CONFIG_NMAP_PARAMS		= NULL;
+char	*CONFIG_HISTORY_STORAGE_TYPE	= NULL;
+char	*CONFIG_HISTORY_STORAGE_TABLE_NAME = NULL;
+
 char	*CONFIG_DBHOST			= NULL;
 char	*CONFIG_DBNAME			= NULL;
 char	*CONFIG_DBSCHEMA		= NULL;
@@ -376,6 +383,16 @@
 		*local_process_type = ZBX_PROCESS_TYPE_UNREACHABLE;
 		*local_process_num = local_server_num - server_count + CONFIG_UNREACHABLE_POLLER_FORKS;
 	}
+	else if (local_server_num <= (server_count += CONFIG_ASYNC_SNMP_POLLER_FORKS))
+	{
+		*local_process_type = ZBX_PROCESS_TYPE_ASYNC_SNMP;
+		*local_process_num = local_server_num - server_count + CONFIG_ASYNC_SNMP_POLLER_FORKS;
+	}
+	else if (local_server_num <= (server_count += CONFIG_ASYNC_AGENT_POLLER_FORKS))
+	{
+		*local_process_type = ZBX_PROCESS_TYPE_ASYNC_AGENT;
+		*local_process_num = local_server_num - server_count + CONFIG_ASYNC_AGENT_POLLER_FORKS;
+	}
 	else if (local_server_num <= (server_count += CONFIG_TRAPPER_FORKS))
 	{
 		*local_process_type = ZBX_PROCESS_TYPE_TRAPPER;
@@ -444,6 +461,18 @@
 	if (NULL == CONFIG_FPING6_LOCATION)
 		CONFIG_FPING6_LOCATION = zbx_strdup(CONFIG_FPING6_LOCATION, "/usr/sbin/fping6");
 #endif
+	if (NULL == CONFIG_NMAP_LOCATION)
+		CONFIG_NMAP_LOCATION = zbx_strdup(CONFIG_NMAP_LOCATION, "/usr/bin/nmap");
+
+	if (NULL == CONFIG_NMAP_PARAMS)
+		CONFIG_NMAP_PARAMS = zbx_strdup(CONFIG_NMAP_PARAMS, "-n -sn -PE");
+	
+	if (NULL == CONFIG_HISTORY_STORAGE_TYPE)
+		CONFIG_HISTORY_STORAGE_TYPE = zbx_strdup(CONFIG_HISTORY_STORAGE_TYPE, "clickhouse");
+
+	if (NULL == CONFIG_HISTORY_STORAGE_TABLE_NAME)
+		CONFIG_HISTORY_STORAGE_TABLE_NAME = zbx_strdup(CONFIG_HISTORY_STORAGE_TABLE_NAME, "zabbix.history");
+
 	if (NULL == CONFIG_EXTERNALSCRIPTS)
 		CONFIG_EXTERNALSCRIPTS = zbx_strdup(CONFIG_EXTERNALSCRIPTS, DEFAULT_EXTERNAL_SCRIPTS_PATH);
 #ifdef HAVE_LIBCURL
@@ -576,6 +605,10 @@
 			PARM_OPT,	0,			1000},
 		{"StartPollersUnreachable",	&CONFIG_UNREACHABLE_POLLER_FORKS,	TYPE_INT,
 			PARM_OPT,	0,			1000},
+		{"StartPollersAsyncSNMP",	&CONFIG_ASYNC_SNMP_POLLER_FORKS,	TYPE_INT,
+			PARM_OPT,	0,			100},
+		{"StartPollersAsyncAGENT",	&CONFIG_ASYNC_AGENT_POLLER_FORKS,	TYPE_INT,
+			PARM_OPT,	0,			100},
 		{"StartIPMIPollers",		&CONFIG_IPMIPOLLER_FORKS,		TYPE_INT,
 			PARM_OPT,	0,			1000},
 		{"StartTimers",			&CONFIG_TIMER_FORKS,			TYPE_INT,
@@ -614,6 +647,10 @@
 			PARM_OPT,	0,			0},
 		{"FpingLocation",		&CONFIG_FPING_LOCATION,			TYPE_STRING,
 			PARM_OPT,	0,			0},
+		{"NmapLocation",		&CONFIG_NMAP_LOCATION,			TYPE_STRING,
+			PARM_OPT,	0,			0},
+		{"NmapParams",		&CONFIG_NMAP_PARAMS,			TYPE_STRING,
+			PARM_OPT,	0,			0},
 		{"Fping6Location",		&CONFIG_FPING6_LOCATION,		TYPE_STRING,
 			PARM_OPT,	0,			0},
 		{"Timeout",			&CONFIG_TIMEOUT,			TYPE_INT,
@@ -718,6 +755,10 @@
 			PARM_OPT,	0,			0},
 		{"ExportFileSize",		&CONFIG_EXPORT_FILE_SIZE,		TYPE_UINT64,
 			PARM_OPT,	ZBX_MEBIBYTE,	ZBX_GIBIBYTE},
+		{"HistoryStorageType",		&CONFIG_HISTORY_STORAGE_TYPE,		TYPE_STRING,
+			PARM_OPT,	1,			0},
+		{"HistoryStorageTableName",		&CONFIG_HISTORY_STORAGE_TABLE_NAME,		TYPE_STRING,
+			PARM_OPT,	1,			0},
 		{NULL}
 	};
 
@@ -941,7 +982,7 @@
 	zabbix_log(LOG_LEVEL_INFORMATION, "VMware monitoring:         " VMWARE_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "SMTP authentication:       " SMTP_AUTH_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "Jabber notifications:      " JABBER_FEATURE_STATUS);
-	zabbix_log(LOG_LEVEL_INFORMATION, "Ez Texting notifications:  " LIBCURL_FEATURE_STATUS);
+	zabbix_log(LOG_LEVEL_INFORMATION, "CURL support:		" LIBCURL_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "ODBC:                      " ODBC_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "SSH2 support:              " SSH2_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "IPv6 support:              " IPV6_FEATURE_STATUS);
@@ -1060,7 +1101,8 @@
 		CONFIG_IPMIMANAGER_FORKS = 1;
 
 	threads_num = CONFIG_CONFSYNCER_FORKS + CONFIG_POLLER_FORKS
-			+ CONFIG_UNREACHABLE_POLLER_FORKS + CONFIG_TRAPPER_FORKS + CONFIG_PINGER_FORKS
+			+ CONFIG_UNREACHABLE_POLLER_FORKS + CONFIG_ASYNC_SNMP_POLLER_FORKS 
+			+ CONFIG_ASYNC_AGENT_POLLER_FORKS + CONFIG_TRAPPER_FORKS + CONFIG_PINGER_FORKS
 			+ CONFIG_ALERTER_FORKS + CONFIG_HOUSEKEEPER_FORKS + CONFIG_TIMER_FORKS
 			+ CONFIG_HTTPPOLLER_FORKS + CONFIG_DISCOVERER_FORKS + CONFIG_HISTSYNCER_FORKS
 			+ CONFIG_ESCALATOR_FORKS + CONFIG_IPMIPOLLER_FORKS + CONFIG_JAVAPOLLER_FORKS
@@ -1112,6 +1154,16 @@
 				thread_args.args = &poller_type;
 				threads[i] = zbx_thread_start(poller_thread, &thread_args);
 				break;
+			case ZBX_PROCESS_TYPE_ASYNC_SNMP:
+				poller_type = ZBX_POLLER_TYPE_ASYNC_SNMP;
+				thread_args.args = &poller_type;
+				threads[i] = zbx_thread_start(poller_thread, &thread_args);
+				break;
+			case ZBX_PROCESS_TYPE_ASYNC_AGENT:
+				poller_type = ZBX_POLLER_TYPE_ASYNC_AGENT;
+				thread_args.args = &poller_type;
+				threads[i] = zbx_thread_start(poller_thread, &thread_args);
+				break;
 			case ZBX_PROCESS_TYPE_TRAPPER:
 				thread_args.args = &listen_sock;
 				threads[i] = zbx_thread_start(trapper_thread, &thread_args);
